{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear\n",
    "\n",
    "Nessa aula, iremos tratar dos seguintes conteúdos:\n",
    "- Introdução a Regressões\n",
    "- Regressão Linear Simples\n",
    "- Métricas de Regressões\n",
    "- Regressão Linear Múltipla\n",
    "- Regressão Polinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução a Regressões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regressão tem por objetivo explicar a associação de variáveis quantitativas, sendo sempre uma delas a variável do objetivo do estudo, aqui chamada de **dependente**, pois veremos que o seu valor dependerá de outras informações, chamadas de **variáveis independentes**, das quais ao menos uma precisa ser também quantitativa.\n",
    "\n",
    "<img src = \"./imgs/reg_lin_pontos.png\" width = \"30%\"></img>\n",
    "\n",
    "O intuito do modelo de regressão linear é definirmos uma reta que melhor se ajusta aos dados.\n",
    "\n",
    "<img src = \"./imgs/reg_lin_explicacao.png\" width = \"30%\"></img>\n",
    "\n",
    "A seguir veremos casos de Regressão Linear Simples, Múltipla e Polinomial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear Simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na regressão linear simples, temos o modelo como: $Y \\approx \\beta_0 + \\beta_1 X$\n",
    "\n",
    "- $Y$ é a variável dependente, pois é escrita em função de variável $X$\n",
    "- $X$ é a variável independente, pois a partir dela chegaremos em valores estimados de $Y$, também denotado por $\\hat{Y}$\n",
    "- $\\beta_0$ é chamado de **intercepto** pois define o valor que intercepta o eixo $y$ quando $x = 0$. Muitas vezes pode ser interpretado como o valor mínimo associado ao determinado experimento.\n",
    "- $\\beta_1$ é chamado de **coeficiente angular**, ou ainda, **coeficiente de proporcionalidade**, pois define a qual taxa as variáveis $X$ e $Y$ se relacionam.\n",
    "\n",
    "A questão agora é, como encontramos os valores de $\\tilde{\\beta}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos de Estimação de Parâmetros\n",
    "### Propriedades esperadas\n",
    "\n",
    "<img src = \"./imgs/vies.png\" width = \"50%\"></img>\n",
    "\n",
    "- A: não-viesado, pouco acurado e baixa precisão\n",
    "- B: viesado, pouco acurado e baixa precisão\n",
    "- C: não-viesado, muito acurada e boa precisão\n",
    "- D: viesada, pouco acurada e alta precisão\n",
    "\n",
    "Queremos sempre um BLUE - Best Linear unbiased estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS ou Mínimos Quadrados Ordinários\n",
    "Um dos procedimentos mais usados para obter estimadores é aquele que se baseia no princípio dos mínimos quadrados, introduzido por Gauss em 1794, mas que primeiro apareceu com esse nome no apêndice do tratado de Legendre, Nouvelles Méthodes pour la Determination des Orbites des Comètes, publicado em Paris em 1806. Gauss somente viria a publicar seus resultados em 1809, em Hamburgo. Ambos utilizaram o princípio em conexão com problemas de Astronomia e Física."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um engenheiro está estudando a resistência Y de uma fibra em função de seu diâmetro X e notou que as variáveis são aproximadamente proporcionais, isto é, elas obedecem à relação\n",
    "\n",
    "$$Y  = \\beta_0 + \\beta_1X$$\n",
    "\n",
    "em que $\\beta_0$ representa o valor mínimo de resistência e $\\beta_1$ é o coeficiente de proporcionalidade. Agora ele deseja estimar estes parâmetros baseado numa amostra colhida por meio de mensuração e testes. Dessa maneira podemos falar que o valor esperado de Y depende de X de tal forma que\n",
    "\n",
    "$$E(Y|X) = \\beta_0 + \\beta_1X$$\n",
    "\n",
    "pois os valores reais não se ajustam perfeitamente, ou seja\n",
    "\n",
    "$$Y_i  = \\hat{\\beta}_0 + \\hat{\\beta}_1X_i + \\epsilon_i$$\n",
    "\n",
    "isto significa que\n",
    "\n",
    "$$\\epsilon_i = Y_i  - (\\beta_0 + \\beta_1X_i) = Y_i - E(Y_i|X_i) $$\n",
    "\n",
    "<img src = \"./imgs/reg_lin_erro.png\" width = \"50%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os erros podem ser positivos e negativos, e lembrando que a soma da diferença da média é sempre zero, o que queremos é minimizar a soma dos erros quadráticos, isto é:\n",
    "\n",
    "$$Z = ||\\epsilon||^2 = \\sum_{i=1}^n\\epsilon_i^2 = \\sum_{i=1}^n[Y_i - E(Y_i)]^2 = \\sum_{i=1}^n[Y_i - \\beta_0 - \\beta_1X_i]^2$$\n",
    "\n",
    "Derivando parcialmente com relação a cada parâmetro $\\beta$, igualando a zero e resolvendo o sistema de equações, chegamos que\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\begin{cases}\n",
    "\\hat{\\beta}_1=\\frac{\\sum_{i=1}^n (x_i- \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} = \\frac{\\sigma_{xy}}{\\sigma_{xx}} = \\frac{covar(x, y)}{var(x)}\\\\\n",
    "\\hat{\\beta}_0= \\bar{y}-\\hat{\\beta_1}\\bar{x}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Máxima Verossimilhança\n",
    "\n",
    "A função de verossimilhança é definida por:\n",
    "\n",
    "$$L(\\theta; \\tilde{x}) = \\prod_{i=1}^nf(x_i;\\theta)$$\n",
    "\n",
    "Neste caso queremos encontrar o valor mais verossímil de $\\theta$, ou seja, queremos encontrar qual $\\theta$ que maximiza essa função e portanto fazemos\n",
    "\n",
    "$$\\dfrac{\\partial L(\\theta; \\tilde{x})}{\\partial \\theta} = 0$$\n",
    "\n",
    "porém muitas vezes é mais fácil encontrar a log-verossimlhança, ou seja\n",
    "$$\\dfrac{\\partial log(L(\\theta; \\tilde{x}))}{\\partial \\theta} = \\dfrac{\\partial l(\\theta; \\tilde{x})}{\\partial \\theta}= 0$$\n",
    "\n",
    "pois\n",
    "\n",
    "$$l(\\theta; \\tilde{x}) = log(L(\\theta; \\tilde{x})) = log(\\prod_{i=1}^n f(x_i;\\theta)) = \\sum_{i=1}^n log(f(x_i;\\theta))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-05T22:44:02.443559Z",
     "start_time": "2021-11-05T22:44:00.636527Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import das bibliotecas necessárias\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-05T22:44:03.975066Z",
     "start_time": "2021-11-05T22:44:03.953052Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read dataset\n",
    "dataset = pd.read_csv(\"./data/Salary_Data.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-05T22:44:08.107920Z",
     "start_time": "2021-11-05T22:44:08.086965Z"
    }
   },
   "outputs": [],
   "source": [
    "#ols stats\n",
    "reg_lin = smf.ols(\"Salary ~ YearsExperience\", dataset).fit()\n",
    "reg_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-05T22:44:10.049982Z",
     "start_time": "2021-11-05T22:44:10.033992Z"
    }
   },
   "outputs": [],
   "source": [
    "reg_lin.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comecamos 21:15 \n",
    "## Métricas de Regressões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alguma das métricas que podemos utilizar para quantificar a acurácia do modelo, usamos por exemplo raiz quadrada da média dos erros quadráticos RMSE (*root mean squared error*), erro quadrático médio MSE (*mean squared error*) e o erro absoluto médio MAE (*mean absolute error*):<br><br>\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "MSE = {\\frac{1}{n}\\sum_{i=1}^n (y_i-\\hat{y}_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "MAE = {\\frac{1}{n}\\sum_{i=1}^n |y_i-\\hat{y}_i|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra medida importante é o **coeficiente de determinação $R^2$**, que mede a proporção da variabilidade em Y que pode ser explicada a partir de X.\n",
    "\n",
    "$$R^2 = 1-\\frac{\\sum_{i=1}^n (y_i-\\hat{y}_i)^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2}, \\quad 0\\leq R^2\\leq 1$$\n",
    "\n",
    "Entretanto essa é uma medida que precisa ser olhada com cautela dado que sempre aumenta a medida que incluímos variáveis no modelos, independentemente de explicar ou não a variável. Além disso ela pode aumentar ou diminuir de acordo com a amplitude de X.\n",
    "\n",
    "Portanto surge o **coeficiente de determinação ajustado $\\overline{R}^2$** dado por:\n",
    "\n",
    "$$1-\\dfrac{n-1}{n-2}(1-R^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-05T22:44:14.612277Z",
     "start_time": "2021-11-05T22:44:14.598278Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-05T22:44:16.724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 1].values\n",
    "#print(X)\n",
    "#print(y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)\n",
    "\n",
    "#print(X_train)\n",
    "#print(X_test)\n",
    "\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "regressor.predict(np.array([1.1]).reshape(1,-1))\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(X_test)\n",
    "print(y_pred)\n",
    "# Visualising the Training set results\n",
    "plt.scatter(X_train, y_train, color = 'red')\n",
    "plt.plot(X_train, regressor.predict(X_train), color = 'blue')\n",
    "plt.title('Salary vs Experience (Training set)')\n",
    "plt.xlabel('Years of Experience')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()\n",
    "\n",
    "# Visualising the Test set results\n",
    "plt.scatter(X_test, y_test, color = 'red')\n",
    "plt.plot(X_test, regressor.predict(X_test), color = 'blue')\n",
    "plt.title('Salary vs Experience (Test set)')\n",
    "plt.xlabel('Years of Experience')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = red>Pressuposições **NECESSÁRIAS**</font>\n",
    "\n",
    "- A relação entre Y e X é **linear**\n",
    "- Os valores de X são fixos (ou controlados)\n",
    "- A média do erro é nula, isto é, $E(\\epsilon_i) = 0$\n",
    "- É necessário haver **homocedasticidade de variância**, ou seja, para cada valor de X, a variância do erro $\\epsilon_i$ é sempre $\\sigma^2$. O que implica que $Var(Y_i) = \\sigma^2$\n",
    "- O erro de uma observação é independente do erro de outra observação, ou seja:\n",
    "$$cov(\\epsilon_i, \\epsilon_i') = 0$$\n",
    "- Os erros têm distribuição normal (necessário para testes de hipóteses e determinação de intervalo de confiânça)\n",
    "$$\\epsilon \\sim N(0, \\sigma^2$$\n",
    "\n",
    "Logo\n",
    "\n",
    "$$Y\\sim N(\\beta_0 + \\beta_1X, \\sigma^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear Múltipla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na regressão linear múltipla, temos o modelo como: $Y = \\beta_0 + \\beta_1 X_1  + \\beta_2 X_2 + ... + \\beta_n X_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo 3\n",
    "\n",
    "Para o exemplo de Regressão Linear Múltipla, iremos utilizar o dataset *Car_Prices.csv*, onde o objetivo é estimar o preço dos carros a partir de suas características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando o CSV\n",
    "cars = pd.read_csv('./data/CarPrice.csv')\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas estatísticas interessantes sobre o dataset\n",
    "cars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Por curiosidade, vamos ver como está os valores desses carros\n",
    "cars[['CarName', 'price']].sort_values(['price'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.histplot(cars[\"price\"], kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Olhando os tipos de variáveis que temos na base\n",
    "cars.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Features categóricas ou em forma de string\n",
    "cars[['CarName', 'fueltype', 'aspiration', 'doornumber', 'carbody', 'cylindernumber']].head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante levantar que a regressão linear, seja ela simples ou múltipla, só suporta valores númericos. Dessa forma devemos tratar os dados categóricos da nossa base. Para isso vamos utilizar a função [get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html), onde esta função transforma as variáveis categóricas em diversas colunas no DataFrame para cada uma das opções de categoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_with_dummies = pd.get_dummies(cars, prefix_sep='_', columns=['fueltype', \n",
    "                                                                  'aspiration', \n",
    "                                                                  'doornumber', \n",
    "                                                                  'carbody', \n",
    "                                                                  'cylindernumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vamos dar uma olhada no que aconteceu com a base\n",
    "cars_with_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparado a base, primeiro passo **importante** para podermos usar os dados no modelo é separar o dados em base de treino e teste (ou em alguns casos validação), onde a divisão fica da seguinte forma:\n",
    "- **X :** todos os dados dispovínel sobre a dado que utilizamos exceto a resposta;\n",
    "- **y :** Variável de resposta da nossa base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cars_with_dummies.drop(['car_ID', 'CarName', 'price'], axis = 1)\n",
    "y = cars_with_dummies['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar para a separação da base em treino e teste a função [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), onde os parâmetros da função que mais iremos utlizar são:\n",
    "- **test_size:** Defini a porcentagem que será separada para a base de teste;\n",
    "- **random_state:** Seed de aleatoriadade, para garantir a reprodutibilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o caso da Regressão Linear Múltipla, iremos utilizar a biblioteca do Scikit-Learn chamada [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linearregression#sklearn.linear_model.LinearRegression):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia o modelo\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit dos dados (ou seja, vamos passar os dados para o modelo aprender com eles)\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para os dados novos, vamos definir a predição para a base de teste\n",
    "y_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar um gráfico para comparar os Valores Reais com os Preditos\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "l = plt.plot(y_pred, y_test, 'bo')\n",
    "plt.setp(l, markersize=10)\n",
    "plt.setp(l, markerfacecolor='C0')\n",
    "plt.title('Comparação Valor Predito x Valor Real', fontsize=12)\n",
    "plt.ylabel(\"True Value\", fontsize=12)\n",
    "plt.xlabel(\"Predict Value\", fontsize=12)\n",
    "\n",
    "# mostra os valores preditos e originais\n",
    "xl = np.arange(min(y_test), 1.2*max(y_test),(max(y_test)-min(y_test))/10)\n",
    "yl = xl\n",
    "plt.plot(xl, yl, 'r--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos calcular o R2 para o modelo, importando a métrica [r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) diretamente do Scikit_Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print('R2:', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo interessante que podemos fazer com o modelo é definir quais variáveis são as mais relevantes na hora da predição dos valores, ou seja quais variáveis têm maiores coeficientes. Esse processo é muito recorrente em Machine Learning e é chamado de **Feature Importance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = linreg.coef_\n",
    "\n",
    "list_columns = X_train.columns\n",
    "list_feature = []\n",
    "list_score = []\n",
    "\n",
    "for i, v in enumerate(coefs):\n",
    "    list_feature.append(list_columns[i])\n",
    "    list_score.append(v)\n",
    "\n",
    "dictionary = {'Features': list_feature,\n",
    "              'Scores': list_score}\n",
    "\n",
    "df_features = pd.DataFrame(dictionary)\n",
    "df_features = df_features.sort_values(by=['Scores'], ascending=False)\n",
    "df_features.reset_index(inplace=True, drop=True)\n",
    "#df_features.head(10)\n",
    "df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Polinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notem que o modelo não precisa ter termos lineares em X, mas apenas nos parâmetros necessitam ser lineares. Por exemplo, modelo abaixo ainda é linear nos parâmetros: $$y = \\beta_0 + \\beta_1 x + \\beta_2 x^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O macete para usar Regressão Linear para a predição com variáveis não lineares é fazermos uma transformação linear dos valores de X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#poly\n",
    "# define a transformação nos dados\n",
    "\n",
    "\n",
    "# transforma os dados incluindo uma nova coluna com valores quadráticos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "l = plt.plot(y_pred, y, 'bo')\n",
    "plt.setp(l, markersize=10)\n",
    "plt.setp(l, markerfacecolor='C0')\n",
    "plt.title('Comparação Valor Predito x Valor Real', fontsize=12)\n",
    "plt.ylabel(\"True Value\", fontsize=12)\n",
    "plt.xlabel(\"Predict Value\", fontsize=12)\n",
    "\n",
    "# mostra a reta diagonal, que representa a predição perfeita\n",
    "xl = np.arange(min(y), 1.2*max(y),(max(y)-min(y))/10)\n",
    "yl = xl\n",
    "plt.plot(xl, yl, 'r--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(x,y, 'ro', label='Dados originais')\n",
    "plt.plot(x,y_pred, 'b-', label = 'Dados preditos')\n",
    "plt.title('Distribuição dos Pontos + Regressão Linear')\n",
    "plt.ylabel(\"y\", fontsize=12)\n",
    "plt.xlabel(\"x\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1)__ O arquivo fish.csv consiste em um dataset com registro de características de 7 espécies diferentes de peixes comuns nas vendas do mercado de peixes. Com este conjunto de dados, um modelo de Regressão Linear para estimar o peso (Weight) dos peixes.\n",
    "\n",
    "Não esqueça de explorar os dados, realizar o tratamento dos dados (analise o tipo dos dados, por exemplo), fazer a separação dos dados de treino e teste; e, por fim, avaliar a precisão do seu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish = pd.read_csv('./datasets/fish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2)__ Carregue os dados contidos no arquivo who-life-expectancy.csv (link abaixo), o qual contém diversas informações sobre os países do mundo inteiro, incluindo a expectativa de vida de sua população, entre os anos de 2000 e 2015. Seu objetivo é criar um modelo de Regressão Linear capaz de estimar a expectativa de vida da população de um país (em um determinado ano) dadas as demais informações sobre esse país.\n",
    "\n",
    "Dica: Você deverá notar que esse dataset possui muitos dados ausentes (NaN), portanto, neste caso, será necessário realizar uma limpeza nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wle = pd.read_csv('./datasets/who-life-expectancy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3)__ O arquivo usa_housing.csv consiste em um dataset que contém informações sobre o preço de casas em determinadas regiões dos Estados Unidos. Uma descrição das colunas desse dataframes é apresentada abaixo:\n",
    "\n",
    "- __Avg. Area Income:__ Média da renda dos residentes de onde a casa está localizada.\n",
    "- __Avg. Area House Age:__ Média de idade das casas da mesma cidade.\n",
    "- __Avg. Area Number of Rooms:__ Número médio de quartos para casas na mesma cidade.\n",
    "- __Avg. Area Number of Bedrooms:__ Número médio de quartos para casas na mesma cidade.\n",
    "- __Area Population:__ A população da cidade onde a casa está localizada.\n",
    "- __Price:__ Preço de venda da casa.\n",
    "- __Address:__ Endereço da casa.\n",
    "\n",
    "Utilize os dados contidos nele para criar um modelo de regressão linear que seja capaz de estimar o preço de venda das casas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = pd.read_csv('./datasets/usa_housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links, Artigos e Referências:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Scikit-Learn](https://scikit-learn.org/stable/index.html), Documentação do Scikit-Learn;\n",
    "- [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), Documentação da Regressão Linear;\n",
    "- [Linear Regression - Detailed View](https://towardsdatascience.com/linear-regression-detailed-view-ea73175f6e86), artigo publicado pelo Towards Data Science."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
