{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362c03d1",
   "metadata": {},
   "source": [
    "# Projeto 2 - NLP\n",
    "\n",
    "-----\n",
    "\n",
    "Nome:  Johnny Hideki Horita <br>\n",
    "Turma: 780"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517a372",
   "metadata": {},
   "source": [
    "Os segundo projeto do módulo de Machine Learning será focado no processamento de linguagem natural! Usaremos os algoritmos aprendidos e as técnicas vistas na segunda parte do curso para extrairmos informações relevantes de texto. Mais precisamente, de publicações no Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a3a98",
   "metadata": {},
   "source": [
    "## Os Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d5657",
   "metadata": {},
   "source": [
    "Utilizaremos um Dataset obtido do Twitter com 100K postagens entre os dias 01/08/2018 e 20/10/2018. Cada postagem é classificada como **positiva**, **negativa** ou **neutra**.  \n",
    "\n",
    "Dois arquivos serão disponilizados para o desenvolvimento dos modelos, um para treino/validação e outro para submissão. Os arquivos se encontram na pasta */Dados/train* e */Dados/subm*, respectivamente.\n",
    "\n",
    "Descrição das colunas:\n",
    "\n",
    "- **id**: ID único para o tweet  \n",
    "- **tweet_text**: Texto da publicação no Twitter  \n",
    "- **tweet_date**: Data da publicação no Twitter  \n",
    "- **sentiment**: 0, se negativo; 1, se positivo; 2, se neutro  \n",
    "- **query_used**: Filtro utilizado para buscar a publicação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc86eb5",
   "metadata": {},
   "source": [
    "## O Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e1f6f",
   "metadata": {},
   "source": [
    "Você deverá desenvolver um modelo para detectar o sentimento de uma publicação do Twitter a classificando em uma das três categorias: **positiva**, **negativa** ou **neutra**. O texto da publicação está disponível na coluna \"tweet_text\". Teste pelo menos 3 técnicas de NLP diferentes e escolha a métrica de avaliação que julgar mais pertinente.  \n",
    "\n",
    "Escolha o melhor modelo e gere uma base a partir dos dados de submissão, que estão no caminho ```Dados/subm/Subm3Classes.csv```, com o seguinte formato:\n",
    "\n",
    "\n",
    "|id|sentiment_predict\n",
    "|-|-|\n",
    "|12123232|0\n",
    "|323212|1\n",
    "|342235|2\n",
    "\n",
    "Salve essa tabela como um arquivo csv com o nome ```<nome>_<sobrenome>_nlp_degree.csv``` e submeta-o como parte da entrega final do projeto.  \n",
    "\n",
    "Para ajudar no desenvolvimento, é possível dividir o projeto em algumas fases:\n",
    "\n",
    "- **Análise de consistência dos dados**: analise se os dados estão fazendo sentido, se os campos estão completos e se há dados duplicados ou faltantes. Se julgar necessário, trate-os.    \n",
    "\n",
    "\n",
    "- **Análise exploratória**: analise a sua base como um todo, verifique o balanceamento entre as classes e foque, principalmente, na coluna ```tweet_text```.    \n",
    "\n",
    "\n",
    "- **Pré-processamento e transformações**: projetos de NLP exigem um considerável pré-processamento. Foque no tratamento da string do texto. Procure começar com tratamentos simples e adicione complexidade gradualmente. Nessa etapa você testará diferentes técnicas de transformações, como o Bag Of Words e o TF-IDF.    \n",
    "\n",
    "\n",
    "- **Treinamento do modelo**: depois das transformações, você poderá executar o treinamento do modelo classificador. Nessa etapa o problema se torna semelhante aos abordados na primeira parte do módulo. Você pode testar diversos classificadores como RandomForest, AdaBoost, entre outros. Otimize os hiperparâmetros do modelo com técnicas como a GridSearch e a RandomizedSearch.    \n",
    "\n",
    "\n",
    "- **Conclusões**: descreva, em texto, as conclusões sobre os seus estudos. O modelo é capaz de identificar o sentimento das publicações? É possível extrapolar o modelo para outros contextos, como a análise de sentimento de uma frase qualquer? Pense em questões pertinentes e relevantes que você tenha obtido durante o desenvolvimento do projeto!     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283638c9",
   "metadata": {},
   "source": [
    "## Critérios de avaliação\n",
    "\n",
    "Os seguintes itens serão avaliados:\n",
    "\n",
    "1. Desenvolvimento das etapas descritas acima;\n",
    "\n",
    "\n",
    "2. Reprodutibilidade do código: seu código será executado e precisa gerar os mesmos resultados apresentados por você;\n",
    "\n",
    "\n",
    "3. Clareza: seu código precisa ser claro e deve existir uma linha de raciocínio direta. Comente o código em pontos que julgar necessário para o entendimento total;\n",
    "\n",
    "\n",
    "4. Justificativa das conclusões obitdas: não existirá certo ou errado, mas as decisões e as conclusões precisam ser bem justificadas com base nos resultados obtidos.  \n",
    "\n",
    "O desempenho do modelo **não** será considerado como critério de avaliação.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6049a9c",
   "metadata": {},
   "source": [
    "## Informações gerais\n",
    "\n",
    "- O projeto deve ser desenvolvido individualmente;\n",
    "\n",
    "\n",
    "- Data de divulgação: 11/01/2022;\n",
    "\n",
    "\n",
    "- Aula de monitoria: 19/01/2022;\n",
    "\n",
    "\n",
    "- Data de entrega: 26/01/2022;\n",
    "\n",
    "\n",
    "- Entrega através do Class: Árvore de Decisão -> Exercícios -> Projeto 2\n",
    "\n",
    "\n",
    "Anexar, na entrega, o notebook de desenvolvimento e o arquivo .csv de submissão, da seguinte forma:  \n",
    "\n",
    "notebook: ```<nome>_<sobrenome>_<númeroTurma>_projeto_2.ipynb```   \n",
    "csv: ```<nome>_<sobrenome>_<númeroTurma>_projeto_2_submissao.csv```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb23437",
   "metadata": {},
   "source": [
    "## Dicas\n",
    "\n",
    "### Base de treino e submissão\n",
    "\n",
    "A base de submissão não possui a variável de saída, portanto ela será utilizada **apenas** para gerar o arquivo que acompanha a submissão do projeto.      \n",
    "\n",
    "### Tente encontrar possíveis vieses\n",
    "\n",
    "É muito comum que modelos de NLP possuam fortes vieses, como a tendência de relacionar palavras específicas com alguma classe de saída. Tente encontrar vieses no seu estudo, isso pode ajudar a tirar boas conclusões. o campo \"query_used\" pode ser útil para essa análise.  \n",
    "\n",
    "### O pré-processamento é a chave para um bom desempenho\n",
    "\n",
    "Essa é a etapa que mais vai contribuir para o desempenho do seu modelo. Seja criativo e desenvolva essa etapa de uma maneira que seja fácil de aplicar o mesmo processamento para uma nova base, você terá que fazer isso para gerar a base de submissão.\n",
    "\n",
    "### Um termômetro para o seu desenvolvimento\n",
    "\n",
    "Após a correção do seu projeto, o professor irá disponibilizar a sua acurácia obtida na base de submissão. Você pode interpretar esse resultado como a simulação do resultado do seu modelo em produção. Uma diferença entre o resultado do estudo e o resultado de submissão indica um grau de **overfitting** no seu modelo.\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96911dea",
   "metadata": {},
   "source": [
    "# Desenvolvimento do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d5233",
   "metadata": {},
   "source": [
    "## 1. Análise de consistência dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f25c3d",
   "metadata": {},
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad89b883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas carregadas com sucesso.\n",
      "Wall time: 8.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Bibliotecas\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import requests\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import squarify\n",
    "import plotly.offline as py\n",
    "import plotly_express as px\n",
    "from plotly import graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, f1_score, r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score, StratifiedKFold, cross_validate\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec, doc2vec\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "# Naive Bayes (Gaussian, Multinomial,BernoulliNB)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# Stochastic Gradient Descent Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# KNN (k-nearest neighbor)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# XGBoost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "# LGBM Classifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# Ada Boosting Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Dummy Boosting Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "# GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from unidecode import unidecode\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#!pip install enelvo\n",
    "from enelvo.normaliser import Normaliser\n",
    "\n",
    "# Abaixo seguem 2 formas para a instalação do spaCy: via conda ou pip\n",
    "# Instalação utilizando conda\n",
    "#!conda install -c conda-forge spacy\n",
    "\n",
    "# Instalação utilizando Pip\n",
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "\n",
    "import spacy\n",
    "from spacy.util import compounding\n",
    "from spacy.util import minibatch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import shap\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from IPython.core.display import HTML as Center\n",
    "from IPython.display import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Bibliotecas carregadas com sucesso.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1272b9b",
   "metadata": {},
   "source": [
    "### Padrões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51314fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de padrões para gráficos e cores\n",
    "\n",
    "sns.set_style('darkgrid') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=13)    # legend fontsize\n",
    "plt.rc('font', size=13)          # controls default text sizes\n",
    "\n",
    "colors = sns.color_palette(\"pastel\") # deep, pastel, Set1 Set2 Set3, icefire, tab10, muted, colorlind, coolwarm\n",
    "cmap_colors = 'GnBu'\n",
    "\n",
    "font_path = \"./fonts/CabinSketch-Bold.ttf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e73245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definição de padrões para centralização de gráficos no notebook\n",
    "\n",
    "Center(\"\"\" <style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style> \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c2874",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3054506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de avaliação dos valores de NaN no dataframe\n",
    "\n",
    "def missing_values_table(df):\n",
    "    '''\n",
    "    Função para verificar se existem valores nulos no dataframe\n",
    "    Entrada:\n",
    "        df - dataframe;\n",
    "        \n",
    "    Resultado: \n",
    "        Apresentação dos valores nulos no dataframe.\n",
    "\n",
    "    '''\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mz_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mz_table = mz_table.rename(\n",
    "    columns = {0 : 'Valores faltantes', 1 : '% de Valores Totais'})\n",
    "    mz_table['Data Type'] = df.dtypes\n",
    "    mz_table = mz_table[\n",
    "        mz_table.iloc[:,1] != 0].sort_values(\n",
    "    '% de Valores Totais', ascending=False).round(1)\n",
    "    print (\"O dataframe tem \" + str(df.shape[1]) + \" colunas e \" + str(df.shape[0]) + \" linhas.\\n\"      \n",
    "        \"Existem \" + str(mz_table.shape[0]) +\n",
    "          \" colunas que têm valores faltantes.\")\n",
    "    mz_table.to_excel('missing_and_zero_values.xlsx', freeze_panes=(1,0), index = True)\n",
    "    return mz_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61537f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de avaliação de modelos apresentação da matriz de confusão\n",
    "score = []\n",
    "\n",
    "def test_models(model_list, col_model_name, col_model, tec_model, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Função para avaliação de modelos de predição\n",
    "    Entrada:\n",
    "        model_list - lista de modelos;\n",
    "        col_model_name - label da lista de modelos, contendo o nome do modelo;\n",
    "        col_model - label da lista de modelos, contendo a instancia do modelo de predição;\n",
    "        tec_model - definição de tratamento de modelos;\n",
    "        X_train - classe de treino\n",
    "        X_test - classe de teste\n",
    "        y_train - classe de treino\n",
    "        y_test - classe de teste\n",
    "        \n",
    "    Resultado: \n",
    "        Apresentação de métricas de predição de modelos.\n",
    "\n",
    "    '''\n",
    "    for mdl in model_list:\n",
    "        start = time.time()\n",
    "\n",
    "        model = mdl[col_model]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        \n",
    "        print(\"\")        \n",
    "        print(\"=\" * 55)\n",
    "        print(\"Model      : %s\" % mdl[col_model_name])\n",
    "        print(\"Accuracy   : %0.4f \" % accuracy_score(y_test, y_predict))\n",
    "        print(\"Precision  : %0.4f \" % precision_score(y_test, y_predict, average='weighted'))\n",
    "        print(\"Recall     : %0.4f \" % recall_score(y_test, y_predict, average='weighted'))\n",
    "        print(\"F1 - Score : %0.4f \" % f1_score(y_test, y_predict, average='weighted'))\n",
    "        print(\"MAE        : %0.4f \" % mean_absolute_error(y_test, y_predict))\n",
    "        print(\"RMSE       : %0.4f \" % np.sqrt(mean_squared_error(y_test, y_predict)))\n",
    "        print(\"R2         : %0.4f \" % r2_score(y_test, y_predict))\n",
    "        print(\"\")\n",
    "        print(classification_report(y_test, y_predict))\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_predict)\n",
    "        labels = ['Negativo','Positivo','Neutro']\n",
    "        dsp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "        dsp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n",
    "        plt.grid(False)\n",
    "        plt.show()        \n",
    "        \n",
    "        end = time.time()\n",
    "        elptime = end - start\n",
    "        converted_time = str(datetime.timedelta(seconds=elptime))\n",
    "        print(f'Partial time: {converted_time}')\n",
    "        \n",
    "        global score\n",
    "        score.append([mdl[col_model_name], tec_model, accuracy_score(y_test, y_predict)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f11adbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a importância da variável no modelo\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "def modelfit(alg, dtrain, predictors, target, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    # Adequando as classes para treino\n",
    "    alg.fit(dtrain[predictors], dtrain[target])\n",
    "        \n",
    "    # Previsão de saída para o conjunto de dados de teste\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    # Utilizando o Cross Validation\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, dtrain[predictors], dtrain[target], cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Exibindo relatório:\n",
    "    print (f\"\\nRelatório do Modelo {alg}\")\n",
    "    print (\"\\nAcuracia : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "    #print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predictions))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "        \n",
    "    #Exibindo gráfico da importancia das variáveis\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Importância das variáveis', color=colors)\n",
    "        plt.ylabel('Pontuação')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f24a2a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_corpus(list_sentences, tokens_only=False):\n",
    "    if tokens_only:\n",
    "        # For test data, just return sentences\n",
    "        return list_sentences\n",
    "    else:\n",
    "        # For training data, add tags\n",
    "        lista = []\n",
    "        for i, line in enumerate(list_sentences):\n",
    "            lista.append(doc2vec.TaggedDocument(line, [i]))\n",
    "\n",
    "        return lista\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52180e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para geração de cores\n",
    "\n",
    "def random_colours(number_of_colors):\n",
    "    '''\n",
    "    Função para geração de cores aleatórias.\n",
    "    Entrada:\n",
    "        número_de_cores - valor inteiro indicando o número de cores que vão ser geradas.\n",
    "    Saída:\n",
    "        Cor no seguinte formato: ['#E86DA4'].\n",
    "        \n",
    "    '''\n",
    "    colors = []\n",
    "    for i in range(number_of_colors):\n",
    "        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n",
    "    return colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc2553f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para contagem de palavras \n",
    "\n",
    "def words_unique(sentiment, numwords, raw_words):\n",
    "    '''\n",
    "    Função para contagem de palavras \n",
    "    Entrada:\n",
    "        segmento - Categoria do segmento (ex. 2 = 'Neutro');\n",
    "        numwords - quantas palavras específicas se pretende ver no resultado final; \n",
    "        raw_words - lista do texto;\n",
    "        \n",
    "    Resultado: \n",
    "        dataframe com informação sobre a palavra específica e quantas vezes aparece no texto (por ordem decrescente com base nas suas contagens).\n",
    "\n",
    "    '''\n",
    "    allother = []\n",
    "    for item in dfc[dfc.sentiment != sentiment]['list_words']:\n",
    "        for word in item:\n",
    "            allother .append(word)\n",
    "    allother  = list(set(allother ))\n",
    "    \n",
    "    specificnonly = [x for x in raw_text if x not in allother]\n",
    "    \n",
    "    mycounter = Counter()\n",
    "    \n",
    "    for item in dfc[dfc.sentiment == sentiment]['list_words']:\n",
    "        for word in item:\n",
    "            mycounter[word] += 1\n",
    "    keep = list(specificnonly)\n",
    "    \n",
    "    for word in list(mycounter):\n",
    "        if word not in keep:\n",
    "            del mycounter[word]\n",
    "    \n",
    "    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n",
    "    \n",
    "    return Unique_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922f869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\johnny.horita\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\johnny.horita\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Abaixo seguem 2 formas para a instalação do spaCy: via conda ou pip\n",
    "\n",
    "# Instalação utilizando conda\n",
    "#!conda install -c conda-forge spacy\n",
    "\n",
    "# Instalação utilizando Pip\n",
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "\n",
    "# Bilbioteca em portugues\n",
    "# Efficiency\n",
    "#!python -m spacy download pt_core_news_sm\n",
    "\n",
    "# Accuracy\n",
    "#!python -m spacy download pt_core_news_lg\n",
    "\n",
    "spc_pt = spacy.load('pt_core_news_lg')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "#Adicionando stopwords que não estão na lista do nltk \n",
    "stopwords.append(\"'\")\n",
    "stopwords.append(\"pra\")\n",
    "stopwords.append(\"tá\")\n",
    "stopwords.append(\"tão\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad860da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para tratamento da variável de texto para definir melhores valores para classificação da modelagem\n",
    "# e ou normalizar o tratamento da variável de texto utilizando a biblioteca enelvo\n",
    "\n",
    "# instanciando\n",
    "normalizador = Normaliser(tokenizer='readable', sanitize=True, capitalize_acs=True, capitalize_pns=True) # capitalize_inis=True\n",
    "\n",
    "def nlp_tratar_texto(texto, normalize=False):\n",
    "    '''\n",
    "    Função para tratamento de texto \n",
    "    Entrada:\n",
    "        texto - Texto para tratamento;\n",
    "        normalize - utilizar função de normalização da biblioteca enelvo;\n",
    "        \n",
    "    Resultado: \n",
    "        Retorna o texto com tratamento de caracteres.\n",
    "\n",
    "    '''    \n",
    "    #Remover endereços de sites\n",
    "    texto_sem_url = re.sub(r'https?:\\/\\/\\S+', '', texto)\n",
    "        \n",
    "    #Remover e-mail / users\n",
    "    #texto_sem_email = re.sub(r'[A-Za-z0-9]*@[A-Za-z]*\\.?[A-Za-z0-9]*\\.?[A-Za-z0-9]*', '', texto_sem_url)\n",
    "    texto_sem_email = re.sub(r'[A-Za-z0-9]*@\\S+', '', texto_sem_url)\n",
    "    \n",
    "    if normalize==True:\n",
    "        # Tratamento do texto utilizando o enelvo (Normalize)\n",
    "        texto_norm = normalizador.normalise(texto_sem_email)\n",
    "    \n",
    "        #Remover caracteres que não são letras e tokenização\n",
    "        texto_tratado =  re.findall(r'\\b[A-zÀ-úü]+\\b', texto_norm.lower())\n",
    "    else:\n",
    "        texto_tratado =  re.findall(r'\\b[A-zÀ-úü]+\\b', texto_sem_email.lower())\n",
    "\n",
    "    #Remover stopwords\n",
    "    stop = set(stopwords)\n",
    "    palavras = [w for w in texto_tratado if w not in stop]\n",
    "    palavras_string = \" \".join(palavras)\n",
    "\n",
    "    #Instanciar o objeto spacy\n",
    "    spc_letras =  spc_pt(palavras_string)\n",
    "\n",
    "    #Lemmização \n",
    "    tokens = [token.lemma_ if token.pos_ == 'VERB' else str(token) for token in spc_letras]\n",
    "\n",
    "    #problemas com verbo ir\n",
    "    ir = ['vou', 'vais', 'vai', 'vamos', 'ides', 'vão']\n",
    "    tokens = ['ir' if token in ir else str(token) for token in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a733446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para apresentar nuvem de palavras\n",
    "\n",
    "def plot_wordcloud(text, title = None, backcolor = 'white', clrmap = ''):\n",
    "    '''\n",
    "    Função para criação de imagem de nuvem de palavras\n",
    "    Entrada:\n",
    "        text - palavras para nuvem de palavras;\n",
    "        title - título da imagem;\n",
    "        backcolor - ;\n",
    "        clrmap - ;\n",
    "        \n",
    "    Resultado: \n",
    "        Imagem com nuvem de palavras.\n",
    "\n",
    "    '''    \n",
    "    wordcloud = WordCloud(\n",
    "                            background_color=backcolor,\n",
    "                            width=2000, \n",
    "                            height=800,\n",
    "                            colormap=clrmap, \n",
    "                            font_path=font_path, \n",
    "                            collocations = False)\n",
    "\n",
    "    wordcloud.generate(text)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c39e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e738a2b7",
   "metadata": {},
   "source": [
    "### Inicializando Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2348e7b",
   "metadata": {},
   "source": [
    "#### Arquivo Train3Classes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39c224f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando arquivo\n",
    "\n",
    "df = pd.read_csv('./dados/train/Train3Classes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efd96274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de linhas...........: 95000\n",
      "Quantidade de linhas duplicadas: 0\n",
      "Quantidade de colunas..........: 5\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtl, qtc = df.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "\n",
    "qtd, _ = df[df.duplicated(keep=False)].shape\n",
    "\n",
    "print(f'Quantidade de linhas...........: {qtl}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtd}')\n",
    "print(f'Quantidade de colunas..........: {qtc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daf0b35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95000 entries, 0 to 94999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          95000 non-null  int64 \n",
      " 1   tweet_text  95000 non-null  object\n",
      " 2   tweet_date  95000 non-null  object\n",
      " 3   sentiment   95000 non-null  int64 \n",
      " 4   query_used  95000 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95aba7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataframe tem 5 colunas e 95000 linhas.\n",
      "Existem 0 colunas que têm valores faltantes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores faltantes</th>\n",
       "      <th>% de Valores Totais</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Valores faltantes, % de Valores Totais, Data Type]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando os valores nulos do dataframe\n",
    "\n",
    "missing_values_table(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abf0cc",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "O dataframe é composto por 05 colunas e 95.000 registros.\n",
    "\n",
    "A tabela acima NÃO apresenta valores faltantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c26c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc5d77c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tweet_text', 'tweet_date', 'sentiment', 'query_used'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de colunas do dataframe\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c9ae92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1049721159292346368</td>\n",
       "      <td>Rio elege maior bancada policial de sua histór...</td>\n",
       "      <td>Tue Oct 09 18:00:01 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>folha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046251157025423360</td>\n",
       "      <td>fiquei tão triste quando eu vi o preço da câme...</td>\n",
       "      <td>Sun Sep 30 04:11:28 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041744620206653440</td>\n",
       "      <td>Para Theresa May, seu plano para o Brexit é a ...</td>\n",
       "      <td>Mon Sep 17 17:44:06 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>exame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046937084727107589</td>\n",
       "      <td>caralho eu quero proteger a danielly em um pot...</td>\n",
       "      <td>Tue Oct 02 01:37:06 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1047326854229778432</td>\n",
       "      <td>@SiCaetano_ viva o caos :)</td>\n",
       "      <td>Wed Oct 03 03:25:55 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         tweet_text  \\\n",
       "0  1049721159292346368  Rio elege maior bancada policial de sua histór...   \n",
       "1  1046251157025423360  fiquei tão triste quando eu vi o preço da câme...   \n",
       "2  1041744620206653440  Para Theresa May, seu plano para o Brexit é a ...   \n",
       "3  1046937084727107589  caralho eu quero proteger a danielly em um pot...   \n",
       "4  1047326854229778432                         @SiCaetano_ viva o caos :)   \n",
       "\n",
       "                       tweet_date  sentiment query_used  \n",
       "0  Tue Oct 09 18:00:01 +0000 2018          2      folha  \n",
       "1  Sun Sep 30 04:11:28 +0000 2018          0         :(  \n",
       "2  Mon Sep 17 17:44:06 +0000 2018          2      exame  \n",
       "3  Tue Oct 02 01:37:06 +0000 2018          0         :(  \n",
       "4  Wed Oct 03 03:25:55 +0000 2018          1         :)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listagem das primeiras linhas do dataframe\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5fbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "076d3e1e",
   "metadata": {},
   "source": [
    "#### Arquivo Subm3Classes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d44206b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando arquivo\n",
    "\n",
    "dfs = pd.read_csv('./dados/subm/Subm3Classes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19b40840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de linhas...........: 5000\n",
      "Quantidade de linhas duplicadas: 0\n",
      "Quantidade de colunas..........: 4\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtls, qtcs = dfs.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "\n",
    "qtds, _ = dfs[dfs.duplicated(keep=False)].shape\n",
    "\n",
    "print(f'Quantidade de linhas...........: {qtls}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtds}')\n",
    "print(f'Quantidade de colunas..........: {qtcs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7804372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          5000 non-null   int64 \n",
      " 1   tweet_text  5000 non-null   object\n",
      " 2   tweet_date  5000 non-null   object\n",
      " 3   query_used  5000 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "dfs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce2ff13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataframe tem 4 colunas e 5000 linhas.\n",
      "Existem 0 colunas que têm valores faltantes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores faltantes</th>\n",
       "      <th>% de Valores Totais</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Valores faltantes, % de Valores Totais, Data Type]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando os valores nulos do dataframe\n",
    "\n",
    "missing_values_table(dfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2aa854",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "O dataframe é composto por 04 colunas e 5.000 registros.\n",
    "\n",
    "A tabela acima NÃO apresenta valores faltantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5758254f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tweet_text', 'tweet_date', 'query_used'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de colunas do dataframe\n",
    "\n",
    "dfs.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f99fa6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1046764676707753987</td>\n",
       "      <td>Apartamento Vila Mariana Praça Monteiro dos Sa...</td>\n",
       "      <td>Mon Oct 01 14:12:01 +0000 2018</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1047329264943751169</td>\n",
       "      <td>@FalleNCS @BrasilGameShow quero 1x1 de scout. ...</td>\n",
       "      <td>Wed Oct 03 03:35:29 +0000 2018</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1045443874947313665</td>\n",
       "      <td>mais uma analógica no correio à minha espera :...</td>\n",
       "      <td>Thu Sep 27 22:43:37 +0000 2018</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1040484298711814144</td>\n",
       "      <td>Em festa de posse como presidente do STF, Toff...</td>\n",
       "      <td>Fri Sep 14 06:16:02 +0000 2018</td>\n",
       "      <td>folha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1045411876887306240</td>\n",
       "      <td>@thethiagor @jubsilva @GSCISA @GrupoMulheRIs A...</td>\n",
       "      <td>Thu Sep 27 20:36:28 +0000 2018</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         tweet_text  \\\n",
       "0  1046764676707753987  Apartamento Vila Mariana Praça Monteiro dos Sa...   \n",
       "1  1047329264943751169  @FalleNCS @BrasilGameShow quero 1x1 de scout. ...   \n",
       "2  1045443874947313665  mais uma analógica no correio à minha espera :...   \n",
       "3  1040484298711814144  Em festa de posse como presidente do STF, Toff...   \n",
       "4  1045411876887306240  @thethiagor @jubsilva @GSCISA @GrupoMulheRIs A...   \n",
       "\n",
       "                       tweet_date query_used  \n",
       "0  Mon Oct 01 14:12:01 +0000 2018         :)  \n",
       "1  Wed Oct 03 03:35:29 +0000 2018         :)  \n",
       "2  Thu Sep 27 22:43:37 +0000 2018         :)  \n",
       "3  Fri Sep 14 06:16:02 +0000 2018      folha  \n",
       "4  Thu Sep 27 20:36:28 +0000 2018         :)  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listagem das primeiras linhas do dataframe\n",
    "\n",
    "dfs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7d961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5811661",
   "metadata": {},
   "source": [
    "## 2. Pré-processamento e transformações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a59eb",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Tratamento de variáveis**\n",
    "\n",
    "- Criação da variável **filtered_words**, onde o texto original (tweet_text) será submetido a tratamentos para melhorar a classificação do modelo;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **join_f_words**, para concatenar as palavras do coluna **filtered_words**;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **num_words_text**, para contar a quantidade de palavras no texto principal;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **num_words_join**, para contar a quantirade de palavrvas após tratamento;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **diff_in_words**, para contar a diferença de palavras entre o texto principal e o tratado;<br>\n",
    "\n",
    "\n",
    "- Exclusão de variáveis que entendemos não ser relevante para o modelo<br>\n",
    "    **id**: ID único para o tweet<br>\n",
    "    **tweet_date**: Data da publicação no Twitter<br>\n",
    "    **query_used**: Filtro utilizado para buscar a publicação<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d247977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula com o tratamendo dos tweets leva em média 10 min, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Cria uma nova variável utilizando funções para tratamento das palavras do texto\n",
    "df['filtered_words'] = df['tweet_text'].apply(lambda w: nlp_tratar_texto(w))\n",
    "dfs['filtered_words'] = dfs['tweet_text'].apply(lambda w: nlp_tratar_texto(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0afad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma nova variável concatenando os tokens gerados pelo tratamento das palavras gerando um novo texto reduzido\n",
    "\n",
    "df['join_f_words'] = df['filtered_words'].apply(lambda w: ' '.join(w))\n",
    "dfs['join_f_words'] = dfs['filtered_words'].apply(lambda w: ' '.join(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9eec6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma nova variável com a quantidade de palavras da variável join_f_words\n",
    "\n",
    "df['num_words_text'] = df['tweet_text'].apply(lambda w:len(str(w).split()))\n",
    "dfs['num_words_text'] = dfs['tweet_text'].apply(lambda w:len(str(w).split()))\n",
    "\n",
    "# Cria uma nova variável com a quantidade de palavras da variável join_f_words\n",
    "df['num_words_join'] = df['join_f_words'].apply(lambda w:len(str(w).split()))\n",
    "dfs['num_words_join'] = dfs['join_f_words'].apply(lambda w:len(str(w).split()))\n",
    "\n",
    "# Cria uma nova variável com a diferença de quantidade de palavras\n",
    "df['diff_in_words'] = df['num_words_text'] - df['num_words_join']\n",
    "dfs['diff_in_words'] = dfs['num_words_text'] - dfs['num_words_join']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3effc2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Este processo foi comentado, pois a normalização do texto utilizando os tratamentos da  biblioteca enelvo \n",
    "# não melhoraram expressivamente a acurácia dos modelos testados e desbalancea a quantidade de tweets por sentimento\n",
    "# apesar de uma variação baixa entre 3% a 5%.\n",
    "\n",
    "# O processamento desta célula com o tratamendo dos tweets utilizando o biblioteca enelvo leva em média 2 horas, \n",
    "# em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Cria uma nova variável normalizando os tokens do novo texto reduzido\n",
    "#df['normalize_words'] = df['tweet_text'].apply(lambda w: nlp_tratar_texto(w, normalize=True))\n",
    "#dfs['normalize_words'] = dfs['tweet_text'].apply(lambda w: nlp_tratar_texto(w, normalize=True))\n",
    "\n",
    "# Cria uma nova variável concatenando os tokens gerados pelo tratamento das palavras gerando um novo texto reduzido\n",
    "#df['join_n_words'] = df['normalize_words'].apply(lambda w: ' '.join(w))\n",
    "#dfs['join_n_words'] = dfs['normalize_words'].apply(lambda w: ' '.join(w))\n",
    "\n",
    "# Retirando as linhas que ficaram sem texto\n",
    "#df = df[np.where((df['normalize_words'].str.len()>1), True, False)].copy()\n",
    "#dfs = dfs[np.where((dfs['normalize_words'].str.len()>1), True, False)].copy()\n",
    "\n",
    "# Reindexando os indices do dataframe\n",
    "#df.reset_index(drop=True, inplace=True)\n",
    "#dfs.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Cria uma nova variável com a quantidade de palavras da variável normalize_words\n",
    "#df['num_words_norm'] = df['join_n_words'].apply(lambda w:len(str(w).split()))\n",
    "#dfs['num_words_norm'] = dfs['join_n_words'].apply(lambda w:len(str(w).split()))\n",
    "\n",
    "# Cria uma nova variável com a diferença de quantidade de palavras\n",
    "#df['diff_in_words_norm'] = df['num_words_text'] - df['num_words_norm']\n",
    "#dfs['diff_in_words_norm'] = dfs['num_words_text'] - dfs['num_words_norm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a43d679f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>join_f_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rio elege maior bancada policial de sua história https://t.co/sGXnhZKrHx https://t.co/Mcgiz70jPF</td>\n",
       "      <td>[rio, eleger, maior, bancada, policial, história]</td>\n",
       "      <td>rio eleger maior bancada policial história</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fiquei tão triste quando eu vi o preço da câmera :((((</td>\n",
       "      <td>[ficar, triste, vir, preço, câmera]</td>\n",
       "      <td>ficar triste vir preço câmera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Para Theresa May, seu plano para o Brexit é a única opção https://t.co/epl39YD9bj</td>\n",
       "      <td>[theresa, may, plano, brexit, única, opção]</td>\n",
       "      <td>theresa may plano brexit única opção</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caralho eu quero proteger a danielly em um pote tadinhaa :(</td>\n",
       "      <td>[caralho, querer, proteger, danielly, pote, tadinhaa]</td>\n",
       "      <td>caralho querer proteger danielly pote tadinhaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@SiCaetano_ viva o caos :)</td>\n",
       "      <td>[vivo, caos]</td>\n",
       "      <td>vivo caos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94995</th>\n",
       "      <td>Cuba e defensor de direitos humanos se unem contra chefe da OEA, intervenção militar na Venezuela. https://t.co/Lo2RvIgFBA https://t.co/CiPddCuRvw</td>\n",
       "      <td>[cuba, defensor, direitos, humanos, unir, contra, chefe, oea, intervenção, militar, venezuela]</td>\n",
       "      <td>cuba defensor direitos humanos unir contra chefe oea intervenção militar venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94996</th>\n",
       "      <td>#Oportunidade ➡️ Venha fazer parte da nossa equipe! Vagas abertas para alunos de Administração. Envie seu currículo e comprovante de matrícula para análise prévia até às 12h do dia 24/08, para o e-mail: vagasestagio@sistemafieto.com.br 😉 https://t.co/qvdFYeJh9I</td>\n",
       "      <td>[oportunidade, vir, fazer, parte, equipe, vagas, aberto, alunos, administração, enviar, currículo, comprovante, matrícula, análise, prévia, dia, mail]</td>\n",
       "      <td>oportunidade vir fazer parte equipe vagas aberto alunos administração enviar currículo comprovante matrícula análise prévia dia mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94997</th>\n",
       "      <td>@96syoo EU SEI 😭😭 é por isso que significa muito!! To feliz demais, eu amo ela :( e aqui da pra ver que ela deixa a bandeira na frente do palco e sai correndo pra pegar garrafa de água mas depois disso ela pegou de novo 😂 https://t.co/82oPAXYVNC</td>\n",
       "      <td>[saber, significar, to, feliz, demais, amar, aqui, ver, deixar, bandeira, frente, palco, sair, correr, pegar, garrafa, água, disso, pegar, novo]</td>\n",
       "      <td>saber significar to feliz demais amar aqui ver deixar bandeira frente palco sair correr pegar garrafa água disso pegar novo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94998</th>\n",
       "      <td>@louistsexhes N te conheço mas posta :D</td>\n",
       "      <td>[n, conhecer, posto, d]</td>\n",
       "      <td>n conhecer posto d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94999</th>\n",
       "      <td>meu deus :( https://t.co/BlXazxZeKq</td>\n",
       "      <td>[deus]</td>\n",
       "      <td>deus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                  tweet_text  \\\n",
       "0      Rio elege maior bancada policial de sua história https://t.co/sGXnhZKrHx https://t.co/Mcgiz70jPF                                                                                                                                                                        \n",
       "1      fiquei tão triste quando eu vi o preço da câmera :((((                                                                                                                                                                                                                  \n",
       "2      Para Theresa May, seu plano para o Brexit é a única opção https://t.co/epl39YD9bj                                                                                                                                                                                       \n",
       "3      caralho eu quero proteger a danielly em um pote tadinhaa :(                                                                                                                                                                                                             \n",
       "4      @SiCaetano_ viva o caos :)                                                                                                                                                                                                                                              \n",
       "...                           ...                                                                                                                                                                                                                                              \n",
       "94995  Cuba e defensor de direitos humanos se unem contra chefe da OEA, intervenção militar na Venezuela. https://t.co/Lo2RvIgFBA https://t.co/CiPddCuRvw                                                                                                                      \n",
       "94996  #Oportunidade ➡️ Venha fazer parte da nossa equipe! Vagas abertas para alunos de Administração. Envie seu currículo e comprovante de matrícula para análise prévia até às 12h do dia 24/08, para o e-mail: vagasestagio@sistemafieto.com.br 😉 https://t.co/qvdFYeJh9I   \n",
       "94997  @96syoo EU SEI 😭😭 é por isso que significa muito!! To feliz demais, eu amo ela :( e aqui da pra ver que ela deixa a bandeira na frente do palco e sai correndo pra pegar garrafa de água mas depois disso ela pegou de novo 😂 https://t.co/82oPAXYVNC                   \n",
       "94998  @louistsexhes N te conheço mas posta :D                                                                                                                                                                                                                                 \n",
       "94999  meu deus :( https://t.co/BlXazxZeKq                                                                                                                                                                                                                                     \n",
       "\n",
       "                                                                                                                                               filtered_words  \\\n",
       "0      [rio, eleger, maior, bancada, policial, história]                                                                                                        \n",
       "1      [ficar, triste, vir, preço, câmera]                                                                                                                      \n",
       "2      [theresa, may, plano, brexit, única, opção]                                                                                                              \n",
       "3      [caralho, querer, proteger, danielly, pote, tadinhaa]                                                                                                    \n",
       "4      [vivo, caos]                                                                                                                                             \n",
       "...             ...                                                                                                                                             \n",
       "94995  [cuba, defensor, direitos, humanos, unir, contra, chefe, oea, intervenção, militar, venezuela]                                                           \n",
       "94996  [oportunidade, vir, fazer, parte, equipe, vagas, aberto, alunos, administração, enviar, currículo, comprovante, matrícula, análise, prévia, dia, mail]   \n",
       "94997  [saber, significar, to, feliz, demais, amar, aqui, ver, deixar, bandeira, frente, palco, sair, correr, pegar, garrafa, água, disso, pegar, novo]         \n",
       "94998  [n, conhecer, posto, d]                                                                                                                                  \n",
       "94999  [deus]                                                                                                                                                   \n",
       "\n",
       "                                                                                                                               join_f_words  \n",
       "0      rio eleger maior bancada policial história                                                                                            \n",
       "1      ficar triste vir preço câmera                                                                                                         \n",
       "2      theresa may plano brexit única opção                                                                                                  \n",
       "3      caralho querer proteger danielly pote tadinhaa                                                                                        \n",
       "4      vivo caos                                                                                                                             \n",
       "...          ...                                                                                                                             \n",
       "94995  cuba defensor direitos humanos unir contra chefe oea intervenção militar venezuela                                                    \n",
       "94996  oportunidade vir fazer parte equipe vagas aberto alunos administração enviar currículo comprovante matrícula análise prévia dia mail  \n",
       "94997  saber significar to feliz demais amar aqui ver deixar bandeira frente palco sair correr pegar garrafa água disso pegar novo           \n",
       "94998  n conhecer posto d                                                                                                                    \n",
       "94999  deus                                                                                                                                  \n",
       "\n",
       "[95000 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Altera o tamanho da visualização das colunas para demonstrar todo o conteúdo\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "\n",
    "# Mostra o conteúdo das variáveis tratadas\n",
    "#df[['tweet_text', 'filtered_words', 'join_f_words', 'normalize_words', 'join_n_words']]\n",
    "df[['tweet_text', 'filtered_words', 'join_f_words']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e0f72",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões**\n",
    "\n",
    "Submetemos a variável tweet_text ao tratamento de texto:\n",
    "\n",
    "- Remoção de endereços de sites;\n",
    "- Remoção de e-mails e usuários do tweet;\n",
    "- Remoção de caracteres que não são letras;\n",
    "- Remoção de dígitos;\n",
    "- Transformação de todas as palavras para minúsculas;\n",
    "- Tokenização do texto;\n",
    "- Remoção de stopwords (portugues);\n",
    "- \"Lemmatização\" do texto;\n",
    "\n",
    "Após o tratamento do texto foram criadas duas variáveis para gravar as informações do texto tratado, entendemos que estas variáveis estejam mais \"limpas\" para utilização na modelagem.\n",
    "\n",
    "- **join_f_words** que contem o texto tratado com o processamento descrito acima;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c927f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a232e43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame gravado com successo.\n"
     ]
    }
   ],
   "source": [
    "# Grava um novo CSV com as novas colunas\n",
    "\n",
    "# Definindo o nome do arquivo\n",
    "file_name = './dados/train/Train3Classes_with_Tokens.csv'\n",
    "  \n",
    "# Salvando o CSV\n",
    "try:\n",
    "    df.to_csv(file_name, index=False)\n",
    "    print('DataFrame gravado com successo.')\n",
    "except:\n",
    "    print(\"Ocorreu um erro na gravação.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6b003b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe original - df\n",
      "Quantidade de linhas vazias ...: 364\n"
     ]
    }
   ],
   "source": [
    "# Verificando quais linhas não apresentam valor após o tratamento do texto\n",
    "\n",
    "# Quantidade de linhas vazias\n",
    "qtd, _ = df[np.where((df['filtered_words'].str.len()<1), True, False)].shape\n",
    "\n",
    "print('Dataframe original - df')\n",
    "print(f'Quantidade de linhas vazias ...: {qtd}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d610ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirando as linhas que ficaram sem texto\n",
    "\n",
    "dfc = df[np.where((df['filtered_words'].str.len()>1), True, False)].copy()\n",
    "\n",
    "# Reindexando os indices do dataframe\n",
    "dfc.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "327e65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusão de variáveis que entendemos não ser relevante para o modelo\n",
    "\n",
    "# id: ID único para o tweet  \n",
    "# tweet_date: Data da publicação no Twitter  \n",
    "# query_used: Filtro utilizado para buscar a publicação\n",
    "\n",
    "# Excluindo colunas\n",
    "DeleteList=['id', 'tweet_date', 'query_used']\n",
    "\n",
    "# Novo dataframe dfc (df copy)\n",
    "dfc = df.drop(DeleteList, axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37f1be2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95000 entries, 0 to 94999\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   tweet_text      95000 non-null  object\n",
      " 1   sentiment       95000 non-null  int64 \n",
      " 2   filtered_words  95000 non-null  object\n",
      " 3   join_f_words    95000 non-null  object\n",
      " 4   num_words_text  95000 non-null  int64 \n",
      " 5   num_words_join  95000 non-null  int64 \n",
      " 6   diff_in_words   95000 non-null  int64 \n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "dfc.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50e7cc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataframe tem 7 colunas e 95000 linhas.\n",
      "Existem 0 colunas que têm valores faltantes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores faltantes</th>\n",
       "      <th>% de Valores Totais</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Valores faltantes, % de Valores Totais, Data Type]\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando os valores nulos do dataframe\n",
    "\n",
    "missing_values_table(dfc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2305832",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "O dataframe é composto por 7 colunas e 95.000 registros.\n",
    "\n",
    "A tabela acima não apresenta valores faltantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a785713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusão dos registros faltantes\n",
    "\n",
    "dfc.dropna() \n",
    "\n",
    "# Reindexando os indices do dataframe\n",
    "dfc.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2887d4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JOHNNY~1.HOR\\AppData\\Local\\Temp/ipykernel_20040/2012888396.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Quantidade de linhas duplicadas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mqtd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dataframe original - df'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6199\u001b[0m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6200\u001b[1;33m         \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         ids = get_group_index(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(vals)\u001b[0m\n\u001b[0;32m   6171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6172\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6173\u001b[1;33m             \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6174\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[1;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[0mna_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m         codes, uniques = factorize_array(\n\u001b[0m\u001b[0;32m    762\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize_hint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mfactorize_array\u001b[1;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m     uniques, codes = table.factorize(\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m     )\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtlc, qtcc = dfc.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "qtd, _ = dfc[dfc.duplicated()].shape\n",
    "\n",
    "print('Dataframe original - df')\n",
    "print(f'Quantidade de linhas...........: {qtl}')\n",
    "print(f'Quantidade de colunas..........: {qtc}')\n",
    "\n",
    "print('\\nDataframe tratado - dfc')\n",
    "print(f'Quantidade de linhas...........: {qtlc}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtd}')\n",
    "print(f'Quantidade de colunas..........: {qtcc}')\n",
    "\n",
    "print (f'\\nPercentual de registros retirados: {(100  * (qtl-qtlc) / qtl):.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3416ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando linhas duplicadas\n",
    "\n",
    "# Seleciona as linhas duplicadas no dataframe baseado em todas as colunas\n",
    "#display(dfc[dfc.duplicated(keep='first')].sort_values(by=list(dfc.columns)))\n",
    "\n",
    "print(\"\\nLinhas duplicadas:\")\n",
    "print(dfc[dfc.duplicated()].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa0cef9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "Após tratamento do dataframe identificamos que diversos texto possuem as mesmas palavras e como o percentual de duplicidade é baixo optamos em retirar as linhas repetidas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551a193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832514dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando os dataframes\n",
    "\n",
    "# Criando copia do dataframe tratado para manter todos os registros \n",
    "dfc_copy = dfc.copy()\n",
    "\n",
    "# Convertendo int 64 para 16\n",
    "dfc['sentiment'] = dfc['sentiment'].astype(np.int16)\n",
    "\n",
    "# Excluindo os linhas duplicadas\n",
    "dfc = dfc.drop_duplicates(keep='first').copy()\n",
    "dfc.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtlc, qtcc = dfc.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "qtd, _ = dfc[dfc.duplicated()].shape\n",
    "\n",
    "\n",
    "print('Dataframe original - df')\n",
    "print(f'Quantidade de linhas...........: {qtl}')\n",
    "print(f'Quantidade de colunas..........: {qtc}')\n",
    "\n",
    "print('\\nDataframe tratado - dfc')\n",
    "print(f'Quantidade de linhas...........: {qtlc}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtd}')\n",
    "print(f'Quantidade de colunas..........: {qtcc}')\n",
    "\n",
    "print (f'\\nPercentual de registros retirados: {(100  * (qtl-qtlc) / qtl):.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b6787",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "- Tratamos a variável **tweet_text** para criar a variável auxiliar **filtered_words**, onde os textos foram submetidos a tratamentos para definir as palavras chaves de sentimento;<br>\n",
    "\n",
    "\n",
    "- Criamos a variável **join_f_words**, para concatenar as palavras do coluna **filtered_words**;<br>\n",
    "\n",
    "\n",
    "- Criamos um novo dataframe **dfc**, retirando as variáveis **id, tweet_date, query_used**, pois aceitamos que as variáveis não são relevantes para a modelagem;<br>\n",
    "\n",
    "\n",
    "- Retiramos todos os registros que estavam duplicados;<br>\n",
    "\n",
    "\n",
    "Com esses tratamentos acreditamos que o novo dataframe esta melhor preparado para análise exploratória de dados e modelagem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cdcd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7682d5be",
   "metadata": {},
   "source": [
    "## 3. Análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4baeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "dfc.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b3e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listagem das primeiras linhas do dataframe\n",
    "\n",
    "dfc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cffc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14f4b52d",
   "metadata": {},
   "source": [
    "### Analisando Sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de20fc",
   "metadata": {},
   "source": [
    "**sentiment**\n",
    "- sentiment: 0, se negativo; 1, se positivo; 2, se neutro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de sentimentos\n",
    "\n",
    "Counter(dfc['sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b796df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição de tweets\n",
    "\n",
    "temp = dfc.groupby('sentiment').count()['tweet_text'].reset_index().sort_values(by='tweet_text',ascending=False)\n",
    "temp.style.background_gradient(cmap=cmap_colors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72634775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição da variavel sentiment\n",
    "\n",
    "col = 'sentiment'\n",
    "\n",
    "total = len(dfc)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "g = sns.countplot(x=col, data=dfc, palette=colors)\n",
    "g.set_title(f\"Distribuição da variável {col}\")\n",
    "g.set_xlabel(f\"{col}\")\n",
    "g.set_ylabel(\"Quantidade\")\n",
    "sizes=[]\n",
    "for p in g.patches:\n",
    "    height = p.get_height()\n",
    "    sizes.append(height)\n",
    "    g.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format((height/total)*100),\n",
    "            ha=\"center\", fontsize=14) \n",
    "g.set_ylim(0, max(sizes) * 1.15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488bcc2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "Analisando a variável **sentiment** podemos constatar que o nosso dataframe contém quantidades de tweets balanceados, diminuindo a tendência do modelo para algum dos resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84e207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45009fc3",
   "metadata": {},
   "source": [
    "### Analisando as palavras dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0abaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas nos textos\n",
    "\n",
    "top = Counter([item for sublist in dfc['filtered_words'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Palavras','Quantidade']\n",
    "temp.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b58fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando a quantidade de palavras mais utilizadas\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp, palette=colors)\n",
    "g.set_title(f\"As 20 palavras mais utilizadas nos textos\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83261e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando a quantidade de palavras mais utilizadas\n",
    "\n",
    "fig = px.treemap(temp, path=['Palavras'], values='Quantidade',title='As 20 palavras mais utilizadas nos textos')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495101ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da8d21a4",
   "metadata": {},
   "source": [
    "### Palavras mais utilizadas por Sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9281a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataframes por sentimentos\n",
    "\n",
    "# negativo\n",
    "Negative_sent = dfc[dfc['sentiment']==0]\n",
    "Negative_sent.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# positivo\n",
    "Positive_sent = dfc[dfc['sentiment']==1]\n",
    "Positive_sent.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# neutro\n",
    "Neutral_sent = dfc[dfc['sentiment']==2]\n",
    "Neutral_sent.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista auxiliar com todas as palavras do dataframe\n",
    "\n",
    "raw_text = [word for word_list in dfc['filtered_words'] for word in word_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e30c327",
   "metadata": {},
   "source": [
    "#### Sentimentos Negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas em sentimentos negativos\n",
    "\n",
    "top = Counter([item for sublist in Negative_sent['filtered_words'] for item in sublist])\n",
    "temp_negative = pd.DataFrame(top.most_common(20))\n",
    "temp_negative = temp_negative.iloc[1:,:]\n",
    "temp_negative.columns = ['Palavras','Quantidade']\n",
    "temp_negative.style.background_gradient(cmap='Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentação da quantidade de palavras mais utilizadas em sentimentos negativos\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp_negative, palette=colors)\n",
    "g.set_title(f\"Palavras mais utilizadas nos textos negativos\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# As 20 palavras utilizadas apenas para o sentimento negativo\n",
    "\n",
    "Unique_Negative= words_unique(0, 20, raw_text)\n",
    "\n",
    "print('As 20 palavras mais utilizadas apenas em Tweets negativos:')\n",
    "Unique_Negative.style.background_gradient(cmap='Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As 20 palavras utilizadas apenas para o sentimento negativos\n",
    "\n",
    "fig = px.treemap(Unique_Negative, path=['words'], values='count',title='As 20 palavras mais utilizadas apenas em Tweets negativos')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85d56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d950de81",
   "metadata": {},
   "source": [
    "#### Sentimentos Positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f27e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas em sentimentos positivos\n",
    "\n",
    "top = Counter([item for sublist in Positive_sent['filtered_words'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(20))\n",
    "temp_positive.columns = ['Palavras','Quantidade']\n",
    "temp_positive.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentação da quantidade de palavras mais utilizadas em sentimentos positivos\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp_positive, palette=colors)\n",
    "g.set_title(f\"Palavras mais utilizadas nos textos positivos\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a152e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# As 20 palavras utilizadas apenas para o sentimento positivo\n",
    "\n",
    "Unique_Positive = words_unique(1, 20, raw_text)\n",
    "\n",
    "print('As 20 palavras mais utilizadas apenas em Tweets positivos:')\n",
    "Unique_Positive.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff9213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentação das palavras utilizadas em sentimentos positivos\n",
    "\n",
    "fig = px.treemap(Unique_Positive, path=['words'], values='count',title='As 20 palavras mais utilizadas apenas em Tweets positivos')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309fdcb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cef58502",
   "metadata": {},
   "source": [
    "#### Sentimentos Neutros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas em sentimentos neutros\n",
    "\n",
    "top = Counter([item for sublist in Neutral_sent['filtered_words'] for item in sublist])\n",
    "temp_neutral = pd.DataFrame(top.most_common(20))\n",
    "temp_neutral = temp_neutral.loc[1:,:]\n",
    "temp_neutral.columns = ['Palavras','Quantidade']\n",
    "temp_neutral.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ca74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentação da quantidade de palavras mais utilizadas em sentimentos neutros\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp_neutral, palette=colors)\n",
    "g.set_title(f\"Palavras mais utilizadas nos textos neutros\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d396ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# As 20 palavras utilizadas apenas para o sentimento neutro\n",
    "\n",
    "Unique_Neutral= words_unique(2, 20, raw_text)\n",
    "\n",
    "print('As 20 palavras utilizadas apenas em Tweets neutros:')\n",
    "Unique_Neutral.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentação das palavras utilizadas em sentimentos neutros\n",
    "\n",
    "fig = px.treemap(Unique_Neutral, path=['words'], values='count',title='As 20 palavras mais utilizadas apenas em Tweets neutros')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92502f5",
   "metadata": {},
   "source": [
    "#### WordClouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ae886e",
   "metadata": {},
   "source": [
    "**Sentimentos negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud para Tweets negativos\n",
    "\n",
    "text = ' '.join(Negative_sent['join_f_words'])\n",
    "plot_wordcloud(text, title = 'WordCloud Tweets negativos', backcolor = 'white', clrmap = 'Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d777e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7610b55",
   "metadata": {},
   "source": [
    "**Sentimentos positivos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud para Tweets positivos\n",
    "\n",
    "text = ' '.join(Positive_sent['join_f_words'])\n",
    "plot_wordcloud(text, title = 'WordCloud Tweets positivos', backcolor = 'white', clrmap = 'Greens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a30ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6656fc3f",
   "metadata": {},
   "source": [
    "**Sentimentos neutros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545fa566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud para Tweets neutros\n",
    "\n",
    "text = ' '.join(Neutral_sent['join_f_words'])\n",
    "plot_wordcloud(text, title = 'WordCloud Tweets neutros', backcolor = 'white', clrmap = 'PuBu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73fa2a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "- Podemos ver que as mesmas palavras são comuns nos três segmentos;\n",
    "\n",
    "\n",
    "- Isso é interessante porque algumas palavras são mais de natureza negativa e outras palavras são mais de natureza positiva, o que significa que os nossos dados podem estar incorretamente etiquetados;\n",
    "\n",
    "\n",
    "- Olhando para as palavras únicas de cada sentimento, temos mais clareza sobre os dados, estas palavras únicas são determinantes para o sentimento dos tweets;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082c8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72070112",
   "metadata": {},
   "source": [
    "## 4. Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb77b8",
   "metadata": {},
   "source": [
    "### Separando conjunto de dados Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65486f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A nossa base de dados tem 93.793 mil linhas e a quantidade de palavras disponíveis nos textos é muito grande. \n",
    "# Para evitar problemas de alocação de memória, processamento dos textos e modelagem, iremos criar uma amostra com 50% da base:\n",
    "\n",
    "# Caso o notebook apresente problemas de alocação de memória, favor diminuir o percentual da amostra dos dados.\n",
    "\n",
    "dfm = dfc.sample(frac=0.5, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos dividir os nossos dados numa matriz X que contém as características a treinar, \n",
    "# e uma matriz y com a variável alvo, neste caso a coluna covid_res. \n",
    "\n",
    "X = dfm['join_f_words']\n",
    "y = dfm['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86beb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos dividir os dados num conjunto de Train e num conjunto de Test. \n",
    "# Iremos treinar o modelo no conjunto de treino e depois utilizaremos o conjunto de testes para avaliar o modelo\n",
    "\n",
    "random_seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade total da variável \"target\" (sentiment)\n",
    "\n",
    "y.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a27f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade separada para o conjunto de treino inicial\n",
    "\n",
    "y_train.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade separada para o conjunto de teste inicial\n",
    "\n",
    "y_test.value_counts().sort_index()#(normalize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8fdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "191bda52",
   "metadata": {},
   "source": [
    "### Processando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de modelos para testes\n",
    "\n",
    "list_models = [\n",
    "    {'model_name': 'Dummy Classifier uniform',\n",
    "     'estimator' : DummyClassifier(strategy='uniform', random_state=random_seed)},\n",
    "    {'model_name': 'Naive Bayes Gaussian',\n",
    "     'estimator' : GaussianNB()},\n",
    "    {'model_name': 'Multinomial Naive Bayes',\n",
    "     'estimator' : MultinomialNB()},\n",
    "    {'model_name': 'Bernoulli Naive Bayes',\n",
    "     'estimator' : BernoulliNB()},\n",
    "    {'model_name': 'Linear Support Vector Machine',\n",
    "     'estimator' : LinearSVC(random_state=random_seed)},\n",
    "    {'model_name': 'Logistic Regression',\n",
    "     'estimator' : LogisticRegression(n_jobs=-1, random_state=random_seed)},\n",
    "    {'model_name': 'Stochastic Gradient Descent Classifier',\n",
    "     'estimator' : SGDClassifier(n_jobs=-1, loss='modified_huber',random_state=random_seed)},\n",
    "    {'model_name': 'LightGBM',\n",
    "     'estimator' : LGBMClassifier(random_state=random_seed)}    \n",
    "]\n",
    "\n",
    "# Os modelos abaixo foram retirados por apresentarem tempo de processamento superior 20 minutos com sample de 50% \n",
    "# e apresentarem resultados muito similares com os modelos escolhidos\n",
    "\n",
    "#{'model_name': 'Decision Tree',\n",
    "# 'estimator' : DecisionTreeClassifier(random_state=random_seed)},\n",
    "#{'model_name': 'Random Forest',\n",
    "# 'estimator' : RandomForestClassifier(random_state=random_seed)}, \n",
    "#{'model_name': 'AdaBoost',\n",
    "# 'estimator' : AdaBoostClassifier(random_state=random_seed)},\n",
    "#{'model_name': 'GradientBoosting',\n",
    "# 'estimator' : GradientBoostingClassifier(random_state=random_seed)},\n",
    "#{'model_name': 'XGBoost',\n",
    "# 'estimator' : XGBClassifier(random_state=random_seed)}\n",
    "#{'model_name': 'Support Vector Machine',\n",
    "# 'estimator' : SVC(random_state=random_seed)},\n",
    "#{'model_name': 'KNN (k-nearest neighbor)',\n",
    "# 'estimator' : KNeighborsClassifier(n_neighbors=3)},\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8f1aa",
   "metadata": {},
   "source": [
    "#### Técnica Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d833f",
   "metadata": {},
   "source": [
    "##### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac91f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9df319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo com os conjuntos de dados de treinamento \n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train).toarray()\n",
    "X_test_cv = cv.transform(X_test).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce44eb",
   "metadata": {},
   "source": [
    "**Processando modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfcc793",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 16 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Processando os modelos baseado na list_models\n",
    "score = []\n",
    "\n",
    "test_models (list_models,\n",
    "             \"model_name\",\n",
    "             \"estimator\",\n",
    "             \"CountVectorizer\",\n",
    "             X_train_cv,\n",
    "             X_test_cv,\n",
    "             y_train,\n",
    "             y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusão de objetos para liberar a memória utilizada\n",
    "\n",
    "del dfm, X, y, X_train_cv, X_test_cv\n",
    "\n",
    "#del dfm, X, y, X_train, X_test, y_train, y_test, X_train_cv, X_test_cv\n",
    "#del tfidf, X_train_tfidf, X_test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef0d7f",
   "metadata": {},
   "source": [
    "##### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bb8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciando TF-IDF\n",
    "\n",
    "tfidf = TfidfVectorizer(use_idf = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo com os conjuntos de dados de treinamento \n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).todense()\n",
    "X_test_tfidf  = tfidf.transform(X_test).todense()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f5592",
   "metadata": {},
   "source": [
    "**Processando modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Processando os modelos baseado na list_models\n",
    "\n",
    "test_models (list_models,\n",
    "             \"model_name\",\n",
    "             \"estimator\",\n",
    "             \"TF-IDF\",\n",
    "             X_train_tfidf,\n",
    "             X_test_tfidf,\n",
    "             y_train,\n",
    "             y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237eaa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusão de objetos para liberar a memória utilizada\n",
    "\n",
    "del tfidf, X_train_tfidf, X_test_tfidf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5946824",
   "metadata": {},
   "source": [
    "#### Técnica Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37804d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciando Word2Vec\n",
    "\n",
    "#w2v = Word2Vec(sentences=X_train, vector_size=500, min_count=5, workers=2)\n",
    "w2v = Word2Vec(sentences=X_train, vector_size=500, min_count=5, workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201bd1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando a classe de treinamento\n",
    "\n",
    "X_train_w2v_m = []\n",
    "X_train_w2v_s = []\n",
    "X_train_w2v_sn = []\n",
    "\n",
    "for phrase in X_train:\n",
    "    vecs = []\n",
    "    for word in phrase:\n",
    "        if word in w2v.wv.index_to_key:\n",
    "            vecs.append(w2v.wv.get_vector(word))\n",
    "            \n",
    "    if vecs:\n",
    "        soma = np.sum(vecs, axis=0)\n",
    "        media = soma/len(vecs)\n",
    "        soma_normalizada = soma / np.linalg.norm(soma)\n",
    "        \n",
    "        X_train_w2v_m.append(media)\n",
    "        X_train_w2v_s.append(soma)\n",
    "        X_train_w2v_sn.append(soma_normalizada)\n",
    "        \n",
    "    else:\n",
    "        X_train_w2v_m.append(np.zeros(w2v.vector_size))\n",
    "        X_train_w2v_s.append(np.zeros(w2v.vector_size))\n",
    "        X_train_w2v_sn.append(np.zeros(w2v.vector_size))\n",
    "    \n",
    "    \n",
    "X_train_w2v_m = np.array(X_train_w2v_m)\n",
    "X_train_w2v_s = np.array(X_train_w2v_s)\n",
    "X_train_w2v_sn = np.array(X_train_w2v_sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5965bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando a classe de teste\n",
    "\n",
    "X_test_w2v_m = []\n",
    "X_test_w2v_s = []\n",
    "X_test_w2v_sn = []\n",
    "\n",
    "for phrase in X_test:\n",
    "    vecs = []\n",
    "    for word in phrase:\n",
    "        if word in w2v.wv.index_to_key:\n",
    "            vecs.append(w2v.wv.get_vector(word))\n",
    "            \n",
    "    if vecs:\n",
    "        soma = np.sum(vecs, axis=0)\n",
    "        media = soma/len(vecs)\n",
    "        soma_normalizada = soma / np.linalg.norm(soma)\n",
    "        \n",
    "        X_test_w2v_m.append(media)\n",
    "        X_test_w2v_s.append(soma)\n",
    "        X_test_w2v_sn.append(soma_normalizada)\n",
    "        \n",
    "    else:\n",
    "        X_test_w2v_m.append(np.zeros(w2v.vector_size))\n",
    "        X_test_w2v_s.append(np.zeros(w2v.vector_size))\n",
    "        X_test_w2v_sn.append(np.zeros(w2v.vector_size))\n",
    "    \n",
    "    \n",
    "X_test_w2v_m = np.array(X_test_w2v_m)\n",
    "X_test_w2v_s = np.array(X_test_w2v_s)\n",
    "X_test_w2v_sn = np.array(X_test_w2v_sn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794b2e0",
   "metadata": {},
   "source": [
    "**Processando modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Processando os modelos baseado na list_models\n",
    "\n",
    "test_models (list_models,\n",
    "             \"model_name\",\n",
    "             \"estimator\",\n",
    "             \"Word2Vec\",\n",
    "             X_train_w2v_m,\n",
    "             X_test_w2v_m,\n",
    "             y_train,\n",
    "             y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9adf8",
   "metadata": {},
   "source": [
    "#### Técnica Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5abea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando Doc2Vec\n",
    "\n",
    "d2v = doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24983e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando a classe de treinamento e teste\n",
    "\n",
    "train_corpus = read_corpus(X_train)\n",
    "test_corpus = read_corpus(X_test, tokens_only=True)\n",
    "\n",
    "d2v.build_vocab(train_corpus)\n",
    "\n",
    "d2v.train(train_corpus, total_examples=d2v.corpus_count, epochs=d2v.epochs)\n",
    "\n",
    "X_train_d2v = np.array(list(map(d2v.infer_vector, X_train)))\n",
    "X_test_d2v = np.array(list(map(d2v.infer_vector, X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21aaa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c09c7a",
   "metadata": {},
   "source": [
    "**Processando modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54820cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O processamento desta célula com o processamento dos modelos leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Processando os modelos baseado na list_models\n",
    "\n",
    "%%time\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Processando os modelos baseado na list_models\n",
    "\n",
    "test_models (list_models,\n",
    "             \"model_name\",\n",
    "             \"estimator\",\n",
    "             \"Doc2Vec\",\n",
    "             X_train_w2v_m,\n",
    "             X_test_w2v_m,\n",
    "             y_train,\n",
    "             y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac10e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e083d432",
   "metadata": {},
   "source": [
    "#### Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfcfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conmparação das pontuações após técnicas de balanceamento\n",
    "# Ordenando a pontuação\n",
    "score.sort(key = lambda y:y[2],reverse =True)\n",
    "\n",
    "# Exibindo a pontuação\n",
    "print(\"Comparação da Acurácia dos modelos: \")\n",
    "pd.DataFrame (score, columns = ['Model', 'Tool', 'Accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9646d853",
   "metadata": {},
   "source": [
    "## 5. Conclusões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c7950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6114f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
