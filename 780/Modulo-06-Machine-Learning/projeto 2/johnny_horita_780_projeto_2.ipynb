{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362c03d1",
   "metadata": {},
   "source": [
    "# Projeto 2 - NLP\n",
    "\n",
    "-----\n",
    "\n",
    "Nome:  Johnny Hideki Horita <br>\n",
    "Turma: 780"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517a372",
   "metadata": {},
   "source": [
    "Os segundo projeto do módulo de Machine Learning será focado no processamento de linguagem natural! Usaremos os algoritmos aprendidos e as técnicas vistas na segunda parte do curso para extrairmos informações relevantes de texto. Mais precisamente, de publicações no Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a3a98",
   "metadata": {},
   "source": [
    "## Os Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d5657",
   "metadata": {},
   "source": [
    "Utilizaremos um Dataset obtido do Twitter com 100K postagens entre os dias 01/08/2018 e 20/10/2018. Cada postagem é classificada como **positiva**, **negativa** ou **neutra**.  \n",
    "\n",
    "Dois arquivos serão disponilizados para o desenvolvimento dos modelos, um para treino/validação e outro para submissão. Os arquivos se encontram na pasta */Dados/train* e */Dados/subm*, respectivamente.\n",
    "\n",
    "Descrição das colunas:\n",
    "\n",
    "- **id**: ID único para o tweet  \n",
    "- **tweet_text**: Texto da publicação no Twitter  \n",
    "- **tweet_date**: Data da publicação no Twitter  \n",
    "- **sentiment**: 0, se negativo; 1, se positivo; 2, se neutro  \n",
    "- **query_used**: Filtro utilizado para buscar a publicação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc86eb5",
   "metadata": {},
   "source": [
    "## O Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e1f6f",
   "metadata": {},
   "source": [
    "Você deverá desenvolver um modelo para detectar o sentimento de uma publicação do Twitter a classificando em uma das três categorias: **positiva**, **negativa** ou **neutra**. O texto da publicação está disponível na coluna \"tweet_text\". Teste pelo menos 3 técnicas de NLP diferentes e escolha a métrica de avaliação que julgar mais pertinente.  \n",
    "\n",
    "Escolha o melhor modelo e gere uma base a partir dos dados de submissão, que estão no caminho ```Dados/subm/Subm3Classes.csv```, com o seguinte formato:\n",
    "\n",
    "\n",
    "|id|sentiment_predict\n",
    "|-|-|\n",
    "|12123232|0\n",
    "|323212|1\n",
    "|342235|2\n",
    "\n",
    "Salve essa tabela como um arquivo csv com o nome ```<nome>_<sobrenome>_nlp_degree.csv``` e submeta-o como parte da entrega final do projeto.  \n",
    "\n",
    "Para ajudar no desenvolvimento, é possível dividir o projeto em algumas fases:\n",
    "\n",
    "- **Análise de consistência dos dados**: analise se os dados estão fazendo sentido, se os campos estão completos e se há dados duplicados ou faltantes. Se julgar necessário, trate-os.    \n",
    "\n",
    "\n",
    "- **Análise exploratória**: analise a sua base como um todo, verifique o balanceamento entre as classes e foque, principalmente, na coluna ```tweet_text```.    \n",
    "\n",
    "\n",
    "- **Pré-processamento e transformações**: projetos de NLP exigem um considerável pré-processamento. Foque no tratamento da string do texto. Procure começar com tratamentos simples e adicione complexidade gradualmente. Nessa etapa você testará diferentes técnicas de transformações, como o Bag Of Words e o TF-IDF.    \n",
    "\n",
    "\n",
    "- **Treinamento do modelo**: depois das transformações, você poderá executar o treinamento do modelo classificador. Nessa etapa o problema se torna semelhante aos abordados na primeira parte do módulo. Você pode testar diversos classificadores como RandomForest, AdaBoost, entre outros. Otimize os hiperparâmetros do modelo com técnicas como a GridSearch e a RandomizedSearch.    \n",
    "\n",
    "\n",
    "- **Conclusões**: descreva, em texto, as conclusões sobre os seus estudos. O modelo é capaz de identificar o sentimento das publicações? É possível extrapolar o modelo para outros contextos, como a análise de sentimento de uma frase qualquer? Pense em questões pertinentes e relevantes que você tenha obtido durante o desenvolvimento do projeto!     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283638c9",
   "metadata": {},
   "source": [
    "## Critérios de avaliação\n",
    "\n",
    "Os seguintes itens serão avaliados:\n",
    "\n",
    "1. Desenvolvimento das etapas descritas acima;\n",
    "\n",
    "\n",
    "2. Reprodutibilidade do código: seu código será executado e precisa gerar os mesmos resultados apresentados por você;\n",
    "\n",
    "\n",
    "3. Clareza: seu código precisa ser claro e deve existir uma linha de raciocínio direta. Comente o código em pontos que julgar necessário para o entendimento total;\n",
    "\n",
    "\n",
    "4. Justificativa das conclusões obitdas: não existirá certo ou errado, mas as decisões e as conclusões precisam ser bem justificadas com base nos resultados obtidos.  \n",
    "\n",
    "O desempenho do modelo **não** será considerado como critério de avaliação.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6049a9c",
   "metadata": {},
   "source": [
    "## Informações gerais\n",
    "\n",
    "- O projeto deve ser desenvolvido individualmente;\n",
    "\n",
    "\n",
    "- Data de divulgação: 11/01/2022;\n",
    "\n",
    "\n",
    "- Aula de monitoria: 19/01/2022;\n",
    "\n",
    "\n",
    "- Data de entrega: 26/01/2022;\n",
    "\n",
    "\n",
    "- Entrega através do Class: Árvore de Decisão -> Exercícios -> Projeto 2\n",
    "\n",
    "\n",
    "Anexar, na entrega, o notebook de desenvolvimento e o arquivo .csv de submissão, da seguinte forma:  \n",
    "\n",
    "notebook: ```<nome>_<sobrenome>_<númeroTurma>_projeto_2.ipynb```   \n",
    "csv: ```<nome>_<sobrenome>_<númeroTurma>_projeto_2_submissao.csv```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb23437",
   "metadata": {},
   "source": [
    "## Dicas\n",
    "\n",
    "### Base de treino e submissão\n",
    "\n",
    "A base de submissão não possui a variável de saída, portanto ela será utilizada **apenas** para gerar o arquivo que acompanha a submissão do projeto.      \n",
    "\n",
    "### Tente encontrar possíveis vieses\n",
    "\n",
    "É muito comum que modelos de NLP possuam fortes vieses, como a tendência de relacionar palavras específicas com alguma classe de saída. Tente encontrar vieses no seu estudo, isso pode ajudar a tirar boas conclusões. o campo \"query_used\" pode ser útil para essa análise.  \n",
    "\n",
    "### O pré-processamento é a chave para um bom desempenho\n",
    "\n",
    "Essa é a etapa que mais vai contribuir para o desempenho do seu modelo. Seja criativo e desenvolva essa etapa de uma maneira que seja fácil de aplicar o mesmo processamento para uma nova base, você terá que fazer isso para gerar a base de submissão.\n",
    "\n",
    "### Um termômetro para o seu desenvolvimento\n",
    "\n",
    "Após a correção do seu projeto, o professor irá disponibilizar a sua acurácia obtida na base de submissão. Você pode interpretar esse resultado como a simulação do resultado do seu modelo em produção. Uma diferença entre o resultado do estudo e o resultado de submissão indica um grau de **overfitting** no seu modelo.\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96911dea",
   "metadata": {},
   "source": [
    "# Desenvolvimento do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d5233",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1. Análise de consistência dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f25c3d",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad89b883",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas carregadas com sucesso.\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Bibliotecas\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import requests\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import squarify\n",
    "import plotly.offline as py\n",
    "import plotly_express as px\n",
    "from plotly import graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, f1_score, r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score, StratifiedKFold, cross_validate\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec, doc2vec\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "# Naive Bayes (Gaussian, Multinomial,BernoulliNB)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# Stochastic Gradient Descent Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# KNN (k-nearest neighbor)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# XGBoost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "# LGBM Classifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# Ada Boosting Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Dummy Boosting Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "# GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# RidgeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from unidecode import unidecode\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#!pip install enelvo\n",
    "from enelvo.normaliser import Normaliser\n",
    "\n",
    "# Abaixo seguem 2 formas para a instalação do spaCy: via conda ou pip\n",
    "# Instalação utilizando conda\n",
    "#!conda install -c conda-forge spacy\n",
    "\n",
    "# Instalação utilizando Pip\n",
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "\n",
    "import spacy\n",
    "from spacy.util import compounding\n",
    "from spacy.util import minibatch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import shap\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from IPython.core.display import HTML as Center\n",
    "from IPython.display import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Bibliotecas carregadas com sucesso.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1272b9b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Padrões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51314fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Definição de padrões para gráficos e cores\n",
    "\n",
    "sns.set_style('darkgrid') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=13)    # legend fontsize\n",
    "plt.rc('font', size=13)          # controls default text sizes\n",
    "\n",
    "colors = sns.color_palette(\"pastel\") # deep, pastel, Set1 Set2 Set3, icefire, tab10, muted, colorlind, coolwarm\n",
    "cmap_colors = 'GnBu'\n",
    "\n",
    "font_path = \"./fonts/CabinSketch-Bold.ttf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e73245",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       " <style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definição de padrões para centralização de gráficos no notebook\n",
    "\n",
    "Center(\"\"\" <style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style> \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c46305",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e98c2874",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3054506e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função de avaliação dos valores de NaN no dataframe\n",
    "\n",
    "def missing_values_table(df):\n",
    "    '''\n",
    "    Função para verificar se existem valores nulos no dataframe\n",
    "    Entrada:\n",
    "        df - dataframe;\n",
    "        \n",
    "    Resultado: \n",
    "        Apresentação dos valores nulos no dataframe.\n",
    "\n",
    "    '''\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mz_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mz_table = mz_table.rename(\n",
    "    columns = {0 : 'Valores faltantes', 1 : '% de Valores Totais'})\n",
    "    mz_table['Data Type'] = df.dtypes\n",
    "    mz_table = mz_table[\n",
    "        mz_table.iloc[:,1] != 0].sort_values(\n",
    "    '% de Valores Totais', ascending=False).round(1)\n",
    "    print (\"O dataframe tem \" + str(df.shape[1]) + \" colunas e \" + str(df.shape[0]) + \" linhas.\\n\"      \n",
    "        \"Existem \" + str(mz_table.shape[0]) +\n",
    "          \" colunas que têm valores faltantes.\")\n",
    "    mz_table.to_excel('missing_and_zero_values.xlsx', freeze_panes=(1,0), index = True)\n",
    "    return mz_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61537f52",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função de avaliação de modelos apresentação da matriz de confusão\n",
    "score = []\n",
    "\n",
    "def test_models(model_list, col_model_name, col_model, tec_model, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Função para avaliação de modelos de predição\n",
    "    Entrada:\n",
    "        model_list - lista de modelos;\n",
    "        col_model_name - label da lista de modelos, contendo o nome do modelo;\n",
    "        col_model - label da lista de modelos, contendo a instancia do modelo de predição;\n",
    "        tec_model - definição de tratamento de modelos;\n",
    "        X_train - classe de treino\n",
    "        X_test - classe de teste\n",
    "        y_train - classe de treino\n",
    "        y_test - classe de teste\n",
    "        \n",
    "    Resultado: \n",
    "        Apresentação de métricas de predição de modelos.\n",
    "\n",
    "    '''\n",
    "    for mdl in model_list:\n",
    "        start = time.time()\n",
    "\n",
    "        model = mdl[col_model]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        \n",
    "        print(\"\")        \n",
    "        print(\"=\" * 55)\n",
    "        print(\"Model      : %s\" % mdl[col_model_name])\n",
    "        print(\"Accuracy   : %0.4f \" % accuracy_score(y_test, y_predict))\n",
    "        print(\"Precision  : %0.4f \" % precision_score(y_test, y_predict, average='weighted'))\n",
    "        print(\"Recall     : %0.4f \" % recall_score(y_test, y_predict, average='weighted'))\n",
    "        print(\"F1 - Score : %0.4f \" % f1_score(y_test, y_predict, average='weighted'))\n",
    "        print(\"MAE        : %0.4f \" % mean_absolute_error(y_test, y_predict))\n",
    "        print(\"RMSE       : %0.4f \" % np.sqrt(mean_squared_error(y_test, y_predict)))\n",
    "        print(\"R2         : %0.4f \" % r2_score(y_test, y_predict))\n",
    "        print(\"\")\n",
    "        print(classification_report(y_test, y_predict))\n",
    "\n",
    "        global score\n",
    "        score.append([mdl[col_model_name], tec_model, accuracy_score(y_test, y_predict)])\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_predict)\n",
    "        labels = ['Negativo','Positivo','Neutro']\n",
    "        dsp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "        dsp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n",
    "        plt.grid(False)\n",
    "        plt.show()        \n",
    "        \n",
    "        end = time.time()\n",
    "        elptime = end - start\n",
    "        converted_time = str(datetime.timedelta(seconds=elptime))\n",
    "        print(f'Partial time: {converted_time}')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f11adbab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função para calcular a importância da variável no modelo\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "def modelfit(alg, dtrain, predictors, target, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    # Adequando as classes para treino\n",
    "    alg.fit(dtrain[predictors], dtrain[target])\n",
    "    \n",
    "    # Previsão de saída para o conjunto de dados de teste\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    # Utilizando o Cross Validation\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, dtrain[predictors], dtrain[target], cv=cv_folds, scoring='accuracy')\n",
    "    \n",
    "    #Exibindo relatório:\n",
    "    print (f\"\\nRelatório do Modelo {alg}\")\n",
    "    print (\"\\nAcuracia : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "    #print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predictions))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29b8b842",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_corpus(list_sentences, tokens_only=False):\n",
    "    if tokens_only:\n",
    "        # For test data, just return sentences\n",
    "        return list_sentences\n",
    "    else:\n",
    "        # For training data, add tags\n",
    "        lista = []\n",
    "        for i, line in enumerate(list_sentences):\n",
    "            lista.append(doc2vec.TaggedDocument(line, [i]))\n",
    "\n",
    "        return lista\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc2553f8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função para contagem de palavras \n",
    "\n",
    "def words_unique(sentiment, numwords, raw_words):\n",
    "    '''\n",
    "    Função para contagem de palavras \n",
    "    Entrada:\n",
    "        segmento - Categoria do segmento (ex. 2 = 'Neutro');\n",
    "        numwords - quantas palavras específicas se pretende ver no resultado final; \n",
    "        raw_words - lista do texto;\n",
    "        \n",
    "    Resultado: \n",
    "        dataframe com informação sobre a palavra específica e quantas vezes aparece no texto (por ordem decrescente com base nas suas contagens).\n",
    "\n",
    "    '''\n",
    "    allother = []\n",
    "    for item in dfc[dfc.sentiment != sentiment]['list_words']:\n",
    "        for word in item:\n",
    "            allother .append(word)\n",
    "    allother  = list(set(allother ))\n",
    "    \n",
    "    specificnonly = [x for x in raw_text if x not in allother]\n",
    "    \n",
    "    mycounter = Counter()\n",
    "    \n",
    "    for item in dfc[dfc.sentiment == sentiment]['list_words']:\n",
    "        for word in item:\n",
    "            mycounter[word] += 1\n",
    "    keep = list(specificnonly)\n",
    "    \n",
    "    for word in list(mycounter):\n",
    "        if word not in keep:\n",
    "            del mycounter[word]\n",
    "    \n",
    "    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n",
    "    \n",
    "    return Unique_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "922f869d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "# Abaixo seguem 2 formas para a instalação do spaCy: via conda ou pip\n",
    "\n",
    "# Instalação utilizando conda\n",
    "#!conda install -c conda-forge spacy\n",
    "\n",
    "# Instalação utilizando Pip\n",
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "\n",
    "# Bilbioteca em portugues\n",
    "# Efficiency\n",
    "#!python -m spacy download pt_core_news_sm\n",
    "\n",
    "# Accuracy\n",
    "#!python -m spacy download pt_core_news_lg\n",
    "\n",
    "spc_pt = spacy.load('pt_core_news_lg')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "#Adicionando stopwords que não estão na lista do nltk \n",
    "stopwords.append(\"'\")\n",
    "stopwords.append(\"pra\")\n",
    "stopwords.append(\"tá\")\n",
    "stopwords.append(\"tão\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad860da3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função para tratamento da variável de texto para definir melhores valores para classificação da modelagem\n",
    "# e ou normalizar o tratamento da variável de texto utilizando a biblioteca enelvo\n",
    "\n",
    "# instanciando\n",
    "normalizador = Normaliser(tokenizer='readable', sanitize=True, capitalize_acs=True, capitalize_pns=True) # capitalize_inis=True\n",
    "\n",
    "def nlp_tratar_texto(texto, normalize=False):\n",
    "    '''\n",
    "    Função para tratamento de texto \n",
    "    Entrada:\n",
    "        texto - Texto para tratamento;\n",
    "        normalize - utilizar função de normalização da biblioteca enelvo;\n",
    "        \n",
    "    Resultado: \n",
    "        Retorna o texto com tratamento de caracteres.\n",
    "\n",
    "    '''    \n",
    "    #Remover endereços de sites\n",
    "    texto_sem_url = re.sub(r'https?:\\/\\/\\S+', '', texto)\n",
    "        \n",
    "    #Remover e-mail / users\n",
    "    #texto_sem_email = re.sub(r'[A-Za-z0-9]*@[A-Za-z]*\\.?[A-Za-z0-9]*\\.?[A-Za-z0-9]*', '', texto_sem_url)\n",
    "    texto_sem_email = re.sub(r'[A-Za-z0-9]*@\\S+', '', texto_sem_url)\n",
    "    \n",
    "    if normalize==True:\n",
    "        # Tratamento do texto utilizando o enelvo (Normalize)\n",
    "        texto_norm = normalizador.normalise(texto_sem_email)\n",
    "    \n",
    "        #Remover caracteres que não são letras e tokenização\n",
    "        texto_tratado =  re.findall(r'\\b[A-zÀ-úü]+\\b', texto_norm.lower())\n",
    "    else:\n",
    "        texto_tratado =  re.findall(r'\\b[A-zÀ-úü]+\\b', texto_sem_email.lower())\n",
    "\n",
    "    #Remover stopwords\n",
    "    stop = set(stopwords)\n",
    "    palavras = [w for w in texto_tratado if w not in stop]\n",
    "    palavras_string = \" \".join(palavras)\n",
    "\n",
    "    #Instanciar o objeto spacy\n",
    "    spc_letras =  spc_pt(palavras_string)\n",
    "\n",
    "    #Lemmização \n",
    "    tokens = [token.lemma_ if token.pos_ == 'VERB' else str(token) for token in spc_letras]\n",
    "\n",
    "    #problemas com verbo ir\n",
    "    ir = ['vou', 'vais', 'vai', 'vamos', 'ides', 'vão']\n",
    "    tokens = ['ir' if token in ir else str(token) for token in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a733446",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função para apresentar nuvem de palavras\n",
    "\n",
    "def plot_wordcloud(text, title = None, backcolor = 'white', clrmap = ''):\n",
    "    '''\n",
    "    Função para criação de imagem de nuvem de palavras\n",
    "    Entrada:\n",
    "        text - palavras para nuvem de palavras;\n",
    "        title - título da imagem;\n",
    "        backcolor - ;\n",
    "        clrmap - ;\n",
    "        \n",
    "    Resultado: \n",
    "        Imagem com nuvem de palavras.\n",
    "\n",
    "    '''    \n",
    "    wordcloud = WordCloud(\n",
    "                            background_color=backcolor,\n",
    "                            width=2000, \n",
    "                            height=800,\n",
    "                            colormap=clrmap, \n",
    "                            font_path=font_path, \n",
    "                            collocations = False)\n",
    "\n",
    "    wordcloud.generate(text)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7656c8d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função para diminuir o tamanho do dataframe com alteração dos datatypes\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    '''\n",
    "    Função para diminuir o tamanho do dataframe com alteração dos datatypes\n",
    "    Entrada:\n",
    "        df - dataframe;\n",
    "        \n",
    "    Resultado: \n",
    "        Retorna o dataframe com alteração com a configuração mínimas dos tipos do datatype;\n",
    "        \n",
    "    '''\n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c39e89",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e738a2b7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Inicializando Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2348e7b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Arquivo Train3Classes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39c224f3",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  2.99 Mb (17.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Importando arquivo\n",
    "\n",
    "df = reduce_mem_usage(pd.read_csv('./dados/train/Train3Classes.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efd96274",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de linhas...........: 95000\n",
      "Quantidade de linhas duplicadas: 0\n",
      "Quantidade de colunas..........: 5\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtl, qtc = df.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "\n",
    "qtd, _ = df[df.duplicated(keep=False)].shape\n",
    "\n",
    "print(f'Quantidade de linhas...........: {qtl}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtd}')\n",
    "print(f'Quantidade de colunas..........: {qtc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daf0b35b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95000 entries, 0 to 94999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          95000 non-null  int64 \n",
      " 1   tweet_text  95000 non-null  object\n",
      " 2   tweet_date  95000 non-null  object\n",
      " 3   sentiment   95000 non-null  int8  \n",
      " 4   query_used  95000 non-null  object\n",
      "dtypes: int64(1), int8(1), object(3)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95aba7f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataframe tem 5 colunas e 95000 linhas.\n",
      "Existem 0 colunas que têm valores faltantes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores faltantes</th>\n",
       "      <th>% de Valores Totais</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Valores faltantes, % de Valores Totais, Data Type]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando os valores nulos do dataframe\n",
    "\n",
    "missing_values_table(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abf0cc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "O dataframe é composto por 05 colunas e 95.000 registros.\n",
    "\n",
    "A tabela acima NÃO apresenta valores faltantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c26c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc5d77c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tweet_text', 'tweet_date', 'sentiment', 'query_used'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de colunas do dataframe\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c9ae92d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1049721159292346368</td>\n",
       "      <td>Rio elege maior bancada policial de sua histór...</td>\n",
       "      <td>Tue Oct 09 18:00:01 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>folha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046251157025423360</td>\n",
       "      <td>fiquei tão triste quando eu vi o preço da câme...</td>\n",
       "      <td>Sun Sep 30 04:11:28 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041744620206653440</td>\n",
       "      <td>Para Theresa May, seu plano para o Brexit é a ...</td>\n",
       "      <td>Mon Sep 17 17:44:06 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>exame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046937084727107589</td>\n",
       "      <td>caralho eu quero proteger a danielly em um pot...</td>\n",
       "      <td>Tue Oct 02 01:37:06 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1047326854229778432</td>\n",
       "      <td>@SiCaetano_ viva o caos :)</td>\n",
       "      <td>Wed Oct 03 03:25:55 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         tweet_text  \\\n",
       "0  1049721159292346368  Rio elege maior bancada policial de sua histór...   \n",
       "1  1046251157025423360  fiquei tão triste quando eu vi o preço da câme...   \n",
       "2  1041744620206653440  Para Theresa May, seu plano para o Brexit é a ...   \n",
       "3  1046937084727107589  caralho eu quero proteger a danielly em um pot...   \n",
       "4  1047326854229778432                         @SiCaetano_ viva o caos :)   \n",
       "\n",
       "                       tweet_date  sentiment query_used  \n",
       "0  Tue Oct 09 18:00:01 +0000 2018          2      folha  \n",
       "1  Sun Sep 30 04:11:28 +0000 2018          0         :(  \n",
       "2  Mon Sep 17 17:44:06 +0000 2018          2      exame  \n",
       "3  Tue Oct 02 01:37:06 +0000 2018          0         :(  \n",
       "4  Wed Oct 03 03:25:55 +0000 2018          1         :)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listagem das primeiras linhas do dataframe\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5fbcb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "076d3e1e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Arquivo Subm3Classes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d44206b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.15 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Importando arquivo\n",
    "\n",
    "dfs = reduce_mem_usage(pd.read_csv('./dados/subm/Subm3Classes.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19b40840",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de linhas...........: 5000\n",
      "Quantidade de linhas duplicadas: 0\n",
      "Quantidade de colunas..........: 4\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "sqtl, sqtc = dfs.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "\n",
    "sqtd, _ = dfs[dfs.duplicated(keep=False)].shape\n",
    "\n",
    "print(f'Quantidade de linhas...........: {sqtl}')\n",
    "print(f'Quantidade de linhas duplicadas: {sqtd}')\n",
    "print(f'Quantidade de colunas..........: {sqtc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7804372f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          5000 non-null   int64 \n",
      " 1   tweet_text  5000 non-null   object\n",
      " 2   tweet_date  5000 non-null   object\n",
      " 3   query_used  5000 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "dfs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce2ff13f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataframe tem 4 colunas e 5000 linhas.\n",
      "Existem 0 colunas que têm valores faltantes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores faltantes</th>\n",
       "      <th>% de Valores Totais</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Valores faltantes, % de Valores Totais, Data Type]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando os valores nulos do dataframe\n",
    "\n",
    "missing_values_table(dfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2aa854",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "O dataframe é composto por 04 colunas e 5.000 registros.\n",
    "\n",
    "A tabela acima NÃO apresenta valores faltantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5758254f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tweet_text', 'tweet_date', 'query_used'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de colunas do dataframe\n",
    "\n",
    "dfs.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f99fa6d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1046764676707753987</td>\n",
       "      <td>Apartamento Vila Mariana Praça Monteiro dos Sa...</td>\n",
       "      <td>Mon Oct 01 14:12:01 +0000 2018</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1047329264943751169</td>\n",
       "      <td>@FalleNCS @BrasilGameShow quero 1x1 de scout. ...</td>\n",
       "      <td>Wed Oct 03 03:35:29 +0000 2018</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1045443874947313665</td>\n",
       "      <td>mais uma analógica no correio à minha espera :...</td>\n",
       "      <td>Thu Sep 27 22:43:37 +0000 2018</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1040484298711814144</td>\n",
       "      <td>Em festa de posse como presidente do STF, Toff...</td>\n",
       "      <td>Fri Sep 14 06:16:02 +0000 2018</td>\n",
       "      <td>folha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1045411876887306240</td>\n",
       "      <td>@thethiagor @jubsilva @GSCISA @GrupoMulheRIs A...</td>\n",
       "      <td>Thu Sep 27 20:36:28 +0000 2018</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         tweet_text  \\\n",
       "0  1046764676707753987  Apartamento Vila Mariana Praça Monteiro dos Sa...   \n",
       "1  1047329264943751169  @FalleNCS @BrasilGameShow quero 1x1 de scout. ...   \n",
       "2  1045443874947313665  mais uma analógica no correio à minha espera :...   \n",
       "3  1040484298711814144  Em festa de posse como presidente do STF, Toff...   \n",
       "4  1045411876887306240  @thethiagor @jubsilva @GSCISA @GrupoMulheRIs A...   \n",
       "\n",
       "                       tweet_date query_used  \n",
       "0  Mon Oct 01 14:12:01 +0000 2018         :)  \n",
       "1  Wed Oct 03 03:35:29 +0000 2018         :)  \n",
       "2  Thu Sep 27 22:43:37 +0000 2018         :)  \n",
       "3  Fri Sep 14 06:16:02 +0000 2018      folha  \n",
       "4  Thu Sep 27 20:36:28 +0000 2018         :)  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listagem das primeiras linhas do dataframe\n",
    "\n",
    "dfs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7d961",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5811661",
   "metadata": {},
   "source": [
    "## 2. Pré-processamento e transformações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a59eb",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Tratamento de variáveis**\n",
    "\n",
    "- Criação da variável **filtered_words**, onde o texto original (tweet_text) será submetido a tratamentos de texto;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **join_f_words**, para concatenar as palavras do coluna **filtered_words**;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **num_words_text**, para contar a quantidade de palavras no texto principal;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **num_words_join**, para contar a quantirade de palavrvas após tratamento;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **diff_in_words**, para contar a diferença de palavras entre o texto principal e o tratado;<br>\n",
    "\n",
    "\n",
    "- Exclusão de variáveis que entendemos não ser relevante para o modelo<br>\n",
    "    **id**: ID único para o tweet<br>\n",
    "    **tweet_date**: Data da publicação no Twitter<br>\n",
    "    **filtered_words**: Variável auxiliar para tratamento de texto<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d247977",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Parametro para utilizar o enelvo.normalise (1=sim / 0=Não)\n",
    "# pois o processo da biblioteca enelvo eleva o tempo de processamento do notebook em 2 horas\n",
    "\n",
    "# use_normalize = 1\n",
    "# O processamento desta célula com o tratamendo dos tweets utilizando o biblioteca enelvo leva em média 2 horas, \n",
    "# em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# use_normalize = 0\n",
    "# O processamento desta célula com o tratamendo dos tweets leva em média 10 min, em uma máquina i7 com 12 cores e 32 ram \n",
    "    \n",
    "use_normalize = 1\n",
    "\n",
    "# Verifica se utiliza o tratamento com Enelvo\n",
    "if use_normalize==1:\n",
    "    # Cria uma nova variável utilizando funções para tratamento das palavras do texto\n",
    "    df['filtered_words'] = df['tweet_text'].apply(lambda w: nlp_tratar_texto(w, normalize=True))\n",
    "    dfs['filtered_words'] = dfs['tweet_text'].apply(lambda w: nlp_tratar_texto(w, normalize=True))\n",
    "else:\n",
    "    # Cria uma nova variável utilizando funções para tratamento das palavras do texto\n",
    "    df['filtered_words'] = df['tweet_text'].apply(lambda w: nlp_tratar_texto(w))\n",
    "    dfs['filtered_words'] = dfs['tweet_text'].apply(lambda w: nlp_tratar_texto(w))\n",
    "\n",
    "# Cria uma nova variável concatenando os tokens gerados pelo tratamento das palavras gerando um novo texto reduzido\n",
    "df['join_f_words'] = df['filtered_words'].apply(lambda w: ' '.join(w))\n",
    "dfs['join_f_words'] = dfs['filtered_words'].apply(lambda w: ' '.join(w))\n",
    "\n",
    "# Cria uma nova variável com a quantidade de palavras da variável join_f_words\n",
    "df['num_words_text'] = df['tweet_text'].apply(lambda w:len(str(w).split()))\n",
    "dfs['num_words_text'] = dfs['tweet_text'].apply(lambda w:len(str(w).split()))\n",
    "\n",
    "# Cria uma nova variável com a quantidade de palavras da variável join_f_words\n",
    "df['num_words_join'] = df['join_f_words'].apply(lambda w:len(str(w).split()))\n",
    "dfs['num_words_join'] = dfs['join_f_words'].apply(lambda w:len(str(w).split()))\n",
    "\n",
    "# Cria uma nova variável com a diferença de quantidade de palavras\n",
    "df['diff_in_words'] = df['num_words_text'] - df['num_words_join']\n",
    "dfs['diff_in_words'] = dfs['num_words_text'] - dfs['num_words_join']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altera o tamanho da visualização das colunas para demonstrar todo o conteúdo\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "\n",
    "# Mostra o conteúdo das variáveis tratadas\n",
    "df[['tweet_text', 'filtered_words', 'join_f_words']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e0f72",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões**\n",
    "\n",
    "Submetemos a variável tweet_text ao tratamento de texto:\n",
    "\n",
    "- Remoção de endereços de sites;\n",
    "- Remoção de e-mails e usuários do tweet;\n",
    "- Remoção de caracteres que não são letras;\n",
    "- Remoção de dígitos;\n",
    "- Transformação de todas as palavras para minúsculas;\n",
    "- Tokenização do texto;\n",
    "- Remoção de stopwords (portugues);\n",
    "- \"Lemmatização\" do texto;\n",
    "- **enelvo.normalise** \"corrige\" abreviações, gírias, erros ortográficos e acrônimos;\n",
    "\n",
    "Após o tratamento do texto foi criada a variável **join_f_words** para gravar as informações do texto tratado, entendemos que esta variável esteja mais \"limpa\" para utilização do texto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e7248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusão de variáveis que entendemos não ser relevante para o modelo\n",
    "\n",
    "# id: ID único para o tweet  \n",
    "# tweet_date: Data da publicação no Twitter  \n",
    "# query_used: Filtro utilizado para buscar a publicação\n",
    "# filtered_words: Texto da publicação no Twitter após tratamento de texto\n",
    "\n",
    "# Excluindo colunas\n",
    "DeleteList=['id', 'tweet_date', 'filtered_words']\n",
    "\n",
    "# Novo dataframe dfc (df copy)\n",
    "dfc = df.drop(DeleteList, axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f1be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "dfc.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46761af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando quais linhas não apresentam valor após o tratamento do texto\n",
    "\n",
    "# Quantidade de linhas vazias\n",
    "qtd, _ = dfc[np.where((dfc['join_f_words'].str.len()<1), True, False)].shape\n",
    "\n",
    "print('Dataframe original - df')\n",
    "print(f'Quantidade de linhas vazias ...: {qtd}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirando as linhas que ficaram sem texto\n",
    "\n",
    "dfc = dfc[np.where((dfc['join_f_words'].str.len()>1), True, False)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando os valores nulos do dataframe\n",
    "\n",
    "missing_values_table(dfc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2305832",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "A tabela acima NÃO apresenta valores faltantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusão dos registros faltantes \n",
    "\n",
    "dfc.dropna() \n",
    "dfc.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2887d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtlc, qtcc = dfc.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "qtd, _ = dfc[dfc.duplicated()].shape\n",
    "\n",
    "\n",
    "print('Dataframe original - df')\n",
    "print(f'Quantidade de linhas...........: {qtl}')\n",
    "print(f'Quantidade de colunas..........: {qtc}')\n",
    "\n",
    "print('\\nDataframe tratado - dfc')\n",
    "print(f'Quantidade de linhas...........: {qtlc}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtd}')\n",
    "print(f'Quantidade de colunas..........: {qtcc}')\n",
    "\n",
    "print (f'\\nPercentual de registros retirados: {(100  * (qtl-qtlc) / qtl):.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3416ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando linhas duplicadas\n",
    "\n",
    "# Seleciona as linhas duplicadas no dataframe baseado em todas as colunas\n",
    "display(dfc[dfc.duplicated(keep='first')].sort_values(by=list(dfc.columns)))\n",
    "\n",
    "print(\"\\nLinhas duplicadas:\")\n",
    "print(dfc[dfc.duplicated()].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa0cef9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "Após tratamento do texto identificamos duplicidades de informações, como a quantidade é baixa optamos em retirar as linhas repetidas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551a193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832514dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Excluindo os linhas duplicadas\n",
    "dfc = dfc.drop_duplicates(keep='first').copy()\n",
    "dfc.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtlc, qtcc = dfc.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "qtd, _ = dfc[dfc.duplicated()].shape\n",
    "\n",
    "\n",
    "print('Dataframe original - df')\n",
    "print(f'Quantidade de linhas...........: {qtl}')\n",
    "print(f'Quantidade de colunas..........: {qtc}')\n",
    "\n",
    "print('\\nDataframe tratado - dfc')\n",
    "print(f'Quantidade de linhas...........: {qtlc}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtd}')\n",
    "print(f'Quantidade de colunas..........: {qtcc}')\n",
    "\n",
    "print (f'\\nPercentual de registros retirados: {(100  * (qtl-qtlc) / qtl):.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grava um novo CSV com as variáveis auxiliares\n",
    "\n",
    "# Definindo o nome do arquivo\n",
    "if use_normalize==1:\n",
    "    file_name = './dados/train/Train3Classes_with_Token_normalize.csv'\n",
    "    file_name_s = './dados/subm/Subm3Classes_with_Token_normalize.csv'\n",
    "else:\n",
    "    file_name = './dados/train/Train3Classes_with_Token.csv'\n",
    "    file_name_s = './dados/subm/Subm3Classes_with_Token.csv'\n",
    "\n",
    "# Salvando o CSV\n",
    "try:\n",
    "    # Gravando o dataframe em CSV\n",
    "    dfc.to_csv(file_name, index=False)\n",
    "    dfs.to_csv(file_name_s, index=False)\n",
    "    print(f'DataFrame gravado com successo.\\n')\n",
    "    \n",
    "    try:\n",
    "        # Carregar o dataframe\n",
    "        dfc = reduce_mem_usage(pd.read_csv(file_name))\n",
    "        dfs = reduce_mem_usage(pd.read_csv(file_name_s))\n",
    "        print(f'Arquivo carregado com successo.')\n",
    "\n",
    "    except:\n",
    "        print(f'Ocorreu um erro no carregamento do arquivo.')\n",
    "    \n",
    "except:\n",
    "    print(\"Ocorreu um erro na gravação.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b6787",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "- Tratamos a variável **tweet_text** para criar a variável auxiliar **filtered_words**, onde os textos foram submetidos a tratamentos para definir as palavras chaves de sentimento, utilizando também a biblioteca **enelvo**;<br>\n",
    "\n",
    "\n",
    "- Criamos a variável **join_f_words**, para concatenar as palavras do coluna **filtered_words**;<br>\n",
    "\n",
    "\n",
    "- Criamos um novo dataframe **dfc**, retirando as variáveis **id, tweet_date, filtered_words**, pois acreditamos que as variáveis não são relevantes para a modelagem;<br>\n",
    "\n",
    "\n",
    "- Retiramos todos os registros que apresentavam colunas nulas;<br>\n",
    "\n",
    "\n",
    "- Retiramos todos os registros que estavam duplicados;<br>\n",
    "\n",
    "\n",
    "Com esses processos acreditamos que o novo dataframe esta melhor preparado para análise exploratória de dados e modelagem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cdcd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7682d5be",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3. Análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4baeaa0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "dfc.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b3e5c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Listagem das primeiras linhas do dataframe\n",
    "\n",
    "dfc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cffc4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14f4b52d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Analisando Sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e0e5c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### sentiment\n",
    "\n",
    "- 0, se negativo; \n",
    "- 1, se positivo; \n",
    "- 2, se neutro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567c31a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quantidade de sentimentos\n",
    "\n",
    "Counter(dfc['sentiment']).most_common()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b796df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Distribuição de tweets\n",
    "\n",
    "temp = dfc.groupby('sentiment').count()['tweet_text'].reset_index().sort_values(by='tweet_text',ascending=False)\n",
    "temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72634775",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Distribuição da variavel sentiment\n",
    "\n",
    "col = 'sentiment'\n",
    "\n",
    "total = len(dfc)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "g = sns.countplot(x=col, data=dfc, palette=colors)\n",
    "g.set_title(f\"Distribuição da variável {col}\")\n",
    "g.set_xlabel(f\"{col}\")\n",
    "g.set_ylabel(\"Quantidade\")\n",
    "sizes=[]\n",
    "for p in g.patches:\n",
    "    height = p.get_height()\n",
    "    sizes.append(height)\n",
    "    g.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format((height/total)*100),\n",
    "            ha=\"center\", fontsize=14) \n",
    "g.set_ylim(0, max(sizes) * 1.15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488bcc2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "Analisando a variável **sentiment** podemos constatar que o nosso dataframe contém quantidades de tweets balanceados, diminuindo a tendência do modelo para algum dos sentimentos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47fb8ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "598d1686",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### query_used\n",
    "\n",
    "- :(, se negativo (0);\n",
    "- :), se positivo (1);\n",
    "- \"outros\", se neutro (2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a3f71",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quantidade de sentimentos\n",
    "\n",
    "Counter(dfc['query_used']).most_common()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de2fe8c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Avaliação da variável query_used\n",
    "\n",
    "# Criação de nova variável substituindo os valores \"outros\" por :|, ou seja, diferente de \":(\" e \":)\" para \n",
    "# agrupar os sentimentos neutros\n",
    "\n",
    "conditions = [\n",
    "    (dfc['query_used'] != ':(') & (dfc['query_used'] != ':)'),\n",
    "    (dfc['query_used'] == ':('),\n",
    "    (dfc['query_used'] == ':)')]\n",
    "choices = [':|', ':(', ':)']\n",
    "dfc['sent_query_used'] = np.select(conditions, choices, default=np.NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d43c363",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Distribuição de tweets\n",
    "\n",
    "temp_q = dfc.groupby('sent_query_used').count()['tweet_text'].reset_index().sort_values(by='tweet_text',ascending=False)\n",
    "temp_q\n",
    "\n",
    "temp_q.rename(columns = {'tweet_text':'tweet_text_q'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60609c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Concatenando os dataframes auxiliares para avaliar a quantidade de sentimentos e query_used\n",
    "\n",
    "df_col = pd.concat([temp_q, temp], axis=1)\n",
    "df_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9352b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "023e7bf4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões**\n",
    "\n",
    "Notamos que a variável **query_used** foi utilizada para criar a variável de **sentiment** convertendo as strings \":(\", \":)\" e outros textos em valores numéricos, pois apresentam a mesma quantidade de linhas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5786321",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45009fc3",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Analisando as palavras dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1596dc7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Criando a lista de palavras e o vocabulário de palavras\n",
    "\n",
    "dfc['list_words'] = dfc['join_f_words'].apply(lambda w:str(w).split())\n",
    "\n",
    "# Criando vocabulário (collection) para armazenar as palavras e vezes que aparecem\n",
    "top = Counter([item for sublist in dfc['list_words'] for item in sublist])\n",
    "\n",
    "print(f\"O vocabulário é formado por {len(top)} palavras!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0abaef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# As 20 Palavras mais utilizadas nos textos\n",
    "\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Palavras','Quantidade']\n",
    "temp.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b58fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Analisando a quantidade de palavras mais utilizadas\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp, palette=colors)\n",
    "g.set_title(f\"As 20 palavras mais utilizadas nos textos\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83261e20",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Analisando a quantidade de palavras mais utilizadas\n",
    "\n",
    "fig = px.treemap(temp, path=['Palavras'], values='Quantidade',title='As 20 palavras mais utilizadas nos textos')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495101ff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da8d21a4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Palavras mais utilizadas por Sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9281a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Criando dataframes por sentimentos\n",
    "\n",
    "# negativo\n",
    "Negative_sent = dfc[dfc['sentiment']==0]\n",
    "Negative_sent.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# positivo\n",
    "Positive_sent = dfc[dfc['sentiment']==1]\n",
    "Positive_sent.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# neutro\n",
    "Neutral_sent = dfc[dfc['sentiment']==2]\n",
    "Neutral_sent.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31a8e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Lista auxiliar com todas as palavras do dataframe\n",
    "\n",
    "raw_text = [word for word_list in dfc['list_words'] for word in word_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e30c327",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Sentimentos Negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c7f6b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas em sentimentos negativos\n",
    "\n",
    "top = Counter([item for sublist in Negative_sent['list_words'] for item in sublist])\n",
    "temp_negative = pd.DataFrame(top.most_common(20))\n",
    "temp_negative = temp_negative.iloc[1:,:]\n",
    "temp_negative.columns = ['Palavras','Quantidade']\n",
    "temp_negative.style.background_gradient(cmap='Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890d809",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação da quantidade de palavras mais utilizadas em sentimentos negativos\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp_negative, palette=colors)\n",
    "g.set_title(f\"Palavras mais utilizadas nos textos negativos\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afff34",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# As 20 palavras utilizadas apenas para o sentimento negativo\n",
    "\n",
    "Unique_Negative= words_unique(0, 20, raw_text)\n",
    "\n",
    "print('As 20 palavras mais utilizadas apenas em Tweets negativos:')\n",
    "Unique_Negative.style.background_gradient(cmap='Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414b719",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# As 20 palavras utilizadas apenas para o sentimento negativos\n",
    "\n",
    "fig = px.treemap(Unique_Negative, path=['words'], values='count',title='As 20 palavras mais utilizadas apenas em Tweets negativos')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85d56c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d950de81",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Sentimentos Positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f27e52",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas em sentimentos positivos\n",
    "\n",
    "top = Counter([item for sublist in Positive_sent['list_words'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(20))\n",
    "temp_positive.columns = ['Palavras','Quantidade']\n",
    "temp_positive.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097beb9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação da quantidade de palavras mais utilizadas em sentimentos positivos\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp_positive, palette=colors)\n",
    "g.set_title(f\"Palavras mais utilizadas nos textos positivos\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a152e0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# As 20 palavras utilizadas apenas para o sentimento positivo\n",
    "\n",
    "Unique_Positive = words_unique(1, 20, raw_text)\n",
    "\n",
    "print('As 20 palavras mais utilizadas apenas em Tweets positivos:')\n",
    "Unique_Positive.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff9213",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação das palavras utilizadas em sentimentos positivos\n",
    "\n",
    "fig = px.treemap(Unique_Positive, path=['words'], values='count',title='As 20 palavras mais utilizadas apenas em Tweets positivos')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309fdcb4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cef58502",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Sentimentos Neutros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118a20e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas em sentimentos neutros\n",
    "\n",
    "top = Counter([item for sublist in Neutral_sent['list_words'] for item in sublist])\n",
    "temp_neutral = pd.DataFrame(top.most_common(20))\n",
    "temp_neutral = temp_neutral.loc[1:,:]\n",
    "temp_neutral.columns = ['Palavras','Quantidade']\n",
    "temp_neutral.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ca74a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação da quantidade de palavras mais utilizadas em sentimentos neutros\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp_neutral, palette=colors)\n",
    "g.set_title(f\"Palavras mais utilizadas nos textos neutros\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d396ded",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# As 20 palavras utilizadas apenas para o sentimento neutro\n",
    "\n",
    "Unique_Neutral= words_unique(2, 20, raw_text)\n",
    "\n",
    "print('As 20 palavras utilizadas apenas em Tweets neutros:')\n",
    "Unique_Neutral.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99c445",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação das palavras utilizadas em sentimentos neutros\n",
    "\n",
    "fig = px.treemap(Unique_Neutral, path=['words'], values='count',title='As 20 palavras mais utilizadas apenas em Tweets neutros')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92502f5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### WordClouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ae886e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Sentimentos negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c3377",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# WordCloud para Tweets negativos\n",
    "\n",
    "text = ' '.join(Negative_sent['join_f_words'])\n",
    "plot_wordcloud(text, title = 'WordCloud Tweets negativos', backcolor = 'white', clrmap = 'Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d777e1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7610b55",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Sentimentos positivos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71ff72",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# WordCloud para Tweets positivos\n",
    "\n",
    "text = ' '.join(Positive_sent['join_f_words'])\n",
    "plot_wordcloud(text, title = 'WordCloud Tweets positivos', backcolor = 'white', clrmap = 'Greens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a30ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6656fc3f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Sentimentos neutros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545fa566",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# WordCloud para Tweets neutros\n",
    "\n",
    "text = ' '.join(Neutral_sent['join_f_words'])\n",
    "plot_wordcloud(text, title = 'WordCloud Tweets neutros', backcolor = 'white', clrmap = 'PuBu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73fa2a9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "- Podemos ver que as mesmas palavras são comuns nos três segmentos;\n",
    "\n",
    "\n",
    "- Isso é interessante porque algumas palavras são mais de natureza negativa e outras palavras são mais de natureza positiva, o que significa que o agrupamento das palavras (frases) definem os sentimentos;\n",
    "\n",
    "\n",
    "- Olhando para as palavras únicas de cada sentimento, temos mais clareza sobre os dados, estas palavras únicas são determinantes para o sentimento dos tweets;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082c8a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72070112",
   "metadata": {},
   "source": [
    "## 4. Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb77b8",
   "metadata": {},
   "source": [
    "### Separando conjunto de dados Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o arquivo tratado para não reprocessar a etapa 2. Pré-processamento e transformações\n",
    "\n",
    "# Definindo o nome do arquivo\n",
    "if use_normalize==1:\n",
    "    file_name = './dados/train/Train3Classes_with_Token_normalize.csv'\n",
    "    file_name_s = './dados/subm/Subm3Classes_with_Token_normalize.csv'\n",
    "else:\n",
    "    file_name = './dados/train/Train3Classes_with_Token.csv'\n",
    "    file_name_s = './dados/subm/Subm3Classes_with_Token.csv'\n",
    "  \n",
    "# Salvando o CSV\n",
    "try:\n",
    "    # Carregar o dataframe\n",
    "    dfc = reduce_mem_usage(pd.read_csv(file_name))\n",
    "    dfs = reduce_mem_usage(pd.read_csv(file_name_s))\n",
    "    \n",
    "    #Incluindo lista de palavras\n",
    "    dfc['list_words'] = dfc['join_f_words'].apply(lambda w:str(w).split())\n",
    "    dfs['list_words'] = dfs['join_f_words'].apply(lambda w:str(w).split())    \n",
    "    \n",
    "    print(f'Arquivo carregado com successo.')\n",
    "    \n",
    "except:\n",
    "    print(f'Ocorreu um erro no carregamento do arquivo.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65486f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A nossa base de dados tem mais de 90 mil linhas e a quantidade de palavras disponíveis nos textos é muito grande. \n",
    "# Para evitar problemas de alocação de memória, processamento dos textos e modelagem, vamos criar uma amostra com 40% da base:\n",
    "\n",
    "# Caso o notebook apresente problemas de alocação de memória, favor diminuir o percentual da amostra dos dados.\n",
    "\n",
    "dfm = dfc.sample(frac=0.4, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos dividir os nossos dados numa matriz X que contém as características a treinar, \n",
    "# e uma matriz y com a variável alvo, neste caso a coluna covid_res. \n",
    "\n",
    "X = dfm['join_f_words']\n",
    "y = dfm['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86beb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos dividir os dados num conjunto de Train e num conjunto de Test. \n",
    "# Iremos treinar o modelo no conjunto de treino e depois utilizaremos o conjunto de testes para avaliar o modelo\n",
    "\n",
    "random_seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade total da variável \"target\" (sentiment)\n",
    "\n",
    "y.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a27f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade separada para o conjunto de treino inicial\n",
    "\n",
    "y_train.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade separada para o conjunto de teste inicial\n",
    "\n",
    "y_test.value_counts().sort_index()#(normalize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8fdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "191bda52",
   "metadata": {},
   "source": [
    "### Processando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de modelos para testes\n",
    "\n",
    "list_models = [\n",
    "    {'model_name': 'Dummy Classifier uniform',\n",
    "     'estimator' : DummyClassifier(strategy='uniform', random_state=random_seed)},    \n",
    "    {'model_name': 'Linear Support Vector Machine',\n",
    "     'estimator' : LinearSVC(random_state=random_seed)},\n",
    "    {'model_name': 'Stochastic Gradient Descent Classifier',\n",
    "     'estimator' : SGDClassifier(n_jobs=-1, loss='modified_huber',random_state=random_seed)},\n",
    "    {'model_name': 'LightGBM',\n",
    "     'estimator' : LGBMClassifier(random_state=random_seed)},\n",
    "    {'model_name': 'Logistic Regression',\n",
    "     'estimator' : LogisticRegression(random_state=random_seed)},\n",
    "    {'model_name': 'Classifier Ridge regression',\n",
    "     'estimator' : RidgeClassifier(random_state=random_seed)},\n",
    "    {'model_name': 'Naive Bayes Gaussian',\n",
    "     'estimator' : GaussianNB()},\n",
    "    {'model_name': 'Bernoulli Naive Bayes',\n",
    "     'estimator' : BernoulliNB()}\n",
    "]\n",
    "\n",
    "# Os modelos abaixo foram retirados por apresentarem tempo de processamento superior 20 minutos com sample de 40% \n",
    "# e apresentarem resultado de acurácia muito similares com os modelos escolhidos\n",
    "\n",
    "#{'model_name': 'Decision Tree',\n",
    "# 'estimator' : DecisionTreeClassifier(random_state=random_seed)},\n",
    "#{'model_name': 'Random Forest',\n",
    "# 'estimator' : RandomForestClassifier(random_state=random_seed)}, \n",
    "#{'model_name': 'AdaBoost',\n",
    "# 'estimator' : AdaBoostClassifier(random_state=random_seed)},\n",
    "#{'model_name': 'GradientBoosting',\n",
    "# 'estimator' : GradientBoostingClassifier(random_state=random_seed)},\n",
    "#{'model_name': 'XGBoost',\n",
    "# 'estimator' : XGBClassifier(random_state=random_seed)}\n",
    "#{'model_name': 'Support Vector Machine',\n",
    "# 'estimator' : SVC(random_state=random_seed)},\n",
    "#{'model_name': 'KNN (k-nearest neighbor)',\n",
    "# 'estimator' : KNeighborsClassifier(n_neighbors=3)},\n",
    "#{'model_name': 'Multinomial Naive Bayes',\n",
    "#'estimator' : MultinomialNB()},\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d833f",
   "metadata": {},
   "source": [
    "#### Técnica CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac91f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9df319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo com os conjuntos de dados de treinamento \n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train).toarray()\n",
    "X_test_cv = cv.transform(X_test).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce44eb",
   "metadata": {},
   "source": [
    "**Processando modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfcc793",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 5 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Processando os modelos baseado na list_models\n",
    "score = []\n",
    "\n",
    "test_models (list_models,\n",
    "             \"model_name\",\n",
    "             \"estimator\",\n",
    "             \"CountVectorizer\",\n",
    "             X_train_cv,\n",
    "             X_test_cv,\n",
    "             y_train,\n",
    "             y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd4188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86ef0d7f",
   "metadata": {},
   "source": [
    "#### Técnica TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bb8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciando TF-IDF\n",
    "\n",
    "tfidf = TfidfVectorizer(use_idf = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo com os conjuntos de dados de treinamento \n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).todense()\n",
    "X_test_tfidf  = tfidf.transform(X_test).todense()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f5592",
   "metadata": {},
   "source": [
    "**Processando modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 5 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Processando os modelos baseado na list_models\n",
    "\n",
    "test_models (list_models,\n",
    "             \"model_name\",\n",
    "             \"estimator\",\n",
    "             \"TF-IDF\",\n",
    "             X_train_tfidf,\n",
    "             X_test_tfidf,\n",
    "             y_train,\n",
    "             y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97515258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ff02828",
   "metadata": {},
   "source": [
    "#### Técnica Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a5869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando Doc2Vec\n",
    "\n",
    "d2v = doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos dividir os nossos dados numa matriz X que contém as características a treinar, \n",
    "# e uma matriz y com a variável alvo, neste caso a coluna covid_res. \n",
    "\n",
    "X_d2v = dfm['list_words']\n",
    "y_d2v = dfm['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos dividir os dados num conjunto de Train e num conjunto de Test. \n",
    "# Iremos treinar o modelo no conjunto de treino e depois utilizaremos o conjunto de testes para avaliar o modelo\n",
    "\n",
    "X_train_d2v, X_test_d2v, y_train_d2v, y_test_d2v = train_test_split(X_d2v, y_d2v, test_size=0.3, random_state=random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24983e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Preparando a classe de treinamento e teste\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 2 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "train_corpus = read_corpus(X_train_d2v)\n",
    "test_corpus = read_corpus(X_test_d2v, tokens_only=True)\n",
    "\n",
    "d2v.build_vocab(train_corpus)\n",
    "\n",
    "d2v.train(train_corpus, total_examples=d2v.corpus_count, epochs=d2v.epochs)\n",
    "\n",
    "X_train_d2v = np.array(list(map(d2v.infer_vector, X_train_d2v)))\n",
    "X_test_d2v = np.array(list(map(d2v.infer_vector, X_test_d2v)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67efed67",
   "metadata": {},
   "source": [
    "**Processando modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54820cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 7 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Processando os modelos baseado na list_models\n",
    "\n",
    "test_models (list_models,\n",
    "             \"model_name\",\n",
    "             \"estimator\",\n",
    "             \"Doc2Vec\",\n",
    "             X_train_d2v,\n",
    "             X_test_d2v,\n",
    "             y_train_d2v,\n",
    "             y_test_d2v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9917db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e083d432",
   "metadata": {},
   "source": [
    "#### Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfcfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conmparação das pontuações após técnicas de balanceamento\n",
    "# Ordenando a pontuação\n",
    "score.sort(key = lambda y:y[2],reverse =True)\n",
    "\n",
    "# Exibindo a pontuação\n",
    "dfscore = pd.DataFrame (score, columns = ['Modelo', 'Técnica', 'Acurácia'])\n",
    "\n",
    "# Apresenta o modelo que obteve a melhor acurácia\n",
    "print(f'O modelo {dfscore.iloc[0][0]} apresentou a melhor acurácia {dfscore.iloc[0][2]}.\\n')\n",
    "print(\"Comparação da Acurácia dos modelos: \")\n",
    "dfscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dec414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba471b66",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "**Conclusões**\n",
    "\n",
    "Os modelos listados para avaliação foram escolhidos pelo critério de tempo de de processamento e acurácia para uma amostra de 40% do dataframe. \n",
    "\n",
    "A lista pode ser acrescida de outros modelos, porém o tempo de processamento do notebook pode ser extremamente longo, exemplo GradientBoostingClassifier com tempo de processamento superior a 40 min e acurácia similar ao Stochastic Gradient Descent Classifier que executa em segundos.\n",
    "\n",
    "Os modelos foram treinados com as amostras utilizando técnicas para conversão de texto de Bag of Words (BoW) ContVectorizer / TF-IDF e Doc2Vec.\n",
    "\n",
    "O critério de avaliação levou em consideração apenas o maior resultado apresentado pela acurácia do modelo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f72cb",
   "metadata": {},
   "source": [
    "#### Otimização do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb04811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo que apresentou a melhor acurácia\n",
    "\n",
    "#model = LogisticRegression(random_state=random_seed)\n",
    "model = SGDClassifier(n_jobs=-1, max_iter=1000, random_state=random_seed)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921d68a",
   "metadata": {},
   "source": [
    "###### Aplicando **GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e483ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 30 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Definindo valores iniciais para ajuste de parametro de reforço\n",
    "\n",
    "# LogisticRegression\n",
    "# param_gs = {'C': [1, 10, 100], 'penalty': ['l2'], 'max_iter': list(range(100,300,100))}\n",
    "\n",
    "# SGDClassifier\n",
    "param_gs = {'alpha': [0.0001, 0.001, 0.01, 0.1], 'penalty': ['l2'], \"loss\" : [\"hinge\", \"log\", \"modified_huber\"]}\n",
    "\n",
    "\n",
    "# Instanciando GridSearchCV com a variação dos parametros \n",
    "gsearch = GridSearchCV(estimator=model, param_grid=param_gs, scoring='accuracy', refit=True, cv=3, verbose=2)\n",
    "\n",
    "# Treinando o modelo com os conjuntos de dados\n",
    "gsearch.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Apresentação dos melhores parametros e melhor resultado\n",
    "print('\\nPrecisão média: %.5f' % gsearch.best_score_)\n",
    "print('Configuração: %s' % gsearch.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a8151e",
   "metadata": {},
   "source": [
    "##### Aplicando RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a1720",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 30 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# LogisticRegression\n",
    "#param_rs = {'C': [1, 10, 100], 'penalty': ['l2'], 'max_iter': list(range(100,300,100))}\n",
    "\n",
    "# SGDClassifier\n",
    "param_rs = {'alpha': [0.0001, 0.001, 0.01, 0.1], 'penalty': ['l2'], \"loss\" : [\"hinge\", \"log\", \"modified_huber\"]}\n",
    "\n",
    "# Instanciando RandomizedSearchCV com a variação dos parametros \n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_rs, scoring='accuracy', n_iter=100, cv=3, verbose=2)\n",
    "\n",
    "# Treinando o modelo com os conjuntos de dados\n",
    "rsearch.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Apresentação dos melhores parametros e melhor resultado\n",
    "print('\\nPrecisão média: %.5f' % rsearch.best_score_)\n",
    "print('Configuração: %s' % rsearch.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b0a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7010e230",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Conclusões**\n",
    "\n",
    "Após aplicar técnicas com alguns parametros para otimização identificamos o GridSearchCV e RandomizedSearchCV apresentaram o mesmo valor e  não melhoraram a precisão do modelo.\n",
    "\n",
    "Existem diversas combinações de parametros para serem testados que podem melhorar a precisão do modelo, neste notebook abordamos alguns parametros para apresentar a utilização. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb7dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24b9dfb0",
   "metadata": {},
   "source": [
    "#### Predição do arquivo de submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O texto do arquivo (tweet_text) de submissão foi tratado com o mesmo processo do arquivo Train3Classes\n",
    "\n",
    "# Quantidade de linhas e colunas\n",
    "\n",
    "sqtl, sqtc = dfs.shape\n",
    "\n",
    "print(f'Quantidade de linhas...........: {sqtl}')\n",
    "print(f'Quantidade de colunas..........: {sqtc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listagem das primeiras linhas do dataframe\n",
    "\n",
    "dfs[['tweet_text', 'filtered_words', 'join_f_words','num_words_text','num_words_join', 'diff_in_words']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a81dad",
   "metadata": {},
   "source": [
    "**Pré-processamento e transformação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3377a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verificando quais linhas não apresentam valor após o tratamento do texto\n",
    "\n",
    "# Quantidade de linhas vazias\n",
    "qtd, _ = dfs[np.where((dfs['join_f_words'].str.len()<1), True, False)].shape\n",
    "\n",
    "print('Dataframe dfs')\n",
    "print(f'Quantidade de linhas vazias ...: {qtd}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d9423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retirando as linhas que ficaram sem texto para análise\n",
    "dfs = dfs[np.where((dfs['join_f_words'].str.len()>1), True, False)].copy()\n",
    "\n",
    "# Quantidade de linhas vazias\n",
    "qtd, _ = dfs[np.where((dfs['join_f_words'].str.len()<1), True, False)].shape\n",
    "\n",
    "print('Dataframe dfs')\n",
    "print(f'Quantidade de linhas vazias ...: {qtd}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando os valores nulos do dataframe\n",
    "\n",
    "missing_values_table(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad835fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6268a95",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Conclusões**\n",
    "\n",
    "O dataframe de submissão não apresenta valores nulos ou que causariam qualquer problema para o processamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f0579f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51eed249",
   "metadata": {},
   "source": [
    "**Processando os melhores modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9022bdd8",
   "metadata": {},
   "source": [
    "**Stochastic Gradient Descent Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2fa687",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Definição do modelo\n",
    "model = SGDClassifier(loss='modified_huber', n_jobs=-1, random_state=42)\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Definição dos dados numa matriz X_subm que contém o texto do novo dataframe\n",
    "X_subm = dfs['join_f_words']\n",
    "X_subm_tfidf = tfidf.transform(X_subm).todense()\n",
    "\n",
    "# Predição de sentimentos do texo\n",
    "y_predict_subm = model.predict(X_subm_tfidf)\n",
    "\n",
    "# Cria a coluna de predição logistica\n",
    "dfs[\"predict_SGDC\"] = y_predict_subm\n",
    "\n",
    "# Cria dataframe de resposta  \n",
    "df_SGDC = dfs[['id', 'predict_SGDC']]\n",
    "df_SGDC.rename(columns = {'predict_SGDC':'sentiment_predict'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5077a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91e60ddf",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Definição do modelo\n",
    "model = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "# Treinando o modelo \n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Definição dos dados numa matriz X_subm que contém o texto do novo dataframe\n",
    "X_subm = dfs['join_f_words']\n",
    "X_subm_tfidf = tfidf.transform(X_subm).todense()\n",
    "\n",
    "# Predição de sentimentos do texo\n",
    "y_predict_subm = model.predict(X_subm_tfidf)\n",
    "\n",
    "# Cria a coluna de predição logistica\n",
    "dfs['predict_LR'] = y_predict_subm\n",
    "\n",
    "# Cria dataframe de resposta  \n",
    "df_LR = dfs[['id', 'predict_LR']]\n",
    "df_LR.rename(columns = {'predict_LR':'sentiment_predict'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d826a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grava dataframe de resposta\n",
    "\n",
    "# Definindo o nome do arquivo\n",
    "file_name_LR = './dados/subm/johnny_horita_780_projeto_2_submissao_LR.csv'\n",
    "file_name_SGDC = './dados/subm/johnny_horita_780_projeto_2_submissao_SGDC.csv'\n",
    "\n",
    "# Salvando o CSV\n",
    "try:\n",
    "    # Gravando o dataframe em CSV\n",
    "    df_LR.to_csv(file_name_LR, index=False)\n",
    "    df_SGDC.to_csv(file_name_SGDC, index=False)\n",
    "    print(f'DataFrame gravado com successo.\\n')\n",
    "        \n",
    "except:\n",
    "    print(\"Ocorreu um erro na gravação.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036fcedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(dfs[dfs['query_used']==':)']))\n",
    "print(len(dfs[dfs['predict_SGDC']==1]))\n",
    "\n",
    "print(len(dfs[dfs['query_used']==':(']))\n",
    "print(len(dfs[dfs['predict_SGDC']==0]))\n",
    "\n",
    "print(len(dfs[(dfs['query_used']!=':(') & (dfs['query_used']!=':)')]))\n",
    "print(len(dfs[dfs['predict_SGDC']==2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe23f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(dfs[dfs['query_used']==':)']))\n",
    "print(len(dfs[dfs['predict_LR']==1]))\n",
    "\n",
    "print(len(dfs[dfs['query_used']==':(']))\n",
    "print(len(dfs[dfs['predict_LR']==0]))\n",
    "\n",
    "print(len(dfs[(dfs['query_used']!=':(') & (dfs['query_used']!=':)')]))\n",
    "print(len(dfs[dfs['predict_LR']==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cfa52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(dfs[dfs['query_used']==':(']))\n",
    "print(len(dfs[dfs['predict_LR']==0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e1a4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa28f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(dfc[dfc['query_used']==':)']))\n",
    "print(len(dfc[dfc['sentiment']==1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(dfc[dfc['query_used']==':)']))\n",
    "print(len(dfc[dfc['sentiment']==1]))\n",
    "\n",
    "print(len(dfc[dfc['query_used']==':(']))\n",
    "print(len(dfc[dfc['sentiment']==0]))\n",
    "\n",
    "print(len(dfc[(dfc['query_used']!=':(') & (dfc['query_used']!=':)')]))\n",
    "print(len(dfc[dfc['sentiment']==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14763b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfc[(dfc['query_used']!=':(') & (dfc['query_used']!=':)')]))\n",
    "print(len(dfc[dfc['sentiment']==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['query_used_sentiment'] = df['dollars_spent'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "dfc.loc[dfc['query_used']==':(', 'c2'] = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca8bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Counter(dfc['query_used'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d49a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d9c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbcf8b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a7240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9646d853",
   "metadata": {},
   "source": [
    "## 5. Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8106f22",
   "metadata": {},
   "source": [
    "No decorrer deste notebook foram criadas diversas células para descrever as conclusões dos processos, abaixo complemento de forma integrada e resumida as conclusões do projeto.\n",
    "\n",
    "Em análise de consistência dos dados, efetuei carga dos arquivos Train3Classes.csv e Subm3Classes.csv e verifiquei as informações básicas dos arquivos, como quantidade de variáveis (colunas), valores duplicados e valores faltantes (nan). \n",
    "\n",
    "Em Pré-processamento e transformações, criei variáveis auxiliares para aplicar técnicas de normalização, stemming, tokenização, stopwords, retirada de caracteres especiais, e-mails e urls na variável **tweet_text**.\n",
    "Tratei os dataframes com a exclusão de linhas duplicadas e colunas que não são necessárias para o modelo.\n",
    "\n",
    "No processo de EAD (Análise exploratória de dados) analisei a quantidade de tweets por sentimentos e identifiquei que a amostra  esta balanceada com a quantiddade de sentimentos negativos, positivos e neutros.\n",
    "Outro item interessante que a variável query_used foi utilizada para determinar um valor numérico para agrupar os sentimentos.\n",
    "Analisei as palavras mais utilizadas nos tweets e as palavras mais utilizadas por sentimento com base nesses estudos gerei gráficos para facilitar a visualização e a nuvem de palavras. \n",
    "\n",
    "Em treinamento do modelo, devido a grande quantidade de registros e palavras utilizei uma amostra de 40% do dataframe (sample(frac=0.4), submeti a amostra de treino e teste com técnicas de **CountVectorizer**, **TfidfVectorizer** e **Doc2Vec** a diversos modelos para identificar a melhor acurácia, este foi o único critério de pontuação para determinar a escolha do modelo.\n",
    "Nos diversos testes 2 modelos apresentaram a melhor acurácia que foram **Logistic Regression** e **Stochastic Gradient Descent Classifier**.\n",
    "Para otimizar o modelo foram utilizados o **GridSearchCV** e **RandomizedSearchCV**, porém não presentaram melhoras.\n",
    "\n",
    "Com as técnicas acima conseguimos obter os seguintes resultados:\n",
    "\n",
    "**<center>Stochastic Gradient Descent</center>**\n",
    "\n",
    "|  | precision | recall | f1-score | support |\n",
    "| -: | -: | -: | -: | -: |\n",
    "| 0 | 0.57 | 0.60 | 0.59 | 8752 |\n",
    "| 1 | 0.59 | 0.56 | 0.58 | 8972 |\n",
    "|    accuracy |  |  | 0.58 | 17724\n",
    "|   macro avg | 0.58 | 0.58 | 0.58 | 17724\n",
    "|weighted avg | 0.58 | 0.58 | 0.58 | 17724\n",
    "\n",
    "<br>\n",
    "\n",
    "**<center>Logistic Regression</center>**\n",
    "\n",
    "|  | precision | recall | f1-score | support |\n",
    "| -: | -: | -: | -: | -: |\n",
    "| 0 | 0.58 | 0.56 | 0.57 | 8752 |\n",
    "| 1 | 0.58 | 0.60 | 0.59 | 8972 |\n",
    "|    accuracy |  |  | 0.58 | 17724\n",
    "|   macro avg | 0.58 | 0.58 | 0.58 | 17724\n",
    "|weighted avg | 0.58 | 0.58 | 0.58 | 17724\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6114f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
