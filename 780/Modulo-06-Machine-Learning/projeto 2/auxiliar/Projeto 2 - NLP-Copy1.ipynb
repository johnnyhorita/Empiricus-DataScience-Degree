{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362c03d1",
   "metadata": {},
   "source": [
    "# Projeto 2 - NLP\n",
    "\n",
    "-----\n",
    "\n",
    "Nome:  Johnny Hideki Horita <br>\n",
    "Turma: 780"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517a372",
   "metadata": {},
   "source": [
    "Os segundo projeto do módulo de Machine Learning será focado no processamento de linguagem natural! Usaremos os algoritmos aprendidos e as técnicas vistas na segunda parte do curso para extrairmos informações relevantes de texto. Mais precisamente, de publicações no Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a3a98",
   "metadata": {},
   "source": [
    "## Os Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d5657",
   "metadata": {},
   "source": [
    "Utilizaremos um Dataset obtido do Twitter com 100K postagens entre os dias 01/08/2018 e 20/10/2018. Cada postagem é classificada como **positiva**, **negativa** ou **neutra**.  \n",
    "\n",
    "Dois arquivos serão disponilizados para o desenvolvimento dos modelos, um para treino/validação e outro para submissão. Os arquivos se encontram na pasta */Dados/train* e */Dados/subm*, respectivamente.\n",
    "\n",
    "Descrição das colunas:\n",
    "\n",
    "- **id**: ID único para o tweet  \n",
    "- **tweet_text**: Texto da publicação no Twitter  \n",
    "- **tweet_date**: Data da publicação no Twitter  \n",
    "- **sentiment**: 0, se negativo; 1, se positivo; 2, se neutro  \n",
    "- **query_used**: Filtro utilizado para buscar a publicação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc86eb5",
   "metadata": {},
   "source": [
    "## O Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e1f6f",
   "metadata": {},
   "source": [
    "Você deverá desenvolver um modelo para detectar o sentimento de uma publicação do Twitter a classificando em uma das três categorias: **positiva**, **negativa** ou **neutra**. O texto da publicação está disponível na coluna \"tweet_text\". Teste pelo menos 3 técnicas de NLP diferentes e escolha a métrica de avaliação que julgar mais pertinente.  \n",
    "\n",
    "Escolha o melhor modelo e gere uma base a partir dos dados de submissão, que estão no caminho ```Dados/subm/Subm3Classes.csv```, com o seguinte formato:\n",
    "\n",
    "\n",
    "|id|sentiment_predict\n",
    "|-|-|\n",
    "|12123232|0\n",
    "|323212|1\n",
    "|342235|2\n",
    "\n",
    "Salve essa tabela como um arquivo csv com o nome ```<nome>_<sobrenome>_nlp_degree.csv``` e submeta-o como parte da entrega final do projeto.  \n",
    "\n",
    "Para ajudar no desenvolvimento, é possível dividir o projeto em algumas fases:\n",
    "\n",
    "- **Análise de consistência dos dados**: analise se os dados estão fazendo sentido, se os campos estão completos e se há dados duplicados ou faltantes. Se julgar necessário, trate-os.    \n",
    "\n",
    "\n",
    "- **Análise exploratória**: analise a sua base como um todo, verifique o balanceamento entre as classes e foque, principalmente, na coluna ```tweet_text```.    \n",
    "\n",
    "\n",
    "- **Pré-processamento e transformações**: projetos de NLP exigem um considerável pré-processamento. Foque no tratamento da string do texto. Procure começar com tratamentos simples e adicione complexidade gradualmente. Nessa etapa você testará diferentes técnicas de transformações, como o Bag Of Words e o TF-IDF.    \n",
    "\n",
    "\n",
    "- **Treinamento do modelo**: depois das transformações, você poderá executar o treinamento do modelo classificador. Nessa etapa o problema se torna semelhante aos abordados na primeira parte do módulo. Você pode testar diversos classificadores como RandomForest, AdaBoost, entre outros. Otimize os hiperparâmetros do modelo com técnicas como a GridSearch e a RandomizedSearch.    \n",
    "\n",
    "\n",
    "- **Conclusões**: descreva, em texto, as conclusões sobre os seus estudos. O modelo é capaz de identificar o sentimento das publicações? É possível extrapolar o modelo para outros contextos, como a análise de sentimento de uma frase qualquer? Pense em questões pertinentes e relevantes que você tenha obtido durante o desenvolvimento do projeto!     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283638c9",
   "metadata": {},
   "source": [
    "## Critérios de avaliação\n",
    "\n",
    "Os seguintes itens serão avaliados:\n",
    "\n",
    "1. Desenvolvimento das etapas descritas acima;\n",
    "\n",
    "\n",
    "2. Reprodutibilidade do código: seu código será executado e precisa gerar os mesmos resultados apresentados por você;\n",
    "\n",
    "\n",
    "3. Clareza: seu código precisa ser claro e deve existir uma linha de raciocínio direta. Comente o código em pontos que julgar necessário para o entendimento total;\n",
    "\n",
    "\n",
    "4. Justificativa das conclusões obitdas: não existirá certo ou errado, mas as decisões e as conclusões precisam ser bem justificadas com base nos resultados obtidos.  \n",
    "\n",
    "O desempenho do modelo **não** será considerado como critério de avaliação.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6049a9c",
   "metadata": {},
   "source": [
    "## Informações gerais\n",
    "\n",
    "- O projeto deve ser desenvolvido individualmente;\n",
    "\n",
    "\n",
    "- Data de divulgação: 11/01/2022;\n",
    "\n",
    "\n",
    "- Aula de monitoria: 19/01/2022;\n",
    "\n",
    "\n",
    "- Data de entrega: 26/01/2022;\n",
    "\n",
    "\n",
    "- Entrega através do Class: Árvore de Decisão -> Exercícios -> Projeto 2\n",
    "\n",
    "\n",
    "Anexar, na entrega, o notebook de desenvolvimento e o arquivo .csv de submissão, da seguinte forma:  \n",
    "\n",
    "notebook: ```<nome>_<sobrenome>_<númeroTurma>_projeto_2.ipynb```   \n",
    "csv: ```<nome>_<sobrenome>_<númeroTurma>_projeto_2_submissao.csv```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb23437",
   "metadata": {},
   "source": [
    "## Dicas\n",
    "\n",
    "### Base de treino e submissão\n",
    "\n",
    "A base de submissão não possui a variável de saída, portanto ela será utilizada **apenas** para gerar o arquivo que acompanha a submissão do projeto.      \n",
    "\n",
    "### Tente encontrar possíveis vieses\n",
    "\n",
    "É muito comum que modelos de NLP possuam fortes vieses, como a tendência de relacionar palavras específicas com alguma classe de saída. Tente encontrar vieses no seu estudo, isso pode ajudar a tirar boas conclusões. o campo \"query_used\" pode ser útil para essa análise.  \n",
    "\n",
    "### O pré-processamento é a chave para um bom desempenho\n",
    "\n",
    "Essa é a etapa que mais vai contribuir para o desempenho do seu modelo. Seja criativo e desenvolva essa etapa de uma maneira que seja fácil de aplicar o mesmo processamento para uma nova base, você terá que fazer isso para gerar a base de submissão.\n",
    "\n",
    "### Um termômetro para o seu desenvolvimento\n",
    "\n",
    "Após a correção do seu projeto, o professor irá disponibilizar a sua acurácia obtida na base de submissão. Você pode interpretar esse resultado como a simulação do resultado do seu modelo em produção. Uma diferença entre o resultado do estudo e o resultado de submissão indica um grau de **overfitting** no seu modelo.\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96911dea",
   "metadata": {},
   "source": [
    "# Desenvolvimento do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d5233",
   "metadata": {},
   "source": [
    "## 1. Análise de consistência dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f25c3d",
   "metadata": {},
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad89b883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas carregadas com sucesso.\n",
      "Wall time: 8.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Bibliotecas\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import requests\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import squarify\n",
    "import plotly.offline as py\n",
    "import plotly_express as px\n",
    "from plotly import graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, f1_score, r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score, StratifiedKFold, cross_validate\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC \n",
    "# Naive Bayes (Gaussian, Multinomial)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Stochastic Gradient Descent Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# KNN (k-nearest neighbor)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# XGBoost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "# LGBM Classifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# Ada Boosting Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Dummy Boosting Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from unidecode import unidecode\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#!pip install enelvo\n",
    "from enelvo.normaliser import Normaliser\n",
    "\n",
    "# Abaixo seguem 2 formas para a instalação do spaCy: via conda ou pip\n",
    "# Instalação utilizando conda\n",
    "#!conda install -c conda-forge spacy\n",
    "\n",
    "# Instalação utilizando Pip\n",
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "\n",
    "import spacy\n",
    "from spacy.util import compounding\n",
    "from spacy.util import minibatch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import shap\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from IPython.core.display import HTML as Center\n",
    "from IPython.display import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Bibliotecas carregadas com sucesso.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1272b9b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Padrões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51314fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Definição de padrões para gráficos e cores\n",
    "\n",
    "sns.set_style('darkgrid') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=13)    # legend fontsize\n",
    "plt.rc('font', size=13)          # controls default text sizes\n",
    "\n",
    "colors = sns.color_palette(\"pastel\") # deep, pastel, Set1 Set2 Set3, icefire, tab10, muted, colorlind, coolwarm\n",
    "cmap_colors = 'GnBu'\n",
    "\n",
    "font_path = \"./fonts/CabinSketch-Bold.ttf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e73245",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       " <style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definição de padrões para centralização de gráficos no notebook\n",
    "\n",
    "Center(\"\"\" <style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style> \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9473b925",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Definição de variáveis auxiliares\n",
    "\n",
    "rollback = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c2874",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3054506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de avaliação dos valores de NaN no dataframe\n",
    "\n",
    "def missing_values_table(df):\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        mz_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mz_table = mz_table.rename(\n",
    "        columns = {0 : 'Valores faltantes', 1 : '% de Valores Totais'})\n",
    "        mz_table['Data Type'] = df.dtypes\n",
    "        mz_table = mz_table[\n",
    "            mz_table.iloc[:,1] != 0].sort_values(\n",
    "        '% de Valores Totais', ascending=False).round(1)\n",
    "        print (\"O dataframe tem \" + str(df.shape[1]) + \" colunas e \" + str(df.shape[0]) + \" linhas.\\n\"      \n",
    "            \"Existem \" + str(mz_table.shape[0]) +\n",
    "              \" colunas que têm valores faltantes.\")\n",
    "        mz_table.to_excel('missing_and_zero_values.xlsx', freeze_panes=(1,0), index = True)\n",
    "        return mz_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaae7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de avaliação de modelos de aprendizagem de máquinas\n",
    "\n",
    "def test_models_plot_roc_auc_curve(model_list, col_model_name, col_model, X_train, X_test, y_train, y_test):\n",
    "    plt.figure(figsize=(15,7))\n",
    "    for mdl in model_list:\n",
    "        model = mdl[col_model]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        y_predproba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "        #fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predproba)\n",
    "        #auc = metrics.roc_auc_score(y_test, y_predict)\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.accuracy_curve(y_test, y_predproba)        \n",
    "        auc = metrics.accuracy_score(y_test, y_predict)\n",
    "        \n",
    "        plt.plot(fpr, tpr, label='%s ROC (AUC = %0.4f)' % (mdl[col_model_name], auc))\n",
    "        print(\"Model      : %s\" % mdl[col_model_name])\n",
    "        calc_predict(mdl[col_model_name], y_test, y_predict)\n",
    "        \n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC-AUC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61537f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de avaliação de modelos apresentação da matriz de confusão\n",
    "\n",
    "def test_models_plot_confusion_matrix(model_list, col_model_name, col_model, X_train, X_test, y_train, y_test):\n",
    "    for mdl in model_list:\n",
    "        model = mdl[col_model]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        \n",
    "        print(\"\")        \n",
    "        print(\"=\" * 55)        \n",
    "        print(\"Model      : %s\" % mdl[col_model_name])\n",
    "        calc_predict(mdl[col_model_name], y_test, y_predict)\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_predict)\n",
    "        cm_matrix = pd.DataFrame(data=cm, columns=['Atual Positivo:1', 'Atual Negativo:0'], \n",
    "                                         index=['Pred. Positivo:1', 'Pred. Negativo:0'])\n",
    "\n",
    "        print('Matriz Confusão\\n\\n', cm)\n",
    "        print('\\nV. Positivos(VP) = ', cm[0,0])\n",
    "        print('V. Negativos(VN) = ', cm[1,1])\n",
    "        print('F. Positivos(FP) = ', cm[0,1])\n",
    "        print('F. Negativos(FN) = ', cm[1,0])\n",
    "\n",
    "        sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a3ea476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para cálcular as métricas \n",
    "\n",
    "def calc_predict(col_model_name, y_test, y_predict):\n",
    "    #print(\"ROC - AUC  : %0.4f \" % metrics.roc_auc_score(y_test, y_predict))\n",
    "    print(\"Accuracy   : %0.4f \" %  accuracy_score(y_test, y_predict))\n",
    "    print(\"Precision  : %0.4f \" % precision_score(y_test, y_predict, average='weighted'))\n",
    "    print(\"Recall     : %0.4f \" % recall_score(y_test, y_predict, average='weighted'))\n",
    "    print(\"F1 - Score : %0.4f \" % f1_score(y_test, y_predict, average='weighted'))\n",
    "    print(\"MAE        : %0.4f \" % mean_absolute_error(y_test, y_predict))\n",
    "    print(\"RMSE       : %0.4f \" % np.sqrt(mean_squared_error(y_test, y_predict)))\n",
    "    print(\"R2         : %0.4f \" % r2_score(y_test, y_predict))\n",
    "    print(\"\")\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    print(\"=\" * 55)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f11adbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a importância da variável no modelo\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "def modelfit(alg, dtrain, predictors, target, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    # Adequando as classes para treino\n",
    "    alg.fit(dtrain[predictors], dtrain[target])\n",
    "        \n",
    "    # Previsão de saída para o conjunto de dados de teste\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    # Utilizando o Cross Validation\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, dtrain[predictors], dtrain[target], cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Exibindo relatório:\n",
    "    print (f\"\\nRelatório do Modelo {alg}\")\n",
    "    print (\"\\nAcuracia : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "    #print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predictions))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "        \n",
    "    #Exibindo gráfico da importancia das variáveis\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Importância das variáveis', color=colors)\n",
    "        plt.ylabel('Pontuação')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52180e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para geração de cores\n",
    "\n",
    "def random_colours(number_of_colors):\n",
    "    '''\n",
    "    Função simples para geração de cores aleatórias.\n",
    "    Entrada:\n",
    "        número_de_cores - valor inteiro indicando o número de cores que vão ser geradas.\n",
    "    Saída:\n",
    "        Cor no seguinte formato: ['#E86DA4'].\n",
    "        \n",
    "    '''\n",
    "    colors = []\n",
    "    for i in range(number_of_colors):\n",
    "        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n",
    "    return colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc2553f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para contagem de palavras \n",
    "\n",
    "def words_unique(sentiment, numwords, raw_words):\n",
    "    '''\n",
    "    Entrada:\n",
    "        segmento - Categoria do segmento (ex. 2 = 'Neutro');\n",
    "        numwords - quantas palavras específicas se pretende ver no resultado final; \n",
    "        raw_words - lista do texto;\n",
    "        \n",
    "    Resultado: \n",
    "        dataframe com informação sobre a palavra específica e quantas vezes aparece no texto (por ordem decrescente com base nas suas contagens).\n",
    "\n",
    "    '''\n",
    "    allother = []\n",
    "    for item in dfc[dfc.sentiment != sentiment]['list_words']:\n",
    "        for word in item:\n",
    "            allother .append(word)\n",
    "    allother  = list(set(allother ))\n",
    "    \n",
    "    specificnonly = [x for x in raw_text if x not in allother]\n",
    "    \n",
    "    mycounter = Counter()\n",
    "    \n",
    "    for item in dfc[dfc.sentiment == sentiment]['list_words']:\n",
    "        for word in item:\n",
    "            mycounter[word] += 1\n",
    "    keep = list(specificnonly)\n",
    "    \n",
    "    for word in list(mycounter):\n",
    "        if word not in keep:\n",
    "            del mycounter[word]\n",
    "    \n",
    "    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n",
    "    \n",
    "    return Unique_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "922f869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\johnny.horita\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\johnny.horita\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Abaixo seguem 2 formas para a instalação do spaCy: via conda ou pip\n",
    "\n",
    "# Instalação utilizando conda\n",
    "#!conda install -c conda-forge spacy\n",
    "\n",
    "# Instalação utilizando Pip\n",
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "\n",
    "# Bilbioteca em portugues\n",
    "# Efficiency\n",
    "#!python -m spacy download pt_core_news_sm\n",
    "\n",
    "# Accuracy\n",
    "#!python -m spacy download pt_core_news_lg\n",
    "\n",
    "spc_pt = spacy.load('pt_core_news_lg')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "#Adicionando stopwords que não estão na lista do nltk \n",
    "stopwords.append(\"'\")\n",
    "stopwords.append(\"pra\")\n",
    "stopwords.append(\"tá\")\n",
    "stopwords.append(\"tão\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad860da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para tratamento da variável de texto para definir melhores valores para classificação da modelagem\n",
    "# e ou normalizar o tratamento da variável de texto utilizando a biblioteca enelvo\n",
    "\n",
    "# instanciando\n",
    "normalizador = Normaliser(tokenizer='readable', sanitize=True, capitalize_acs=True, capitalize_pns=True) # capitalize_inis=True\n",
    "\n",
    "def nlp_tratar_texto(texto, normalize=False):\n",
    "    #Remover endereços de sites\n",
    "    texto_sem_url = re.sub(r'https?:\\/\\/\\S+', '', texto)\n",
    "        \n",
    "    #Remover e-mail / users\n",
    "    #texto_sem_email = re.sub(r'[A-Za-z0-9]*@[A-Za-z]*\\.?[A-Za-z0-9]*\\.?[A-Za-z0-9]*', '', texto_sem_url)\n",
    "    texto_sem_email = re.sub(r'[A-Za-z0-9]*@\\S+', '', texto_sem_url)\n",
    "    \n",
    "    if normalize==True:\n",
    "        # Tratamento do texto utilizando o enelvo (Normalize)\n",
    "        texto_norm = normalizador.normalise(texto_sem_email)\n",
    "    \n",
    "        #Remover caracteres que não são letras e tokenização\n",
    "        texto_tratado =  re.findall(r'\\b[A-zÀ-úü]+\\b', texto_norm.lower())\n",
    "    else:\n",
    "        texto_tratado =  re.findall(r'\\b[A-zÀ-úü]+\\b', texto_sem_email.lower())\n",
    "\n",
    "    #Remover stopwords\n",
    "    stop = set(stopwords)\n",
    "    palavras = [w for w in texto_tratado if w not in stop]\n",
    "    palavras_string = \" \".join(palavras)\n",
    "\n",
    "    #Instanciar o objeto spacy\n",
    "    spc_letras =  spc_pt(palavras_string)\n",
    "\n",
    "    #Lemmização \n",
    "    tokens = [token.lemma_ if token.pos_ == 'VERB' else str(token) for token in spc_letras]\n",
    "\n",
    "    #problemas com verbo ir\n",
    "    ir = ['vou', 'vais', 'vai', 'vamos', 'ides', 'vão']\n",
    "    tokens = ['ir' if token in ir else str(token) for token in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a733446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para apresentar nuvem de palavras\n",
    "\n",
    "def plot_wordcloud(text, title = None, backcolor = 'white', clrmap = ''):\n",
    "\n",
    "    wordcloud = WordCloud(\n",
    "                            background_color=backcolor,\n",
    "                            width=2000, \n",
    "                            height=800,\n",
    "                            colormap=clrmap, \n",
    "                            font_path=font_path, \n",
    "                            collocations = False)\n",
    "\n",
    "    wordcloud.generate(text)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c39e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e738a2b7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Inicializando Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39c224f3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Importando arquivo\n",
    "\n",
    "df = pd.read_csv('./dados/train/Train3Classes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efd96274",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de linhas...........: 95000\n",
      "Quantidade de linhas duplicadas: 0\n",
      "Quantidade de colunas..........: 5\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtl, qtc = df.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "\n",
    "qtd, _ = df[df.duplicated(keep=False)].shape\n",
    "\n",
    "print(f'Quantidade de linhas...........: {qtl}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtd}')\n",
    "print(f'Quantidade de colunas..........: {qtc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daf0b35b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95000 entries, 0 to 94999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          95000 non-null  int64 \n",
      " 1   tweet_text  95000 non-null  object\n",
      " 2   tweet_date  95000 non-null  object\n",
      " 3   sentiment   95000 non-null  int64 \n",
      " 4   query_used  95000 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95aba7f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataframe tem 5 colunas e 95000 linhas.\n",
      "Existem 0 colunas que têm valores faltantes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores faltantes</th>\n",
       "      <th>% de Valores Totais</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Valores faltantes, % de Valores Totais, Data Type]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando os valores nulos do dataframe\n",
    "\n",
    "missing_values_table(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abf0cc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "O dataframe é composto por 05 colunas e 95.000 registros.\n",
    "\n",
    "A tabela acima NÃO apresenta valores faltantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c26c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc5d77c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tweet_text', 'tweet_date', 'sentiment', 'query_used'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de colunas do dataframe\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c9ae92d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1049721159292346368</td>\n",
       "      <td>Rio elege maior bancada policial de sua histór...</td>\n",
       "      <td>Tue Oct 09 18:00:01 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>folha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046251157025423360</td>\n",
       "      <td>fiquei tão triste quando eu vi o preço da câme...</td>\n",
       "      <td>Sun Sep 30 04:11:28 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041744620206653440</td>\n",
       "      <td>Para Theresa May, seu plano para o Brexit é a ...</td>\n",
       "      <td>Mon Sep 17 17:44:06 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>exame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046937084727107589</td>\n",
       "      <td>caralho eu quero proteger a danielly em um pot...</td>\n",
       "      <td>Tue Oct 02 01:37:06 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1047326854229778432</td>\n",
       "      <td>@SiCaetano_ viva o caos :)</td>\n",
       "      <td>Wed Oct 03 03:25:55 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         tweet_text  \\\n",
       "0  1049721159292346368  Rio elege maior bancada policial de sua histór...   \n",
       "1  1046251157025423360  fiquei tão triste quando eu vi o preço da câme...   \n",
       "2  1041744620206653440  Para Theresa May, seu plano para o Brexit é a ...   \n",
       "3  1046937084727107589  caralho eu quero proteger a danielly em um pot...   \n",
       "4  1047326854229778432                         @SiCaetano_ viva o caos :)   \n",
       "\n",
       "                       tweet_date  sentiment query_used  \n",
       "0  Tue Oct 09 18:00:01 +0000 2018          2      folha  \n",
       "1  Sun Sep 30 04:11:28 +0000 2018          0         :(  \n",
       "2  Mon Sep 17 17:44:06 +0000 2018          2      exame  \n",
       "3  Tue Oct 02 01:37:06 +0000 2018          0         :(  \n",
       "4  Wed Oct 03 03:25:55 +0000 2018          1         :)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listagem das primeiras linhas do dataframe\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5fbcb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5811661",
   "metadata": {},
   "source": [
    "## 2. Pré-processamento e transformações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a59eb",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Tratamento de variáveis**\n",
    "\n",
    "- Criação da variável **filtered_words**, onde o texto original (tweet_text) será submetido a tratamentos para definir as palavras chaves de sentimento para melhorar a classificação do modelo;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **join_f_words**, para concatenar as palavras do coluna **filtered_words**;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **normalize_words**, para normalizar a coluna **join_f_words** utilizando a biblioteca **enelvo**;<br>\n",
    "\n",
    "\n",
    "- Exclusão de variáveis que entendemos não ser relevante para o modelo<br>\n",
    "    **id**: ID único para o tweet<br>\n",
    "    **tweet_date**: Data da publicação no Twitter<br>\n",
    "    **query_used**: Filtro utilizado para buscar a publicação<br>\n",
    "\n",
    "\n",
    "- Exclusão de variáveis tratadas<br>\n",
    "    **tweet_text**: Texto da publicação no Twitter<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d247977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# O tratamendo dos tweets leva em média 10 min, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Cria uma nova variável utilizando funções para tratamento das palavras do texto\n",
    "df['filtered_words'] = df['tweet_text'].apply(lambda w: nlp_tratar_texto(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0afad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma nova variável concatenando os tokens gerados pelo tratamento das palavras gerando um novo texto reduzido\n",
    "\n",
    "df['join_f_words'] = df['filtered_words'].apply(lambda w: ' '.join(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3effc2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# O tratamendo dos tweets utilizando o biblioteca enelvo leva em média 4 horas, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Cria uma nova variável normalizando os tokens do novo texto reduzido\n",
    "\n",
    "#df['normalize_words'] = df['join_f_words'].apply(lambda w: nlp_normalizar_texto(w))\n",
    "#df['normalize_words'] = df['tweet_text'].apply(lambda w: nlp_tratar_texto(w, normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a43d679f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>join_f_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rio elege maior bancada policial de sua história https://t.co/sGXnhZKrHx https://t.co/Mcgiz70jPF</td>\n",
       "      <td>[rio, eleger, maior, bancada, policial, história]</td>\n",
       "      <td>rio eleger maior bancada policial história</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fiquei tão triste quando eu vi o preço da câmera :((((</td>\n",
       "      <td>[ficar, triste, vir, preço, câmera]</td>\n",
       "      <td>ficar triste vir preço câmera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Para Theresa May, seu plano para o Brexit é a única opção https://t.co/epl39YD9bj</td>\n",
       "      <td>[theresa, may, plano, brexit, única, opção]</td>\n",
       "      <td>theresa may plano brexit única opção</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caralho eu quero proteger a danielly em um pote tadinhaa :(</td>\n",
       "      <td>[caralho, querer, proteger, danielly, pote, tadinhaa]</td>\n",
       "      <td>caralho querer proteger danielly pote tadinhaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@SiCaetano_ viva o caos :)</td>\n",
       "      <td>[vivo, caos]</td>\n",
       "      <td>vivo caos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94995</th>\n",
       "      <td>Cuba e defensor de direitos humanos se unem contra chefe da OEA, intervenção militar na Venezuela. https://t.co/Lo2RvIgFBA https://t.co/CiPddCuRvw</td>\n",
       "      <td>[cuba, defensor, direitos, humanos, unir, contra, chefe, oea, intervenção, militar, venezuela]</td>\n",
       "      <td>cuba defensor direitos humanos unir contra chefe oea intervenção militar venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94996</th>\n",
       "      <td>#Oportunidade ➡️ Venha fazer parte da nossa equipe! Vagas abertas para alunos de Administração. Envie seu currículo e comprovante de matrícula para análise prévia até às 12h do dia 24/08, para o e-mail: vagasestagio@sistemafieto.com.br 😉 https://t.co/qvdFYeJh9I</td>\n",
       "      <td>[oportunidade, vir, fazer, parte, equipe, vagas, aberto, alunos, administração, enviar, currículo, comprovante, matrícula, análise, prévia, dia, mail]</td>\n",
       "      <td>oportunidade vir fazer parte equipe vagas aberto alunos administração enviar currículo comprovante matrícula análise prévia dia mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94997</th>\n",
       "      <td>@96syoo EU SEI 😭😭 é por isso que significa muito!! To feliz demais, eu amo ela :( e aqui da pra ver que ela deixa a bandeira na frente do palco e sai correndo pra pegar garrafa de água mas depois disso ela pegou de novo 😂 https://t.co/82oPAXYVNC</td>\n",
       "      <td>[saber, significar, to, feliz, demais, amar, aqui, ver, deixar, bandeira, frente, palco, sair, correr, pegar, garrafa, água, disso, pegar, novo]</td>\n",
       "      <td>saber significar to feliz demais amar aqui ver deixar bandeira frente palco sair correr pegar garrafa água disso pegar novo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94998</th>\n",
       "      <td>@louistsexhes N te conheço mas posta :D</td>\n",
       "      <td>[n, conhecer, posto, d]</td>\n",
       "      <td>n conhecer posto d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94999</th>\n",
       "      <td>meu deus :( https://t.co/BlXazxZeKq</td>\n",
       "      <td>[deus]</td>\n",
       "      <td>deus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                  tweet_text  \\\n",
       "0      Rio elege maior bancada policial de sua história https://t.co/sGXnhZKrHx https://t.co/Mcgiz70jPF                                                                                                                                                                        \n",
       "1      fiquei tão triste quando eu vi o preço da câmera :((((                                                                                                                                                                                                                  \n",
       "2      Para Theresa May, seu plano para o Brexit é a única opção https://t.co/epl39YD9bj                                                                                                                                                                                       \n",
       "3      caralho eu quero proteger a danielly em um pote tadinhaa :(                                                                                                                                                                                                             \n",
       "4      @SiCaetano_ viva o caos :)                                                                                                                                                                                                                                              \n",
       "...                           ...                                                                                                                                                                                                                                              \n",
       "94995  Cuba e defensor de direitos humanos se unem contra chefe da OEA, intervenção militar na Venezuela. https://t.co/Lo2RvIgFBA https://t.co/CiPddCuRvw                                                                                                                      \n",
       "94996  #Oportunidade ➡️ Venha fazer parte da nossa equipe! Vagas abertas para alunos de Administração. Envie seu currículo e comprovante de matrícula para análise prévia até às 12h do dia 24/08, para o e-mail: vagasestagio@sistemafieto.com.br 😉 https://t.co/qvdFYeJh9I   \n",
       "94997  @96syoo EU SEI 😭😭 é por isso que significa muito!! To feliz demais, eu amo ela :( e aqui da pra ver que ela deixa a bandeira na frente do palco e sai correndo pra pegar garrafa de água mas depois disso ela pegou de novo 😂 https://t.co/82oPAXYVNC                   \n",
       "94998  @louistsexhes N te conheço mas posta :D                                                                                                                                                                                                                                 \n",
       "94999  meu deus :( https://t.co/BlXazxZeKq                                                                                                                                                                                                                                     \n",
       "\n",
       "                                                                                                                                               filtered_words  \\\n",
       "0      [rio, eleger, maior, bancada, policial, história]                                                                                                        \n",
       "1      [ficar, triste, vir, preço, câmera]                                                                                                                      \n",
       "2      [theresa, may, plano, brexit, única, opção]                                                                                                              \n",
       "3      [caralho, querer, proteger, danielly, pote, tadinhaa]                                                                                                    \n",
       "4      [vivo, caos]                                                                                                                                             \n",
       "...             ...                                                                                                                                             \n",
       "94995  [cuba, defensor, direitos, humanos, unir, contra, chefe, oea, intervenção, militar, venezuela]                                                           \n",
       "94996  [oportunidade, vir, fazer, parte, equipe, vagas, aberto, alunos, administração, enviar, currículo, comprovante, matrícula, análise, prévia, dia, mail]   \n",
       "94997  [saber, significar, to, feliz, demais, amar, aqui, ver, deixar, bandeira, frente, palco, sair, correr, pegar, garrafa, água, disso, pegar, novo]         \n",
       "94998  [n, conhecer, posto, d]                                                                                                                                  \n",
       "94999  [deus]                                                                                                                                                   \n",
       "\n",
       "                                                                                                                               join_f_words  \n",
       "0      rio eleger maior bancada policial história                                                                                            \n",
       "1      ficar triste vir preço câmera                                                                                                         \n",
       "2      theresa may plano brexit única opção                                                                                                  \n",
       "3      caralho querer proteger danielly pote tadinhaa                                                                                        \n",
       "4      vivo caos                                                                                                                             \n",
       "...          ...                                                                                                                             \n",
       "94995  cuba defensor direitos humanos unir contra chefe oea intervenção militar venezuela                                                    \n",
       "94996  oportunidade vir fazer parte equipe vagas aberto alunos administração enviar currículo comprovante matrícula análise prévia dia mail  \n",
       "94997  saber significar to feliz demais amar aqui ver deixar bandeira frente palco sair correr pegar garrafa água disso pegar novo           \n",
       "94998  n conhecer posto d                                                                                                                    \n",
       "94999  deus                                                                                                                                  \n",
       "\n",
       "[95000 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Altera o tamanho da visualização das colunas para demonstrar todo o conteúdo\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "\n",
    "# Mostra o conteúdo das variáveis tratadas\n",
    "#df[['tweet_text', 'filtered_words', 'join_f_words', 'normalize_words']]\n",
    "df[['tweet_text', 'filtered_words', 'join_f_words']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e0f72",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões**\n",
    "\n",
    "Submetemos a variável tweet_text ao processamento de texto:\n",
    "\n",
    "- Remoção de endereços de sites;\n",
    "- Remoção de e-mails e usuários do tweet;\n",
    "- Remoção de caracteres que não são letras;\n",
    "- Remoção de dígitos;\n",
    "- Transformação de todas as palavras para minúsculas;\n",
    "- Tokenização do texto;\n",
    "- Remoção de stopwords (portugues);\n",
    "- \"Lemmatização\" do texto;\n",
    "\n",
    "Após o tratamento do texto foram criadas duas variáveis para gravar as informações do texto tratado, entendemos que estas variáveis estejam mais limpas para utilização na modelagem.\n",
    "\n",
    "- **join_f_words** que contem o texto tratado com o processamento descrito acima;\n",
    "- **normalize_words** que contém o texto tratado e a normalização de texto utilizando a biblioteca **enelvo** que \"corrige\" abreviações, gírias, erros ortográficos e acrônimos;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b597bb38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a232e43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame gravado com successo.\n"
     ]
    }
   ],
   "source": [
    "#Grava um novo CSV com as novas colunas para avaliação\n",
    "\n",
    "# Definindo o nome do arquivo\n",
    "file_name = './dados/train/Train3Classes_with_Tokens.csv'\n",
    "  \n",
    "# Salvando o CSV\n",
    "try:\n",
    "    df.to_csv(file_name, index=False)\n",
    "    print('DataFrame gravado com successo.')\n",
    "except:\n",
    "    print(\"Ocorreu um erro na gravação.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51a02c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processo de rollback do dataframe não executado.\n"
     ]
    }
   ],
   "source": [
    "# Para executar esta celula descomentar o comando **#rollback = 1** para restaurar o df após tratamento de texto,\n",
    "# para testes de repetição, devido ao tempo de normalização do texto\n",
    "\n",
    "#rollback = 1\n",
    "\n",
    "# Restaurar o dataframe df\n",
    "if rollback == 1:\n",
    "    # Carregando csv\n",
    "    try:\n",
    "        df = pd.read_csv('./dados/train/Train3Classes_with_Tokens.csv')\n",
    "        \n",
    "        DeleteList=['Unnamed: 0']\n",
    "        df = df.drop(DeleteList, axis=1).copy()\n",
    "        \n",
    "        print('Arquivo carregado com successo.')\n",
    "        rollback = 0\n",
    "    except:\n",
    "        print('Ocorreu um erro no carregamento do arquivo.')\n",
    "else:\n",
    "    print('Processo de rollback do dataframe não executado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46761af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>join_f_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1046982734827200513</td>\n",
       "      <td>Não mais :(( https://t.co/3omrxaGTJc</td>\n",
       "      <td>Tue Oct 02 04:38:30 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>1049147450613792768</td>\n",
       "      <td>@yoongxsmin Eu também :(</td>\n",
       "      <td>Mon Oct 08 04:00:19 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1046999889597616133</td>\n",
       "      <td>@brooklenbarbie eu também :(</td>\n",
       "      <td>Tue Oct 02 05:46:40 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>1046276432241004544</td>\n",
       "      <td>@ywkheiz 1,57 só :( e a sua?</td>\n",
       "      <td>Sun Sep 30 05:51:54 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1047533065252327425</td>\n",
       "      <td>@b1ktwpas E é mesmo! : )</td>\n",
       "      <td>Wed Oct 03 17:05:19 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93081</th>\n",
       "      <td>1047538834462969856</td>\n",
       "      <td>https://t.co/iHSV24IOgV</td>\n",
       "      <td>Wed Oct 03 17:28:15 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>veja</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93294</th>\n",
       "      <td>1049253272220061696</td>\n",
       "      <td>@charroeciencia Que foi :(</td>\n",
       "      <td>Mon Oct 08 11:00:48 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94127</th>\n",
       "      <td>1049296782298173441</td>\n",
       "      <td>@JoaoGSimoes A minha e a tua :))</td>\n",
       "      <td>Mon Oct 08 13:53:42 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94206</th>\n",
       "      <td>1045413174181343232</td>\n",
       "      <td>e foi :)</td>\n",
       "      <td>Thu Sep 27 20:41:38 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94573</th>\n",
       "      <td>1046256494222725120</td>\n",
       "      <td>@antunesaranda muito :(</td>\n",
       "      <td>Sun Sep 30 04:32:41 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                            tweet_text  \\\n",
       "215    1046982734827200513  Não mais :(( https://t.co/3omrxaGTJc   \n",
       "286    1049147450613792768  @yoongxsmin Eu também :(               \n",
       "476    1046999889597616133  @brooklenbarbie eu também :(           \n",
       "592    1046276432241004544  @ywkheiz 1,57 só :( e a sua?           \n",
       "862    1047533065252327425  @b1ktwpas E é mesmo! : )               \n",
       "...                    ...                       ...               \n",
       "93081  1047538834462969856  https://t.co/iHSV24IOgV                \n",
       "93294  1049253272220061696  @charroeciencia Que foi :(             \n",
       "94127  1049296782298173441  @JoaoGSimoes A minha e a tua :))       \n",
       "94206  1045413174181343232  e foi :)                               \n",
       "94573  1046256494222725120  @antunesaranda muito :(                \n",
       "\n",
       "                           tweet_date  sentiment query_used filtered_words  \\\n",
       "215    Tue Oct 02 04:38:30 +0000 2018  0          :(         []              \n",
       "286    Mon Oct 08 04:00:19 +0000 2018  0          :(         []              \n",
       "476    Tue Oct 02 05:46:40 +0000 2018  0          :(         []              \n",
       "592    Sun Sep 30 05:51:54 +0000 2018  0          :(         []              \n",
       "862    Wed Oct 03 17:05:19 +0000 2018  1          :)         []              \n",
       "...                               ... ..          ..         ..              \n",
       "93081  Wed Oct 03 17:28:15 +0000 2018  2          veja       []              \n",
       "93294  Mon Oct 08 11:00:48 +0000 2018  0          :(         []              \n",
       "94127  Mon Oct 08 13:53:42 +0000 2018  1          :)         []              \n",
       "94206  Thu Sep 27 20:41:38 +0000 2018  1          :)         []              \n",
       "94573  Sun Sep 30 04:32:41 +0000 2018  0          :(         []              \n",
       "\n",
       "      join_f_words  \n",
       "215                 \n",
       "286                 \n",
       "476                 \n",
       "592                 \n",
       "862                 \n",
       "...   ..            \n",
       "93081               \n",
       "93294               \n",
       "94127               \n",
       "94206               \n",
       "94573               \n",
       "\n",
       "[364 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando quais linhas não apresentam valor após o tratamento do texto\n",
    "\n",
    "df[np.where((df['join_f_words'].str.len()<1), True, False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d610ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando novo dataframe retirando as linhas que ficaram sem texto\n",
    "\n",
    "# Novo dataframe dfc (df copy)\n",
    "dfc = df[np.where((df['join_f_words'].str.len()>1), True, False)].copy()\n",
    "\n",
    "# Reindexando os indices do dataframe\n",
    "dfc.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "327e65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisar o momento dessa execução\n",
    "\n",
    "# Exclusão de variáveis que entendemos não ser relevante para o modelo\n",
    "\n",
    "# id: ID único para o tweet  \n",
    "# tweet_text: Texto da publicação no Twitter  \n",
    "# tweet_date: Data da publicação no Twitter  \n",
    "# query_used: Filtro utilizado para buscar a publicação\n",
    "# filtered_words: Texto da publicação no Twitter após tratamento de texto\n",
    "\n",
    "# Excluindo colunas\n",
    "#DeleteList=['id', 'tweet_text', 'tweet_date', 'query_used', 'filtered_words']\n",
    "DeleteList=['id', 'tweet_date', 'query_used', 'filtered_words']\n",
    "\n",
    "# Novo dataframe dfc (df copy)\n",
    "dfc = dfc.drop(DeleteList, axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37f1be2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94604 entries, 0 to 94603\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   tweet_text    94604 non-null  object\n",
      " 1   sentiment     94604 non-null  int64 \n",
      " 2   join_f_words  94604 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "dfc.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50e7cc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataframe tem 3 colunas e 94604 linhas.\n",
      "Existem 0 colunas que têm valores faltantes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores faltantes</th>\n",
       "      <th>% de Valores Totais</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Valores faltantes, % de Valores Totais, Data Type]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando os valores nulos do dataframe\n",
    "\n",
    "missing_values_table(dfc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2305832",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "O dataframe é composto por 5 colunas e 94.604 registros.\n",
    "\n",
    "A tabela acima apresenta valores faltantes, porém como não representa um percentual consideravél optamos em excluir os dados faltantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a785713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusão dos registros faltantes\n",
    "\n",
    "dfc.dropna() \n",
    "dfc.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2887d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe original - df\n",
      "Quantidade de linhas...........: 95000\n",
      "Quantidade de colunas..........: 5\n",
      "\n",
      "Dataframe tratado - dfc\n",
      "Quantidade de linhas...........: 94604\n",
      "Quantidade de linhas duplicadas: 811\n",
      "Quantidade de colunas..........: 3\n",
      "\n",
      "Percentual de registros retirados: 0.42%\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtlc, qtcc = dfc.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "qtd, _ = dfc[dfc.duplicated()].shape\n",
    "\n",
    "\n",
    "print('Dataframe original - df')\n",
    "print(f'Quantidade de linhas...........: {qtl}')\n",
    "print(f'Quantidade de colunas..........: {qtc}')\n",
    "\n",
    "print('\\nDataframe tratado - dfc')\n",
    "print(f'Quantidade de linhas...........: {qtlc}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtd}')\n",
    "print(f'Quantidade de colunas..........: {qtcc}')\n",
    "\n",
    "print (f'\\nPercentual de registros retirados: {(100  * (qtl-qtlc) / qtl):.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3416ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>join_f_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74022</th>\n",
       "      <td>\"Em recuperação judicial, Eternit vê receita crescer em agosto\" https://t.co/aKl26jNJyJ #trabalho #feedly</td>\n",
       "      <td>2</td>\n",
       "      <td>recuperação judicial eternit ver receita crescer agosto trabalho feedly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36418</th>\n",
       "      <td>#CulturalSpam serale... #notizie #curiose, #interessanti, talvolta #utili! :D #curious, #interesting, sometimes #useful #news! :D Des #nouvelles #curieuses, #intéressantes, parfois #utiles! https://t.co/MjC5j2svqe :D</td>\n",
       "      <td>1</td>\n",
       "      <td>culturalspam serale notizie curiose interessanti talvolta utili d curious interesting sometimes useful news d des nouvelles curieuses intéressantes parfois utiles d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66554</th>\n",
       "      <td>#FollowFriday Todos os meus seguidores. :) #ff</td>\n",
       "      <td>1</td>\n",
       "      <td>followfriday todos seguidores ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30159</th>\n",
       "      <td>#FollowFriday para todos meus queridos seguidores. :) #IFTTT</td>\n",
       "      <td>1</td>\n",
       "      <td>followfriday todos queridos seguidores ifttt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>#Novidade Novo Kindle Oasis, tela de 7” sensível ao toque de alta resolução, à prova d’água, iluminação embutida, Wi-Fi https://t.co/kLVZK6xkBp Confira o preço no site. #kindle #amazon #leitor #ebook #KindleUnlimited #kindledeals #kindlebook</td>\n",
       "      <td>2</td>\n",
       "      <td>novidade novo kindle oasis tela sensível toque alta resolução prova d água iluminação embutir wi fi conferir preço site kindle amazon leitor ebook kindleunlimited kindledeals kindlebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39077</th>\n",
       "      <td>tédio :(</td>\n",
       "      <td>0</td>\n",
       "      <td>tédio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55345</th>\n",
       "      <td>us2 q uminom :(((</td>\n",
       "      <td>0</td>\n",
       "      <td>q uminom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39161</th>\n",
       "      <td>voltei :)</td>\n",
       "      <td>1</td>\n",
       "      <td>voltar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88831</th>\n",
       "      <td>vou tentar dormir :(</td>\n",
       "      <td>0</td>\n",
       "      <td>ir tentar dormir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60822</th>\n",
       "      <td>😱NOVOS FILMES E SÉRIES ESTÃO CHEGANDO NA NETFLIX ESTA SEMANA👉https://t.co/pKE3MfHuwN #netflix #netflixbrasil #filmes #séries #animação #desenho #anime #documentário #movie #cinema #sdv #bolsonaro #net #youtube #notícia #news #assistir #baixar #lançamentos #estreias #novidades</td>\n",
       "      <td>2</td>\n",
       "      <td>novos filmes séries chegar netflix semana netflix netflixbrasil filmes séries animação desenho anime documentário movie cinema sdv bolsonaro net youtube notícia news assistir baixar lançamentos estreias novidades</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>811 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                 tweet_text  \\\n",
       "74022  \"Em recuperação judicial, Eternit vê receita crescer em agosto\" https://t.co/aKl26jNJyJ #trabalho #feedly                                                                                                                                                                              \n",
       "36418  #CulturalSpam serale... #notizie #curiose, #interessanti, talvolta #utili! :D #curious, #interesting, sometimes #useful #news! :D Des #nouvelles #curieuses, #intéressantes, parfois #utiles! https://t.co/MjC5j2svqe :D                                                               \n",
       "66554  #FollowFriday Todos os meus seguidores. :) #ff                                                                                                                                                                                                                                         \n",
       "30159  #FollowFriday para todos meus queridos seguidores. :) #IFTTT                                                                                                                                                                                                                           \n",
       "24782  #Novidade Novo Kindle Oasis, tela de 7” sensível ao toque de alta resolução, à prova d’água, iluminação embutida, Wi-Fi https://t.co/kLVZK6xkBp Confira o preço no site. #kindle #amazon #leitor #ebook #KindleUnlimited #kindledeals #kindlebook                                      \n",
       "...                                                                                                                                                                                                                                                  ...                                      \n",
       "39077  tédio :(                                                                                                                                                                                                                                                                               \n",
       "55345  us2 q uminom :(((                                                                                                                                                                                                                                                                      \n",
       "39161  voltei :)                                                                                                                                                                                                                                                                              \n",
       "88831  vou tentar dormir :(                                                                                                                                                                                                                                                                   \n",
       "60822  😱NOVOS FILMES E SÉRIES ESTÃO CHEGANDO NA NETFLIX ESTA SEMANA👉https://t.co/pKE3MfHuwN #netflix #netflixbrasil #filmes #séries #animação #desenho #anime #documentário #movie #cinema #sdv #bolsonaro #net #youtube #notícia #news #assistir #baixar #lançamentos #estreias #novidades   \n",
       "\n",
       "       sentiment  \\\n",
       "74022  2           \n",
       "36418  1           \n",
       "66554  1           \n",
       "30159  1           \n",
       "24782  2           \n",
       "...   ..           \n",
       "39077  0           \n",
       "55345  0           \n",
       "39161  1           \n",
       "88831  0           \n",
       "60822  2           \n",
       "\n",
       "                                                                                                                                                                                                               join_f_words  \n",
       "74022  recuperação judicial eternit ver receita crescer agosto trabalho feedly                                                                                                                                               \n",
       "36418  culturalspam serale notizie curiose interessanti talvolta utili d curious interesting sometimes useful news d des nouvelles curieuses intéressantes parfois utiles d                                                  \n",
       "66554  followfriday todos seguidores ff                                                                                                                                                                                      \n",
       "30159  followfriday todos queridos seguidores ifttt                                                                                                                                                                          \n",
       "24782  novidade novo kindle oasis tela sensível toque alta resolução prova d água iluminação embutir wi fi conferir preço site kindle amazon leitor ebook kindleunlimited kindledeals kindlebook                             \n",
       "...                                                                                                                                                                                          ...                             \n",
       "39077  tédio                                                                                                                                                                                                                 \n",
       "55345  q uminom                                                                                                                                                                                                              \n",
       "39161  voltar                                                                                                                                                                                                                \n",
       "88831  ir tentar dormir                                                                                                                                                                                                      \n",
       "60822  novos filmes séries chegar netflix semana netflix netflixbrasil filmes séries animação desenho anime documentário movie cinema sdv bolsonaro net youtube notícia news assistir baixar lançamentos estreias novidades  \n",
       "\n",
       "[811 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linhas duplicadas:\n",
      "811\n"
     ]
    }
   ],
   "source": [
    "# Verificando linhas duplicadas\n",
    "\n",
    "# Seleciona as linhas duplicadas no dataframe baseado em todas as colunas\n",
    "display(dfc[dfc.duplicated(keep='first')].sort_values(by=list(dfc.columns)))\n",
    "\n",
    "print(\"\\nLinhas duplicadas:\")\n",
    "print(dfc[dfc.duplicated()].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa0cef9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "Após tratamento do dataframe identificamos que diversos texto possuem as mesmas palavras e como o percentual de duplicidade é baixo optamos em retirar as linhas repetidas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551a193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "832514dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando os dataframes\n",
    "\n",
    "# Criando copia do dataframe tratado para manter todos os registros \n",
    "dfc_copy = dfc.copy()\n",
    "\n",
    "# Convertendo int 64 para 32\n",
    "dfc['sentiment'] = dfc['sentiment'].astype(np.int16)\n",
    "\n",
    "# Excluindo os linhas duplicadas\n",
    "dfc = dfc.drop_duplicates(keep='first').copy()\n",
    "dfc.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2217c6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe original - df\n",
      "Quantidade de linhas...........: 95000\n",
      "Quantidade de colunas..........: 5\n",
      "\n",
      "Dataframe tratado - dfc\n",
      "Quantidade de linhas...........: 93793\n",
      "Quantidade de linhas duplicadas: 0\n",
      "Quantidade de colunas..........: 3\n",
      "\n",
      "Percentual de registros retirados: 1.27%\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtlc, qtcc = dfc.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "qtd, _ = dfc[dfc.duplicated()].shape\n",
    "\n",
    "\n",
    "print('Dataframe original - df')\n",
    "print(f'Quantidade de linhas...........: {qtl}')\n",
    "print(f'Quantidade de colunas..........: {qtc}')\n",
    "\n",
    "print('\\nDataframe tratado - dfc')\n",
    "print(f'Quantidade de linhas...........: {qtlc}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtd}')\n",
    "print(f'Quantidade de colunas..........: {qtcc}')\n",
    "\n",
    "print (f'\\nPercentual de registros retirados: {(100  * (qtl-qtlc) / qtl):.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b6787",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "- Tratamos a variável **tweet_text** para criar a variável auxiliar **filtered_words**, onde os textos foram submetidos a tratamentos para definir as palavras chaves de sentimento;<br>\n",
    "\n",
    "\n",
    "- Criamos a variável **join_f_words**, para concatenar as palavras do coluna **filtered_words**;<br>\n",
    "\n",
    "\n",
    "- Criamos a variável **normalize_words**, tratando a variável **tweet_text** utilizando a biblioteca **enelvo**;<br>\n",
    "\n",
    "\n",
    "- Criamos um novo dataframe **dfc**, retirando as variáveis **id, tweet_date, query_used**, pois  as variáveis **id, tweet_date, query_used** não são relevantes para a modelagem;<br>\n",
    "\n",
    "\n",
    "- Retiramos todos os registros que estavam duplicados;<br>\n",
    "\n",
    "\n",
    "Com esses tratamentos acreditamos que o novo dataframe esta melhor preparado para análise exploratória de dados e modelagem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cdcd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7682d5be",
   "metadata": {},
   "source": [
    "## 3. Análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4baeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "dfc.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b3e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listagem das primeiras linhas do dataframe\n",
    "\n",
    "dfc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cffc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14f4b52d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Analisando Sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de20fc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**sentiment**\n",
    "- sentiment: 0, se negativo; 1, se positivo; 2, se neutro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567c31a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quantidade de sentimentos\n",
    "\n",
    "Counter(dfc['sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b796df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Distribuição de tweets\n",
    "\n",
    "temp = dfc.groupby('sentiment').count()['join_f_words'].reset_index().sort_values(by='join_f_words',ascending=False)\n",
    "temp.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72634775",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Distribuição da variavel sentiment\n",
    "\n",
    "col = 'sentiment'\n",
    "\n",
    "total = len(dfc)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "g = sns.countplot(x=col, data=dfc, palette=colors)\n",
    "g.set_title(f\"Distribuição da variável {col}\")\n",
    "g.set_xlabel(f\"{col}\")\n",
    "g.set_ylabel(\"Quantidade\")\n",
    "sizes=[]\n",
    "for p in g.patches:\n",
    "    height = p.get_height()\n",
    "    sizes.append(height)\n",
    "    g.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format((height/total)*100),\n",
    "            ha=\"center\", fontsize=14) \n",
    "g.set_ylim(0, max(sizes) * 1.15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488bcc2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "Analisando a variável **sentiment** podemos constatar que o nosso dataframe contém quantidades de tweets balanceados, diminuindo a tendência do modelo para algum dos resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84e207",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45009fc3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Analisando as palavras dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0abaef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas nos textos\n",
    "\n",
    "dfc['list_words'] = dfc['join_f_words'].apply(lambda w:str(w).split())\n",
    "\n",
    "top = Counter([item for sublist in dfc['list_words'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Palavras','Quantidade']\n",
    "temp.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b58fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Analisando a quantidade de palavras mais utilizadas\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp, palette=colors)\n",
    "g.set_title(f\"As 20 palavras mais utilizadas nos textos\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83261e20",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Analisando a quantidade de palavras mais utilizadas\n",
    "\n",
    "fig = px.treemap(temp, path=['Palavras'], values='Quantidade',title='As 20 palavras mais utilizadas nos textos')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495101ff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da8d21a4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Palavras mais utilizadas por Sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9281a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Criando dataframes por sentimentos\n",
    "\n",
    "# negativo\n",
    "Negative_sent = dfc[dfc['sentiment']==0]\n",
    "Negative_sent.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# positivo\n",
    "Positive_sent = dfc[dfc['sentiment']==1]\n",
    "Positive_sent.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# neutro\n",
    "Neutral_sent = dfc[dfc['sentiment']==2]\n",
    "Neutral_sent.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31a8e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Lista auxiliar com todas as palavras do dataframe\n",
    "\n",
    "raw_text = [word for word_list in dfc['list_words'] for word in word_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626484d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# O processamento de cada instrução leva em média 7 minutos, totalizando aproximadamente 21 minutos\n",
    "# em uma máquina i7 com 12 cores e 32 ram\n",
    "\n",
    "# As 20 palavras utilizadas apenas para o sentimento negativo\n",
    "Unique_Negative= words_unique(0, 20, raw_text)\n",
    "\n",
    "# As 20 palavras utilizadas apenas para o sentimento positivo\n",
    "Unique_Positive = words_unique(1, 20, raw_text)\n",
    "\n",
    "# As 20 palavras utilizadas apenas para o sentimento neutro\n",
    "Unique_Neutral= words_unique(2, 20, raw_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e30c327",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Sentimentos Negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c7f6b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas em sentimentos negativos\n",
    "\n",
    "top = Counter([item for sublist in Negative_sent['list_words'] for item in sublist])\n",
    "temp_negative = pd.DataFrame(top.most_common(20))\n",
    "temp_negative = temp_negative.iloc[1:,:]\n",
    "temp_negative.columns = ['Palavras','Quantidade']\n",
    "temp_negative.style.background_gradient(cmap='Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890d809",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação da quantidade de palavras mais utilizadas em sentimentos negativos\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp_negative, palette=colors)\n",
    "g.set_title(f\"Palavras mais utilizadas nos textos negativos\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afff34",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresenta as palavras utilizadas apenas em sentimentos negativos\n",
    "\n",
    "print('As 20 palavras mais utilizadas apenas em Tweets negativos:')\n",
    "Unique_Negative.style.background_gradient(cmap='Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414b719",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# As 20 palavras utilizadas apenas para o sentimento negativos\n",
    "\n",
    "fig = px.treemap(Unique_Negative, path=['words'], values='count',title='As 20 palavras mais utilizadas apenas em Tweets negativos')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85d56c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d950de81",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Sentimentos Positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f27e52",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas em sentimentos positivos\n",
    "\n",
    "top = Counter([item for sublist in Positive_sent['list_words'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(20))\n",
    "temp_positive.columns = ['Palavras','Quantidade']\n",
    "temp_positive.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097beb9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação da quantidade de palavras mais utilizadas em sentimentos positivos\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp_positive, palette=colors)\n",
    "g.set_title(f\"Palavras mais utilizadas nos textos positivos\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a152e0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresenta as palavras utilizadas apenas em sentimentos positivos\n",
    "\n",
    "print('As 20 palavras mais utilizadas apenas em Tweets positivos:')\n",
    "Unique_Positive.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff9213",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação das palavras utilizadas em sentimentos positivos\n",
    "\n",
    "fig = px.treemap(Unique_Positive, path=['words'], values='count',title='As 20 palavras mais utilizadas apenas em Tweets positivos')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309fdcb4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cef58502",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Sentimentos Neutros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118a20e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas em sentimentos neutros\n",
    "\n",
    "top = Counter([item for sublist in Neutral_sent['list_words'] for item in sublist])\n",
    "temp_neutral = pd.DataFrame(top.most_common(20))\n",
    "temp_neutral = temp_neutral.loc[1:,:]\n",
    "temp_neutral.columns = ['Palavras','Quantidade']\n",
    "temp_neutral.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ca74a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação da quantidade de palavras mais utilizadas em sentimentos neutros\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp_neutral, palette=colors)\n",
    "g.set_title(f\"Palavras mais utilizadas nos textos neutros\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d396ded",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresenta as palavras utilizadas apenas em sentimentos neutros\n",
    "\n",
    "print('As 20 palavras utilizadas apenas em Tweets neutros:')\n",
    "Unique_Neutral.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99c445",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação das palavras utilizadas em sentimentos neutros\n",
    "\n",
    "fig = px.treemap(Unique_Neutral, path=['words'], values='count',title='As 20 palavras mais utilizadas apenas em Tweets neutros')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92502f5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### WordClouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c3377",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# WordCloud para Tweets negativos\n",
    "\n",
    "text = ' '.join(Negative_sent['join_f_words'])\n",
    "plot_wordcloud(text, title = 'WordCloud Tweets negativos', backcolor = 'white', clrmap = 'Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71ff72",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# WordCloud para Tweets positivos\n",
    "\n",
    "text = ' '.join(Positive_sent['join_f_words'])\n",
    "plot_wordcloud(text, title = 'WordCloud Tweets positivos', backcolor = 'white', clrmap = 'Greens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545fa566",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# WordCloud para Tweets neutros\n",
    "\n",
    "text = ' '.join(Neutral_sent['join_f_words'])\n",
    "plot_wordcloud(text, title = 'WordCloud Tweets neutros', backcolor = 'white', clrmap = 'PuBu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73fa2a9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "- Podemos ver que as mesmas palavras são comuns nos três segmentos;\n",
    "\n",
    "\n",
    "- Isso é interessante porque palavras como dont e cant são mais de natureza negativa e palavras como lol são mais de natureza positiva, o que significa que os nossos dados estão incorrectamente etiquetados, teremos mais informações sobre isso após a análise de N-grama;\n",
    "\n",
    "\n",
    "- Olhando para as palavras únicas de cada sentimento,temos agora muito mais clareza sobre os dados, estas palavras únicas são determinantes para o sentimento dos tweets;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082c8a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72070112",
   "metadata": {},
   "source": [
    "## 4. Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb77b8",
   "metadata": {},
   "source": [
    "### Separando conjunto de dados Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc['Num_words_text'] = dfc['join_f_words'].apply(lambda x:len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65486f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A nossa base de dados tem 93.793 mil linhas e a quantidade de palavras disponíveis nos textos é muito grande. \n",
    "# Para evitar problemas de alocação de memória e processamento dos textos e modelagem, iremos criar uma amostra com 70% da base:\n",
    "\n",
    "dfc = dfc.sample(frac=0.7, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos dividir os nossos dados numa matriz X que contém as características a treinar, \n",
    "# e uma matriz y com a variável alvo, neste caso a coluna covid_res. \n",
    "\n",
    "X = dfc['join_f_words']\n",
    "y = dfc['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86beb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos dividir os dados num conjunto de Train e num conjunto de Test. \n",
    "# Iremos treinar o modelo no conjunto de treino e depois utilizaremos o conjunto de testes para avaliar o modelo\n",
    "\n",
    "random_seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade total da variável \"target\" (sentiment)\n",
    "\n",
    "y.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a27f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade separada para o conjunto de treino inicial\n",
    "\n",
    "y_train.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade separada para o conjunto de teste inicial\n",
    "\n",
    "y_test.value_counts().sort_index()#(normalize = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8f1aa",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d833f",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac91f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9df319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo com os conjuntos de dados de treinamento \n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train).toarray()\n",
    "X_test_cv = cv.transform(X_test).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de modelos\n",
    "\n",
    "list_models = [\n",
    "{'model_name': 'XGBClassifier',\n",
    " 'estimator' : XGBClassifier(n_jobs = 1, objective = 'multi:softmax', tree_method='approx', random_state = random_seed)},\n",
    "{'model_name': 'XGBClassifier',\n",
    " 'estimator' : XGBClassifier(n_jobs = 1, tree_method='approx', metric='multiclass', eval_metric='mlogloss', random_state = random_seed)}\n",
    "#{'model_name': 'Logistic Regression',\n",
    "# 'estimator' : LogisticRegression(random_state = random_seed, solver = 'lbfgs')}\n",
    "#{'model_name': 'Decision Tree',\n",
    "# 'estimator' : DecisionTreeClassifier(random_state = random_seed)}\n",
    "#,{'model_name': 'Random Forest',\n",
    "# 'estimator' : RandomForestClassifier(random_state = random_seed)}\n",
    "#,{'model_name': 'AdaBoost',\n",
    "# 'estimator' : AdaBoostClassifier(random_state = random_seed)}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfcc793",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Processando os modelos baseado na list_models\n",
    "\n",
    "test_models_plot_roc_auc_curve(list_models,\n",
    "                              'model_name',\n",
    "                              'estimator',\n",
    "                              X_train_cv,\n",
    "                              X_test_cv,\n",
    "                              y_train,\n",
    "                              y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef0d7f",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bb8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciando TF-IDF\n",
    "\n",
    "tfidf = TfidfVectorizer(use_idf = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo com os conjuntos de dados de treinamento \n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).todense()\n",
    "X_test_tfidf  = tfidf.transform(X_test).todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processando os modelos baseado na list_models\n",
    "\n",
    "test_models_plot_roc_auc_curve(list_models,\n",
    "                               'model_name',\n",
    "                               'estimator',\n",
    "                               X_train_tfidf,\n",
    "                               X_test_tfidf,\n",
    "                               y_train,\n",
    "                               y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07e009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9646d853",
   "metadata": {},
   "source": [
    "## 5. Conclusões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c7950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6114f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
