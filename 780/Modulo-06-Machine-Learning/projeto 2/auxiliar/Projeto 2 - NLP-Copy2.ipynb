{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362c03d1",
   "metadata": {},
   "source": [
    "# Projeto 2 - NLP\n",
    "\n",
    "-----\n",
    "\n",
    "Nome:  Johnny Hideki Horita <br>\n",
    "Turma: 780"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517a372",
   "metadata": {},
   "source": [
    "Os segundo projeto do módulo de Machine Learning será focado no processamento de linguagem natural! Usaremos os algoritmos aprendidos e as técnicas vistas na segunda parte do curso para extrairmos informações relevantes de texto. Mais precisamente, de publicações no Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a3a98",
   "metadata": {},
   "source": [
    "## Os Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d5657",
   "metadata": {},
   "source": [
    "Utilizaremos um Dataset obtido do Twitter com 100K postagens entre os dias 01/08/2018 e 20/10/2018. Cada postagem é classificada como **positiva**, **negativa** ou **neutra**.  \n",
    "\n",
    "Dois arquivos serão disponilizados para o desenvolvimento dos modelos, um para treino/validação e outro para submissão. Os arquivos se encontram na pasta */Dados/train* e */Dados/subm*, respectivamente.\n",
    "\n",
    "Descrição das colunas:\n",
    "\n",
    "- **id**: ID único para o tweet  \n",
    "- **tweet_text**: Texto da publicação no Twitter  \n",
    "- **tweet_date**: Data da publicação no Twitter  \n",
    "- **sentiment**: 0, se negativo; 1, se positivo; 2, se neutro  \n",
    "- **query_used**: Filtro utilizado para buscar a publicação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc86eb5",
   "metadata": {},
   "source": [
    "## O Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e1f6f",
   "metadata": {},
   "source": [
    "Você deverá desenvolver um modelo para detectar o sentimento de uma publicação do Twitter a classificando em uma das três categorias: **positiva**, **negativa** ou **neutra**. O texto da publicação está disponível na coluna \"tweet_text\". Teste pelo menos 3 técnicas de NLP diferentes e escolha a métrica de avaliação que julgar mais pertinente.  \n",
    "\n",
    "Escolha o melhor modelo e gere uma base a partir dos dados de submissão, que estão no caminho ```Dados/subm/Subm3Classes.csv```, com o seguinte formato:\n",
    "\n",
    "\n",
    "|id|sentiment_predict\n",
    "|-|-|\n",
    "|12123232|0\n",
    "|323212|1\n",
    "|342235|2\n",
    "\n",
    "Salve essa tabela como um arquivo csv com o nome ```<nome>_<sobrenome>_nlp_degree.csv``` e submeta-o como parte da entrega final do projeto.  \n",
    "\n",
    "Para ajudar no desenvolvimento, é possível dividir o projeto em algumas fases:\n",
    "\n",
    "- **Análise de consistência dos dados**: analise se os dados estão fazendo sentido, se os campos estão completos e se há dados duplicados ou faltantes. Se julgar necessário, trate-os.    \n",
    "\n",
    "\n",
    "- **Análise exploratória**: analise a sua base como um todo, verifique o balanceamento entre as classes e foque, principalmente, na coluna ```tweet_text```.    \n",
    "\n",
    "\n",
    "- **Pré-processamento e transformações**: projetos de NLP exigem um considerável pré-processamento. Foque no tratamento da string do texto. Procure começar com tratamentos simples e adicione complexidade gradualmente. Nessa etapa você testará diferentes técnicas de transformações, como o Bag Of Words e o TF-IDF.    \n",
    "\n",
    "\n",
    "- **Treinamento do modelo**: depois das transformações, você poderá executar o treinamento do modelo classificador. Nessa etapa o problema se torna semelhante aos abordados na primeira parte do módulo. Você pode testar diversos classificadores como RandomForest, AdaBoost, entre outros. Otimize os hiperparâmetros do modelo com técnicas como a GridSearch e a RandomizedSearch.    \n",
    "\n",
    "\n",
    "- **Conclusões**: descreva, em texto, as conclusões sobre os seus estudos. O modelo é capaz de identificar o sentimento das publicações? É possível extrapolar o modelo para outros contextos, como a análise de sentimento de uma frase qualquer? Pense em questões pertinentes e relevantes que você tenha obtido durante o desenvolvimento do projeto!     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283638c9",
   "metadata": {},
   "source": [
    "## Critérios de avaliação\n",
    "\n",
    "Os seguintes itens serão avaliados:\n",
    "\n",
    "1. Desenvolvimento das etapas descritas acima;\n",
    "\n",
    "\n",
    "2. Reprodutibilidade do código: seu código será executado e precisa gerar os mesmos resultados apresentados por você;\n",
    "\n",
    "\n",
    "3. Clareza: seu código precisa ser claro e deve existir uma linha de raciocínio direta. Comente o código em pontos que julgar necessário para o entendimento total;\n",
    "\n",
    "\n",
    "4. Justificativa das conclusões obitdas: não existirá certo ou errado, mas as decisões e as conclusões precisam ser bem justificadas com base nos resultados obtidos.  \n",
    "\n",
    "O desempenho do modelo **não** será considerado como critério de avaliação.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6049a9c",
   "metadata": {},
   "source": [
    "## Informações gerais\n",
    "\n",
    "- O projeto deve ser desenvolvido individualmente;\n",
    "\n",
    "\n",
    "- Data de divulgação: 11/01/2022;\n",
    "\n",
    "\n",
    "- Aula de monitoria: 19/01/2022;\n",
    "\n",
    "\n",
    "- Data de entrega: 26/01/2022;\n",
    "\n",
    "\n",
    "- Entrega através do Class: Árvore de Decisão -> Exercícios -> Projeto 2\n",
    "\n",
    "\n",
    "Anexar, na entrega, o notebook de desenvolvimento e o arquivo .csv de submissão, da seguinte forma:  \n",
    "\n",
    "notebook: ```<nome>_<sobrenome>_<númeroTurma>_projeto_2.ipynb```   \n",
    "csv: ```<nome>_<sobrenome>_<númeroTurma>_projeto_2_submissao.csv```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb23437",
   "metadata": {},
   "source": [
    "## Dicas\n",
    "\n",
    "### Base de treino e submissão\n",
    "\n",
    "A base de submissão não possui a variável de saída, portanto ela será utilizada **apenas** para gerar o arquivo que acompanha a submissão do projeto.      \n",
    "\n",
    "### Tente encontrar possíveis vieses\n",
    "\n",
    "É muito comum que modelos de NLP possuam fortes vieses, como a tendência de relacionar palavras específicas com alguma classe de saída. Tente encontrar vieses no seu estudo, isso pode ajudar a tirar boas conclusões. o campo \"query_used\" pode ser útil para essa análise.  \n",
    "\n",
    "### O pré-processamento é a chave para um bom desempenho\n",
    "\n",
    "Essa é a etapa que mais vai contribuir para o desempenho do seu modelo. Seja criativo e desenvolva essa etapa de uma maneira que seja fácil de aplicar o mesmo processamento para uma nova base, você terá que fazer isso para gerar a base de submissão.\n",
    "\n",
    "### Um termômetro para o seu desenvolvimento\n",
    "\n",
    "Após a correção do seu projeto, o professor irá disponibilizar a sua acurácia obtida na base de submissão. Você pode interpretar esse resultado como a simulação do resultado do seu modelo em produção. Uma diferença entre o resultado do estudo e o resultado de submissão indica um grau de **overfitting** no seu modelo.\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96911dea",
   "metadata": {},
   "source": [
    "# Desenvolvimento do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d5233",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1. Análise de consistência dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f25c3d",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89b883",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Bibliotecas\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import requests\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import squarify\n",
    "import plotly.offline as py\n",
    "import plotly_express as px\n",
    "from plotly import graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, f1_score, r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score, StratifiedKFold, cross_validate\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec, doc2vec\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "# Naive Bayes (Gaussian, Multinomial,BernoulliNB)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# Stochastic Gradient Descent Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# KNN (k-nearest neighbor)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# XGBoost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "# LGBM Classifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# Ada Boosting Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Dummy Boosting Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "# GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# RidgeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from unidecode import unidecode\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#!pip install enelvo\n",
    "from enelvo.normaliser import Normaliser\n",
    "\n",
    "# Abaixo seguem 2 formas para a instalação do spaCy: via conda ou pip\n",
    "# Instalação utilizando conda\n",
    "#!conda install -c conda-forge spacy\n",
    "\n",
    "# Instalação utilizando Pip\n",
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "\n",
    "import spacy\n",
    "from spacy.util import compounding\n",
    "from spacy.util import minibatch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import shap\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from IPython.core.display import HTML as Center\n",
    "from IPython.display import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Bibliotecas carregadas com sucesso.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1272b9b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Padrões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51314fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Definição de padrões para gráficos e cores\n",
    "\n",
    "sns.set_style('darkgrid') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=13)    # legend fontsize\n",
    "plt.rc('font', size=13)          # controls default text sizes\n",
    "\n",
    "colors = sns.color_palette(\"pastel\") # deep, pastel, Set1 Set2 Set3, icefire, tab10, muted, colorlind, coolwarm\n",
    "cmap_colors = 'GnBu'\n",
    "\n",
    "font_path = \"./fonts/CabinSketch-Bold.ttf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e73245",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Definição de padrões para centralização de gráficos no notebook\n",
    "\n",
    "Center(\"\"\" <style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style> \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c46305",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e98c2874",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054506e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função de avaliação dos valores de NaN no dataframe\n",
    "\n",
    "def missing_values_table(df):\n",
    "    '''\n",
    "    Função para verificar se existem valores nulos no dataframe\n",
    "    Entrada:\n",
    "        df - dataframe;\n",
    "        \n",
    "    Resultado: \n",
    "        Apresentação dos valores nulos no dataframe.\n",
    "\n",
    "    '''\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mz_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mz_table = mz_table.rename(\n",
    "    columns = {0 : 'Valores faltantes', 1 : '% de Valores Totais'})\n",
    "    mz_table['Data Type'] = df.dtypes\n",
    "    mz_table = mz_table[\n",
    "        mz_table.iloc[:,1] != 0].sort_values(\n",
    "    '% de Valores Totais', ascending=False).round(1)\n",
    "    print (\"O dataframe tem \" + str(df.shape[1]) + \" colunas e \" + str(df.shape[0]) + \" linhas.\\n\"      \n",
    "        \"Existem \" + str(mz_table.shape[0]) +\n",
    "          \" colunas que têm valores faltantes.\")\n",
    "    mz_table.to_excel('missing_and_zero_values.xlsx', freeze_panes=(1,0), index = True)\n",
    "    return mz_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61537f52",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função de avaliação de modelos apresentação da matriz de confusão\n",
    "score = []\n",
    "\n",
    "def test_models(model_list, col_model_name, col_model, tec_model, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Função para avaliação de modelos de predição\n",
    "    Entrada:\n",
    "        model_list - lista de modelos;\n",
    "        col_model_name - label da lista de modelos, contendo o nome do modelo;\n",
    "        col_model - label da lista de modelos, contendo a instancia do modelo de predição;\n",
    "        tec_model - definição de tratamento de modelos;\n",
    "        X_train - classe de treino\n",
    "        X_test - classe de teste\n",
    "        y_train - classe de treino\n",
    "        y_test - classe de teste\n",
    "        \n",
    "    Resultado: \n",
    "        Apresentação de métricas de predição de modelos.\n",
    "\n",
    "    '''\n",
    "    for mdl in model_list:\n",
    "        start = time.time()\n",
    "\n",
    "        model = mdl[col_model]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        \n",
    "        print(\"\")        \n",
    "        print(\"=\" * 55)\n",
    "        print(\"Model      : %s\" % mdl[col_model_name])\n",
    "        print(\"Accuracy   : %0.4f \" % accuracy_score(y_test, y_predict))\n",
    "        print(\"Precision  : %0.4f \" % precision_score(y_test, y_predict, average='weighted'))\n",
    "        print(\"Recall     : %0.4f \" % recall_score(y_test, y_predict, average='weighted'))\n",
    "        print(\"F1 - Score : %0.4f \" % f1_score(y_test, y_predict, average='weighted'))\n",
    "        print(\"MAE        : %0.4f \" % mean_absolute_error(y_test, y_predict))\n",
    "        print(\"RMSE       : %0.4f \" % np.sqrt(mean_squared_error(y_test, y_predict)))\n",
    "        print(\"R2         : %0.4f \" % r2_score(y_test, y_predict))\n",
    "        print(\"\")\n",
    "        print(classification_report(y_test, y_predict))\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_predict)\n",
    "        labels = ['Negativo','Positivo','Neutro']\n",
    "        dsp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "        dsp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n",
    "        plt.grid(False)\n",
    "        plt.show()        \n",
    "        \n",
    "        end = time.time()\n",
    "        elptime = end - start\n",
    "        converted_time = str(datetime.timedelta(seconds=elptime))\n",
    "        print(f'Partial time: {converted_time}')\n",
    "        \n",
    "        global score\n",
    "        score.append([mdl[col_model_name], tec_model, accuracy_score(y_test, y_predict)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11adbab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função para calcular a importância da variável no modelo\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "def modelfit(alg, dtrain, predictors, target, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    # Adequando as classes para treino\n",
    "    alg.fit(dtrain[predictors], dtrain[target])\n",
    "        \n",
    "    # Previsão de saída para o conjunto de dados de teste\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    # Utilizando o Cross Validation\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, dtrain[predictors], dtrain[target], cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Exibindo relatório:\n",
    "    print (f\"\\nRelatório do Modelo {alg}\")\n",
    "    print (\"\\nAcuracia : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "    #print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predictions))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "        \n",
    "    #Exibindo gráfico da importancia das variáveis\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Importância das variáveis', color=colors)\n",
    "        plt.ylabel('Pontuação')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b8b842",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_corpus(list_sentences, tokens_only=False):\n",
    "    if tokens_only:\n",
    "        # For test data, just return sentences\n",
    "        return list_sentences\n",
    "    else:\n",
    "        # For training data, add tags\n",
    "        lista = []\n",
    "        for i, line in enumerate(list_sentences):\n",
    "            lista.append(doc2vec.TaggedDocument(line, [i]))\n",
    "\n",
    "        return lista\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2553f8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função para contagem de palavras \n",
    "\n",
    "def words_unique(sentiment, numwords, raw_words):\n",
    "    '''\n",
    "    Função para contagem de palavras \n",
    "    Entrada:\n",
    "        segmento - Categoria do segmento (ex. 2 = 'Neutro');\n",
    "        numwords - quantas palavras específicas se pretende ver no resultado final; \n",
    "        raw_words - lista do texto;\n",
    "        \n",
    "    Resultado: \n",
    "        dataframe com informação sobre a palavra específica e quantas vezes aparece no texto (por ordem decrescente com base nas suas contagens).\n",
    "\n",
    "    '''\n",
    "    allother = []\n",
    "    for item in dfc[dfc.sentiment != sentiment]['list_words']:\n",
    "        for word in item:\n",
    "            allother .append(word)\n",
    "    allother  = list(set(allother ))\n",
    "    \n",
    "    specificnonly = [x for x in raw_text if x not in allother]\n",
    "    \n",
    "    mycounter = Counter()\n",
    "    \n",
    "    for item in dfc[dfc.sentiment == sentiment]['list_words']:\n",
    "        for word in item:\n",
    "            mycounter[word] += 1\n",
    "    keep = list(specificnonly)\n",
    "    \n",
    "    for word in list(mycounter):\n",
    "        if word not in keep:\n",
    "            del mycounter[word]\n",
    "    \n",
    "    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n",
    "    \n",
    "    return Unique_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f869d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Abaixo seguem 2 formas para a instalação do spaCy: via conda ou pip\n",
    "\n",
    "# Instalação utilizando conda\n",
    "#!conda install -c conda-forge spacy\n",
    "\n",
    "# Instalação utilizando Pip\n",
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "\n",
    "# Bilbioteca em portugues\n",
    "# Efficiency\n",
    "#!python -m spacy download pt_core_news_sm\n",
    "\n",
    "# Accuracy\n",
    "#!python -m spacy download pt_core_news_lg\n",
    "\n",
    "spc_pt = spacy.load('pt_core_news_lg')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "#Adicionando stopwords que não estão na lista do nltk \n",
    "stopwords.append(\"'\")\n",
    "stopwords.append(\"pra\")\n",
    "stopwords.append(\"tá\")\n",
    "stopwords.append(\"tão\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad860da3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função para tratamento da variável de texto para definir melhores valores para classificação da modelagem\n",
    "# e ou normalizar o tratamento da variável de texto utilizando a biblioteca enelvo\n",
    "\n",
    "# instanciando\n",
    "normalizador = Normaliser(tokenizer='readable', sanitize=True, capitalize_acs=True, capitalize_pns=True) # capitalize_inis=True\n",
    "\n",
    "def nlp_tratar_texto(texto, normalize=False):\n",
    "    '''\n",
    "    Função para tratamento de texto \n",
    "    Entrada:\n",
    "        texto - Texto para tratamento;\n",
    "        normalize - utilizar função de normalização da biblioteca enelvo;\n",
    "        \n",
    "    Resultado: \n",
    "        Retorna o texto com tratamento de caracteres.\n",
    "\n",
    "    '''    \n",
    "    #Remover endereços de sites\n",
    "    texto_sem_url = re.sub(r'https?:\\/\\/\\S+', '', texto)\n",
    "        \n",
    "    #Remover e-mail / users\n",
    "    #texto_sem_email = re.sub(r'[A-Za-z0-9]*@[A-Za-z]*\\.?[A-Za-z0-9]*\\.?[A-Za-z0-9]*', '', texto_sem_url)\n",
    "    texto_sem_email = re.sub(r'[A-Za-z0-9]*@\\S+', '', texto_sem_url)\n",
    "    \n",
    "    if normalize==True:\n",
    "        # Tratamento do texto utilizando o enelvo (Normalize)\n",
    "        texto_norm = normalizador.normalise(texto_sem_email)\n",
    "    \n",
    "        #Remover caracteres que não são letras e tokenização\n",
    "        texto_tratado =  re.findall(r'\\b[A-zÀ-úü]+\\b', texto_norm.lower())\n",
    "    else:\n",
    "        texto_tratado =  re.findall(r'\\b[A-zÀ-úü]+\\b', texto_sem_email.lower())\n",
    "\n",
    "    #Remover stopwords\n",
    "    stop = set(stopwords)\n",
    "    palavras = [w for w in texto_tratado if w not in stop]\n",
    "    palavras_string = \" \".join(palavras)\n",
    "\n",
    "    #Instanciar o objeto spacy\n",
    "    spc_letras =  spc_pt(palavras_string)\n",
    "\n",
    "    #Lemmização \n",
    "    tokens = [token.lemma_ if token.pos_ == 'VERB' else str(token) for token in spc_letras]\n",
    "\n",
    "    #problemas com verbo ir\n",
    "    ir = ['vou', 'vais', 'vai', 'vamos', 'ides', 'vão']\n",
    "    tokens = ['ir' if token in ir else str(token) for token in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a733446",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função para apresentar nuvem de palavras\n",
    "\n",
    "def plot_wordcloud(text, title = None, backcolor = 'white', clrmap = ''):\n",
    "    '''\n",
    "    Função para criação de imagem de nuvem de palavras\n",
    "    Entrada:\n",
    "        text - palavras para nuvem de palavras;\n",
    "        title - título da imagem;\n",
    "        backcolor - ;\n",
    "        clrmap - ;\n",
    "        \n",
    "    Resultado: \n",
    "        Imagem com nuvem de palavras.\n",
    "\n",
    "    '''    \n",
    "    wordcloud = WordCloud(\n",
    "                            background_color=backcolor,\n",
    "                            width=2000, \n",
    "                            height=800,\n",
    "                            colormap=clrmap, \n",
    "                            font_path=font_path, \n",
    "                            collocations = False)\n",
    "\n",
    "    wordcloud.generate(text)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7656c8d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Função para diminuir o tamanho do dataframe com alteração dos datatypes\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    '''\n",
    "    Função para diminuir o tamanho do dataframe com alteração dos datatypes\n",
    "    Entrada:\n",
    "        df - dataframe;\n",
    "        \n",
    "    Resultado: \n",
    "        Retorna o dataframe com alteração com a configuração mínimas dos tipos do datatype;\n",
    "        \n",
    "    '''\n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c39e89",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e738a2b7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Inicializando Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2348e7b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Arquivo Train3Classes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c224f3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Importando arquivo\n",
    "\n",
    "df = reduce_mem_usage(pd.read_csv('./dados/train/Train3Classes.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd96274",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtl, qtc = df.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "\n",
    "qtd, _ = df[df.duplicated(keep=False)].shape\n",
    "\n",
    "print(f'Quantidade de linhas...........: {qtl}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtd}')\n",
    "print(f'Quantidade de colunas..........: {qtc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0b35b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aba7f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Avaliando os valores nulos do dataframe\n",
    "\n",
    "missing_values_table(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abf0cc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "O dataframe é composto por 05 colunas e 95.000 registros.\n",
    "\n",
    "A tabela acima NÃO apresenta valores faltantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c26c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d77c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Lista de colunas do dataframe\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ae92d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Listagem das primeiras linhas do dataframe\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5fbcb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "076d3e1e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Arquivo Subm3Classes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44206b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Importando arquivo\n",
    "\n",
    "dfs = reduce_mem_usage(pd.read_csv('./dados/subm/Subm3Classes.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b40840",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "sqtl, sqtc = dfs.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "\n",
    "sqtd, _ = dfs[dfs.duplicated(keep=False)].shape\n",
    "\n",
    "print(f'Quantidade de linhas...........: {sqtl}')\n",
    "print(f'Quantidade de linhas duplicadas: {sqtd}')\n",
    "print(f'Quantidade de colunas..........: {sqtc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7804372f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "dfs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ff13f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Avaliando os valores nulos do dataframe\n",
    "\n",
    "missing_values_table(dfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2aa854",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "O dataframe é composto por 04 colunas e 5.000 registros.\n",
    "\n",
    "A tabela acima NÃO apresenta valores faltantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758254f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Lista de colunas do dataframe\n",
    "\n",
    "dfs.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99fa6d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Listagem das primeiras linhas do dataframe\n",
    "\n",
    "dfs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7d961",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5811661",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 2. Pré-processamento e transformações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a59eb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Tratamento de variáveis**\n",
    "\n",
    "- Criação da variável **filtered_words**, onde o texto original (tweet_text) será submetido a tratamentos de texto, caso o normalize seja ativado o texto também será submetidos a tratamentos da biblioteca **enelvo**;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **join_f_words**, para concatenar as palavras do coluna **filtered_words**;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **num_words_text**, para contar a quantidade de palavras no texto principal;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **num_words_join**, para contar a quantirade de palavrvas após tratamento;<br>\n",
    "\n",
    "\n",
    "- Criação da variável **diff_in_words**, para contar a diferença de palavras entre o texto principal e o tratado;<br>\n",
    "\n",
    "\n",
    "- Exclusão de variáveis que entendemos não ser relevante para o modelo<br>\n",
    "    **id**: ID único para o tweet<br>\n",
    "    **tweet_date**: Data da publicação no Twitter<br>\n",
    "    **query_used**: Filtro utilizado para buscar a publicação<br>\n",
    "    **filtered_words**: Variável auxiliar para tratamento de texto<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d247977",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Parametro para utilizar o enelvo.normalise (1=sim / 0=Não)\n",
    "# use_normalize = 1\n",
    "# O processamento desta célula com o tratamendo dos tweets utilizando o biblioteca enelvo leva em média 2 horas, \n",
    "# em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# use_normalize = 0\n",
    "# O processamento desta célula com o tratamendo dos tweets leva em média 10 min, em uma máquina i7 com 12 cores e 32 ram \n",
    "    \n",
    "use_normalize = 1\n",
    "\n",
    "# Verifica se utiliza o tratamento com Enelvo\n",
    "if use_normalize==1:\n",
    "    # Cria uma nova variável utilizando funções para tratamento das palavras do texto\n",
    "    df['filtered_words'] = df['tweet_text'].apply(lambda w: nlp_tratar_texto(w, normalize=True))\n",
    "    dfs['filtered_words'] = dfs['tweet_text'].apply(lambda w: nlp_tratar_texto(w, normalize=True))\n",
    "else:\n",
    "    # Cria uma nova variável utilizando funções para tratamento das palavras do texto\n",
    "    df['filtered_words'] = df['tweet_text'].apply(lambda w: nlp_tratar_texto(w))\n",
    "    dfs['filtered_words'] = dfs['tweet_text'].apply(lambda w: nlp_tratar_texto(w))\n",
    "\n",
    "# Cria uma nova variável concatenando os tokens gerados pelo tratamento das palavras gerando um novo texto reduzido\n",
    "df['join_f_words'] = df['filtered_words'].apply(lambda w: ' '.join(w))\n",
    "dfs['join_f_words'] = dfs['filtered_words'].apply(lambda w: ' '.join(w))\n",
    "\n",
    "# Cria uma nova variável com a quantidade de palavras da variável join_f_words\n",
    "df['num_words_text'] = df['tweet_text'].apply(lambda w:len(str(w).split()))\n",
    "dfs['num_words_text'] = dfs['tweet_text'].apply(lambda w:len(str(w).split()))\n",
    "\n",
    "# Cria uma nova variável com a quantidade de palavras da variável join_f_words\n",
    "df['num_words_join'] = df['join_f_words'].apply(lambda w:len(str(w).split()))\n",
    "dfs['num_words_join'] = dfs['join_f_words'].apply(lambda w:len(str(w).split()))\n",
    "\n",
    "# Cria uma nova variável com a diferença de quantidade de palavras\n",
    "df['diff_in_words'] = df['num_words_text'] - df['num_words_join']\n",
    "dfs['diff_in_words'] = dfs['num_words_text'] - dfs['num_words_join']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d679f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Altera o tamanho da visualização das colunas para demonstrar todo o conteúdo\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "\n",
    "# Mostra o conteúdo das variáveis tratadas\n",
    "df[['tweet_text', 'filtered_words', 'join_f_words']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e0f72",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões**\n",
    "\n",
    "Submetemos a variável tweet_text ao tratamento de texto:\n",
    "\n",
    "- Remoção de endereços de sites;\n",
    "- Remoção de e-mails e usuários do tweet;\n",
    "- Remoção de caracteres que não são letras;\n",
    "- Remoção de dígitos;\n",
    "- Transformação de todas as palavras para minúsculas;\n",
    "- Tokenização do texto;\n",
    "- Remoção de stopwords (portugues);\n",
    "- \"Lemmatização\" do texto;\n",
    "- **enelvo.normalise** \"corrige\" abreviações, gírias, erros ortográficos e acrônimos; (**Obs**: se habilitado)\n",
    "\n",
    "Após o tratamento do texto foi criada a variável **join_f_words** para gravar as informações do texto tratado, entendemos que esta variável esteja mais \"limpa\" para utilização do texto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e7248",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e65c5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exclusão de variáveis que entendemos não ser relevante para o modelo\n",
    "\n",
    "# id: ID único para o tweet  \n",
    "# tweet_date: Data da publicação no Twitter  \n",
    "# query_used: Filtro utilizado para buscar a publicação\n",
    "# filtered_words: Texto da publicação no Twitter após tratamento de texto\n",
    "\n",
    "# Excluindo colunas\n",
    "DeleteList=['id', 'tweet_date', 'query_used', 'filtered_words']\n",
    "\n",
    "# Novo dataframe dfc (df copy)\n",
    "dfc = df.drop(DeleteList, axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f1be2a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "dfc.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46761af3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Verificando quais linhas não apresentam valor após o tratamento do texto\n",
    "\n",
    "# Quantidade de linhas vazias\n",
    "qtd, _ = dfc[np.where((dfc['join_f_words'].str.len()<1), True, False)].shape\n",
    "\n",
    "print('Dataframe original - df')\n",
    "print(f'Quantidade de linhas vazias ...: {qtd}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610ffce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Retirando as linhas que ficaram sem texto\n",
    "\n",
    "dfc = dfc[np.where((dfc['join_f_words'].str.len()>1), True, False)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7cc16",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Avaliando os valores nulos do dataframe\n",
    "\n",
    "missing_values_table(dfc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2305832",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "O dataframe é composto por 6 colunas e 95.000 registros.\n",
    "\n",
    "A tabela acima apresenta valores faltantes, porém como não representa um percentual consideravél optamos em excluir os dados faltantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785713d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exclusão dos registros faltantes\n",
    "\n",
    "dfc.dropna() \n",
    "dfc.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2887d4e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtlc, qtcc = dfc.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "qtd, _ = dfc[dfc.duplicated()].shape\n",
    "\n",
    "\n",
    "print('Dataframe original - df')\n",
    "print(f'Quantidade de linhas...........: {qtl}')\n",
    "print(f'Quantidade de colunas..........: {qtc}')\n",
    "\n",
    "print('\\nDataframe tratado - dfc')\n",
    "print(f'Quantidade de linhas...........: {qtlc}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtd}')\n",
    "print(f'Quantidade de colunas..........: {qtcc}')\n",
    "\n",
    "print (f'\\nPercentual de registros retirados: {(100  * (qtl-qtlc) / qtl):.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3416ec1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Verificando linhas duplicadas\n",
    "\n",
    "# Seleciona as linhas duplicadas no dataframe baseado em todas as colunas\n",
    "display(dfc[dfc.duplicated(keep='first')].sort_values(by=list(dfc.columns)))\n",
    "\n",
    "print(\"\\nLinhas duplicadas:\")\n",
    "print(dfc[dfc.duplicated()].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa0cef9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "Após tratamento do dataframe identificamos que diversos texto possuem as mesmas palavras e como o percentual de duplicidade é baixo optamos em retirar as linhas repetidas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551a193",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832514dd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Excluindo os linhas duplicadas\n",
    "dfc = dfc.drop_duplicates(keep='first').copy()\n",
    "dfc.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217c6e1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtlc, qtcc = dfc.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "qtd, _ = dfc[dfc.duplicated()].shape\n",
    "\n",
    "\n",
    "print('Dataframe original - df')\n",
    "print(f'Quantidade de linhas...........: {qtl}')\n",
    "print(f'Quantidade de colunas..........: {qtc}')\n",
    "\n",
    "print('\\nDataframe tratado - dfc')\n",
    "print(f'Quantidade de linhas...........: {qtlc}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtd}')\n",
    "print(f'Quantidade de colunas..........: {qtcc}')\n",
    "\n",
    "print (f'\\nPercentual de registros retirados: {(100  * (qtl-qtlc) / qtl):.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232e43e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Grava um novo CSV com as variáveis auxiliares\n",
    "\n",
    "# Definindo o nome do arquivo\n",
    "if use_normalize==1:\n",
    "    file_name = './dados/train/Train3Classes_with_Token_normalize.csv'\n",
    "else:\n",
    "    file_name = './dados/train/Train3Classes_with_Token.csv'\n",
    "  \n",
    "# Salvando o CSV\n",
    "try:\n",
    "    # Gravando o dataframe em CSV\n",
    "    dfc.to_csv(file_name, index=False)\n",
    "    print(f'DataFrame gravado com successo.\\n')\n",
    "    \n",
    "    try:\n",
    "        # Carregar o dataframe\n",
    "        dfc = reduce_mem_usage(pd.read_csv(file_name))\n",
    "        print(f'Arquivo carregado com successo.')\n",
    "\n",
    "    except:\n",
    "        print(f'Ocorreu um erro no carregamento do arquivo.')\n",
    "    \n",
    "except:\n",
    "    print(\"Ocorreu um erro na gravação.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b6787",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "- Tratamos a variável **tweet_text** para criar a variável auxiliar **filtered_words**, onde os textos foram submetidos a tratamentos para definir as palavras chaves de sentimento, caso o normalize esteja ativo o texto também foi submetidos a tratamentos da biblioteca **enelvo**;<br>\n",
    "\n",
    "\n",
    "- Criamos a variável **join_f_words**, para concatenar as palavras do coluna **filtered_words**;<br>\n",
    "\n",
    "\n",
    "- Criamos um novo dataframe **dfc**, retirando as variáveis **id, tweet_date, query_used, filtered_words**, pois acreditamos que as variáveis não são relevantes para a modelagem;<br>\n",
    "\n",
    "\n",
    "- Retiramos todos os registros que apresentavam colunas nulas;<br>\n",
    "\n",
    "\n",
    "- Retiramos todos os registros que estavam duplicados;<br>\n",
    "\n",
    "\n",
    "Com esses processos acreditamos que o novo dataframe esta melhor preparado para análise exploratória de dados e modelagem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cdcd0f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7682d5be",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3. Análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4baeaa0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "dfc.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b3e5c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Listagem das primeiras linhas do dataframe\n",
    "\n",
    "dfc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cffc4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14f4b52d",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Analisando Sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de20fc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**sentiment**\n",
    "- sentiment: 0, se negativo; 1, se positivo; 2, se neutro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567c31a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quantidade de sentimentos\n",
    "\n",
    "Counter(dfc['sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b796df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Distribuição de tweets\n",
    "\n",
    "temp = dfc.groupby('sentiment').count()['tweet_text'].reset_index().sort_values(by='tweet_text',ascending=False)\n",
    "temp.style.background_gradient(cmap=cmap_colors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72634775",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Distribuição da variavel sentiment\n",
    "\n",
    "col = 'sentiment'\n",
    "\n",
    "total = len(dfc)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "g = sns.countplot(x=col, data=dfc, palette=colors)\n",
    "g.set_title(f\"Distribuição da variável {col}\")\n",
    "g.set_xlabel(f\"{col}\")\n",
    "g.set_ylabel(\"Quantidade\")\n",
    "sizes=[]\n",
    "for p in g.patches:\n",
    "    height = p.get_height()\n",
    "    sizes.append(height)\n",
    "    g.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format((height/total)*100),\n",
    "            ha=\"center\", fontsize=14) \n",
    "g.set_ylim(0, max(sizes) * 1.15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488bcc2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "Analisando a variável **sentiment** podemos constatar que o nosso dataframe contém quantidades de tweets balanceados, diminuindo a tendência do modelo para algum dos sentimentos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84e207",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45009fc3",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Analisando as palavras dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1596dc7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Criando a lista de palavras e o vocabulário de palavras\n",
    "\n",
    "dfc['list_words'] = dfc['join_f_words'].apply(lambda w:str(w).split())\n",
    "\n",
    "# Criando vocabulário (collection) para armazenar as palavras e vezes que aparecem\n",
    "top = Counter([item for sublist in dfc['list_words'] for item in sublist])\n",
    "\n",
    "print(f\"O vocabulário é formado por {len(top)} palavras!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0abaef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# As 20 Palavras mais utilizadas nos textos\n",
    "\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Palavras','Quantidade']\n",
    "temp.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b58fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Analisando a quantidade de palavras mais utilizadas\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp, palette=colors)\n",
    "g.set_title(f\"As 20 palavras mais utilizadas nos textos\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83261e20",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Analisando a quantidade de palavras mais utilizadas\n",
    "\n",
    "fig = px.treemap(temp, path=['Palavras'], values='Quantidade',title='As 20 palavras mais utilizadas nos textos')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495101ff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da8d21a4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Palavras mais utilizadas por Sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9281a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Criando dataframes por sentimentos\n",
    "\n",
    "# negativo\n",
    "Negative_sent = dfc[dfc['sentiment']==0]\n",
    "Negative_sent.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# positivo\n",
    "Positive_sent = dfc[dfc['sentiment']==1]\n",
    "Positive_sent.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# neutro\n",
    "Neutral_sent = dfc[dfc['sentiment']==2]\n",
    "Neutral_sent.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31a8e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Lista auxiliar com todas as palavras do dataframe\n",
    "\n",
    "raw_text = [word for word_list in dfc['list_words'] for word in word_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e30c327",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Sentimentos Negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c7f6b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas em sentimentos negativos\n",
    "\n",
    "top = Counter([item for sublist in Negative_sent['list_words'] for item in sublist])\n",
    "temp_negative = pd.DataFrame(top.most_common(20))\n",
    "temp_negative = temp_negative.iloc[1:,:]\n",
    "temp_negative.columns = ['Palavras','Quantidade']\n",
    "temp_negative.style.background_gradient(cmap='Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890d809",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação da quantidade de palavras mais utilizadas em sentimentos negativos\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp_negative, palette=colors)\n",
    "g.set_title(f\"Palavras mais utilizadas nos textos negativos\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afff34",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# As 20 palavras utilizadas apenas para o sentimento negativo\n",
    "\n",
    "Unique_Negative= words_unique(0, 20, raw_text)\n",
    "\n",
    "print('As 20 palavras mais utilizadas apenas em Tweets negativos:')\n",
    "Unique_Negative.style.background_gradient(cmap='Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414b719",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# As 20 palavras utilizadas apenas para o sentimento negativos\n",
    "\n",
    "fig = px.treemap(Unique_Negative, path=['words'], values='count',title='As 20 palavras mais utilizadas apenas em Tweets negativos')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85d56c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d950de81",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Sentimentos Positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f27e52",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas em sentimentos positivos\n",
    "\n",
    "top = Counter([item for sublist in Positive_sent['list_words'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(20))\n",
    "temp_positive.columns = ['Palavras','Quantidade']\n",
    "temp_positive.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097beb9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação da quantidade de palavras mais utilizadas em sentimentos positivos\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp_positive, palette=colors)\n",
    "g.set_title(f\"Palavras mais utilizadas nos textos positivos\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a152e0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# As 20 palavras utilizadas apenas para o sentimento positivo\n",
    "\n",
    "Unique_Positive = words_unique(1, 20, raw_text)\n",
    "\n",
    "print('As 20 palavras mais utilizadas apenas em Tweets positivos:')\n",
    "Unique_Positive.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff9213",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação das palavras utilizadas em sentimentos positivos\n",
    "\n",
    "fig = px.treemap(Unique_Positive, path=['words'], values='count',title='As 20 palavras mais utilizadas apenas em Tweets positivos')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309fdcb4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cef58502",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Sentimentos Neutros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118a20e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Palavras mais utilizadas em sentimentos neutros\n",
    "\n",
    "top = Counter([item for sublist in Neutral_sent['list_words'] for item in sublist])\n",
    "temp_neutral = pd.DataFrame(top.most_common(20))\n",
    "temp_neutral = temp_neutral.loc[1:,:]\n",
    "temp_neutral.columns = ['Palavras','Quantidade']\n",
    "temp_neutral.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ca74a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação da quantidade de palavras mais utilizadas em sentimentos neutros\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "g = sns.barplot(x='Quantidade', y='Palavras', data=temp_neutral, palette=colors)\n",
    "g.set_title(f\"Palavras mais utilizadas nos textos neutros\")\n",
    "g.set_xlabel(f\"Quantidade\")\n",
    "g.set_ylabel(\"Palavras\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d396ded",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# As 20 palavras utilizadas apenas para o sentimento neutro\n",
    "\n",
    "Unique_Neutral= words_unique(2, 20, raw_text)\n",
    "\n",
    "print('As 20 palavras utilizadas apenas em Tweets neutros:')\n",
    "Unique_Neutral.style.background_gradient(cmap=cmap_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99c445",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apresentação das palavras utilizadas em sentimentos neutros\n",
    "\n",
    "fig = px.treemap(Unique_Neutral, path=['words'], values='count',title='As 20 palavras mais utilizadas apenas em Tweets neutros')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92502f5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### WordClouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ae886e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Sentimentos negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c3377",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# WordCloud para Tweets negativos\n",
    "\n",
    "text = ' '.join(Negative_sent['join_f_words'])\n",
    "plot_wordcloud(text, title = 'WordCloud Tweets negativos', backcolor = 'white', clrmap = 'Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d777e1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7610b55",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Sentimentos positivos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71ff72",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# WordCloud para Tweets positivos\n",
    "\n",
    "text = ' '.join(Positive_sent['join_f_words'])\n",
    "plot_wordcloud(text, title = 'WordCloud Tweets positivos', backcolor = 'white', clrmap = 'Greens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a30ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6656fc3f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Sentimentos neutros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545fa566",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# WordCloud para Tweets neutros\n",
    "\n",
    "text = ' '.join(Neutral_sent['join_f_words'])\n",
    "plot_wordcloud(text, title = 'WordCloud Tweets neutros', backcolor = 'white', clrmap = 'PuBu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73fa2a9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "- Podemos ver que as mesmas palavras são comuns nos três segmentos;\n",
    "\n",
    "\n",
    "- Isso é interessante porque algumas palavras são mais de natureza negativa e outras palavras são mais de natureza positiva, o que significa que os nossos dados podem estar incorretamente etiquetados;\n",
    "\n",
    "\n",
    "- Olhando para as palavras únicas de cada sentimento, temos mais clareza sobre os dados, estas palavras únicas são determinantes para o sentimento dos tweets;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082c8a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72070112",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 4. Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb77b8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Separando conjunto de dados Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65486f15",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# A nossa base de dados tem 93.793 mil linhas e a quantidade de palavras disponíveis nos textos é muito grande. \n",
    "# Para evitar problemas de alocação de memória, processamento dos textos e modelagem, iremos criar uma amostra com 40% da base:\n",
    "\n",
    "# Caso o notebook apresente problemas de alocação de memória, favor diminuir o percentual da amostra dos dados.\n",
    "\n",
    "#file_name = './dados/train/Train3Classes_with_Token.csv'\n",
    "#dfc = reduce_mem_usage(pd.read_csv(file_name))\n",
    "#dfc['list_words'] = dfc['join_f_words'].apply(lambda w:str(w).split())\n",
    "\n",
    "#dfm = dfc.sample(frac=0.4, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5edcb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Vamos dividir os nossos dados numa matriz X que contém as características a treinar, \n",
    "# e uma matriz y com a variável alvo, neste caso a coluna covid_res. \n",
    "\n",
    "X = dfm['join_f_words']\n",
    "y = dfm['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86beb61d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Vamos dividir os dados num conjunto de Train e num conjunto de Test. \n",
    "# Iremos treinar o modelo no conjunto de treino e depois utilizaremos o conjunto de testes para avaliar o modelo\n",
    "\n",
    "random_seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49b80d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quantidade total da variável \"target\" (sentiment)\n",
    "\n",
    "y.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a27f32",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quantidade separada para o conjunto de treino inicial\n",
    "\n",
    "y_train.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3b2c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quantidade separada para o conjunto de teste inicial\n",
    "\n",
    "y_test.value_counts().sort_index()#(normalize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8fdeb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "191bda52",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Processando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e8e37",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Lista de modelos para testes\n",
    "\n",
    "list_models = [\n",
    "    {'model_name': 'Dummy Classifier uniform',\n",
    "     'estimator' : DummyClassifier(strategy='uniform', random_state=random_seed)},    \n",
    "    {'model_name': 'Linear Support Vector Machine',\n",
    "     'estimator' : LinearSVC(random_state=random_seed)},\n",
    "    {'model_name': 'Stochastic Gradient Descent Classifier',\n",
    "     'estimator' : SGDClassifier(n_jobs=-1, loss='modified_huber',random_state=random_seed)},\n",
    "    {'model_name': 'LightGBM',\n",
    "     'estimator' : LGBMClassifier(random_state=random_seed)},\n",
    "    {'model_name': 'Logistic Regression',\n",
    "     'estimator' : LogisticRegression(random_state=random_seed)},\n",
    "    {'model_name': 'Classifier Ridge regression',\n",
    "     'estimator' : RidgeClassifier(random_state=random_seed)},\n",
    "    {'model_name': 'Naive Bayes Gaussian',\n",
    "     'estimator' : GaussianNB()},\n",
    "    {'model_name': 'Bernoulli Naive Bayes',\n",
    "     'estimator' : BernoulliNB()}\n",
    "]\n",
    "\n",
    "# Os modelos abaixo foram retirados por apresentarem tempo de processamento superior 20 minutos com sample de 50% \n",
    "# e apresentarem resultados muito similares com os modelos escolhidos\n",
    "\n",
    "#{'model_name': 'Decision Tree',\n",
    "# 'estimator' : DecisionTreeClassifier(random_state=random_seed)},\n",
    "#{'model_name': 'Random Forest',\n",
    "# 'estimator' : RandomForestClassifier(random_state=random_seed)}, \n",
    "#{'model_name': 'AdaBoost',\n",
    "# 'estimator' : AdaBoostClassifier(random_state=random_seed)},\n",
    "#{'model_name': 'GradientBoosting',\n",
    "# 'estimator' : GradientBoostingClassifier(random_state=random_seed)},\n",
    "#{'model_name': 'XGBoost',\n",
    "# 'estimator' : XGBClassifier(random_state=random_seed)}\n",
    "#{'model_name': 'Support Vector Machine',\n",
    "# 'estimator' : SVC(random_state=random_seed)},\n",
    "#{'model_name': 'KNN (k-nearest neighbor)',\n",
    "# 'estimator' : KNeighborsClassifier(n_neighbors=3)},\n",
    "#{'model_name': 'Multinomial Naive Bayes',\n",
    "#'estimator' : MultinomialNB()},\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8f1aa",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Técnica Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d833f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac91f0a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Instanciando CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9df319",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Treinando o modelo com os conjuntos de dados de treinamento \n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train).toarray()\n",
    "X_test_cv = cv.transform(X_test).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce44eb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Processando modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfcc793",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 16 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Processando os modelos baseado na list_models\n",
    "score = []\n",
    "\n",
    "test_models (list_models,\n",
    "             \"model_name\",\n",
    "             \"estimator\",\n",
    "             \"CountVectorizer\",\n",
    "             X_train_cv,\n",
    "             X_test_cv,\n",
    "             y_train,\n",
    "             y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd4188",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86ef0d7f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bb8ef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Instanciando TF-IDF\n",
    "\n",
    "tfidf = TfidfVectorizer(use_idf = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc179a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Treinando o modelo com os conjuntos de dados de treinamento \n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).todense()\n",
    "X_test_tfidf  = tfidf.transform(X_test).todense()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f5592",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Processando modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e31ea",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Processando os modelos baseado na list_models\n",
    "\n",
    "test_models (list_models,\n",
    "             \"model_name\",\n",
    "             \"estimator\",\n",
    "             \"TF-IDF\",\n",
    "             X_train_tfidf,\n",
    "             X_test_tfidf,\n",
    "             y_train,\n",
    "             y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97515258",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ff02828",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Técnica Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a5869",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Instanciando Doc2Vec\n",
    "\n",
    "d2v = doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72efc9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Vamos dividir os nossos dados numa matriz X que contém as características a treinar, \n",
    "# e uma matriz y com a variável alvo, neste caso a coluna covid_res. \n",
    "\n",
    "X = dfm['list_words']\n",
    "y = dfm['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784160d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Vamos dividir os dados num conjunto de Train e num conjunto de Test. \n",
    "# Iremos treinar o modelo no conjunto de treino e depois utilizaremos o conjunto de testes para avaliar o modelo\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24983e62",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Preparando a classe de treinamento e teste\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "train_corpus = read_corpus(X_train)\n",
    "test_corpus = read_corpus(X_test, tokens_only=True)\n",
    "\n",
    "d2v.build_vocab(train_corpus)\n",
    "\n",
    "d2v.train(train_corpus, total_examples=d2v.corpus_count, epochs=d2v.epochs)\n",
    "\n",
    "X_train_d2v = np.array(list(map(d2v.infer_vector, X_train)))\n",
    "X_test_d2v = np.array(list(map(d2v.infer_vector, X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67efed67",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Processando modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54820cde",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# O processamento desta célula com o processamento dos modelos leva em média 10 minutos, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "# Processando os modelos baseado na list_models\n",
    "\n",
    "test_models (list_models,\n",
    "             \"model_name\",\n",
    "             \"estimator\",\n",
    "             \"Doc2Vec\",\n",
    "             X_train_d2v,\n",
    "             X_test_d2v,\n",
    "             y_train,\n",
    "             y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9917db",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e083d432",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfcfb3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Conmparação das pontuações após técnicas de balanceamento\n",
    "# Ordenando a pontuação\n",
    "score.sort(key = lambda y:y[2],reverse =True)\n",
    "\n",
    "# Exibindo a pontuação\n",
    "dfscore = pd.DataFrame (score, columns = ['Model', 'Tool', 'Accuracy'])\n",
    "\n",
    "# Apresenta o modelo que obteve a melhor acurácia\n",
    "print(f'O modelo {dfscore.iloc[0][0]} apresentou a melhor acurácia {dfscore.iloc[0][2]}.\\n')\n",
    "print(\"Comparação da Acurácia dos modelos: \")\n",
    "dfscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dec414",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc5f72cb",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Otimização do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb04811",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Modelo que apresentou a melhor acurácia\n",
    "\n",
    "model = LogisticRegression(random_state=random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921d68a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Aplicando **GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e483ae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Definindo valores iniciais para ajuste de parametro de reforço\n",
    "\n",
    "param_gs = {\n",
    "            'C': [1, 10, 100],\n",
    "            'penalty': ['l2'],\n",
    "            'max_iter': list(range(100,300,100))\n",
    "            }\n",
    "\n",
    "# Instanciando GridSearchCV com a variação dos parametros \n",
    "gsearch = GridSearchCV(estimator=model, param_grid=param_gs, scoring='accuracy', refit=True, verbose=2, cv=3)\n",
    "\n",
    "# Treinando o modelo com os conjuntos de dados\n",
    "gsearch.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Apresentação dos melhores parametros e melhor resultado\n",
    "print('\\nPrecisão média: %.3f' % gsearch.best_score_)\n",
    "print('Configuração: %s' % gsearch.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a8151e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Aplicando RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a1720",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_rs = {\n",
    "            'C': [1, 10, 100],\n",
    "            'penalty': ['l2'],\n",
    "            'max_iter': list(range(100,300,100))\n",
    "}\n",
    "\n",
    "# Instanciando RandomizedSearchCV com a variação dos parametros \n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_rs, scoring='accuracy', n_iter=100, cv=3, verbose=2)\n",
    "\n",
    "# Treinando o modelo com os conjuntos de dados\n",
    "rsearch.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Apresentação dos melhores parametros e melhor resultado\n",
    "print('\\nPrecisão média: %.3f' % rsearch.best_score_)\n",
    "print('Configuração: %s' % rsearch.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f43db",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd4de68",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Grava um novo CSV com os resultados dos modelos\n",
    "\n",
    "# Definindo o nome do arquivo\n",
    "if use_normalize==1:\n",
    "    file_name = './dados/train/Train3Classes_train_models_normalize.csv'\n",
    "else:\n",
    "    file_name = './dados/train/Train3Classes_train_models_Token.csv'\n",
    "  \n",
    "# Salvando o CSV\n",
    "try:\n",
    "    # Gravando o dataframe em CSV\n",
    "    dfm = pd.DataFrame (score, columns = ['Model', 'Tool', 'Accuracy'])\n",
    "    dfm.to_csv(file_name, index=False)\n",
    "    print('DataFrame modelos gravado com successo.')\n",
    "    \n",
    "except:\n",
    "    print(\"Ocorreu um erro na gravação.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9646d853",
   "metadata": {},
   "source": [
    "## 5. Conclusões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c7950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6114f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
