{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362c03d1",
   "metadata": {},
   "source": [
    "# Projeto 2 - NLP\n",
    "\n",
    "-----\n",
    "\n",
    "Nome:  Johnny Hideki Horita <br>\n",
    "Turma: 780"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517a372",
   "metadata": {},
   "source": [
    "Os segundo projeto do módulo de Machine Learning será focado no processamento de linguagem natural! Usaremos os algoritmos aprendidos e as técnicas vistas na segunda parte do curso para extrairmos informações relevantes de texto. Mais precisamente, de publicações no Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a3a98",
   "metadata": {},
   "source": [
    "## Os Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d5657",
   "metadata": {},
   "source": [
    "Utilizaremos um Dataset obtido do Twitter com 100K postagens entre os dias 01/08/2018 e 20/10/2018. Cada postagem é classificada como **positiva**, **negativa** ou **neutra**.  \n",
    "\n",
    "Dois arquivos serão disponilizados para o desenvolvimento dos modelos, um para treino/validação e outro para submissão. Os arquivos se encontram na pasta */Dados/train* e */Dados/subm*, respectivamente.\n",
    "\n",
    "Descrição das colunas:\n",
    "\n",
    "- **id**: ID único para o tweet  \n",
    "- **tweet_text**: Texto da publicação no Twitter  \n",
    "- **tweet_date**: Data da publicação no Twitter  \n",
    "- **sentiment**: 0, se negativo; 1, se positivo; 2, se neutro  \n",
    "- **query_used**: Filtro utilizado para buscar a publicação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc86eb5",
   "metadata": {},
   "source": [
    "## O Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e1f6f",
   "metadata": {},
   "source": [
    "Você deverá desenvolver um modelo para detectar o sentimento de uma publicação do Twitter a classificando em uma das três categorias: **positiva**, **negativa** ou **neutra**. O texto da publicação está disponível na coluna \"tweet_text\". Teste pelo menos 3 técnicas de NLP diferentes e escolha a métrica de avaliação que julgar mais pertinente.  \n",
    "\n",
    "Escolha o melhor modelo e gere uma base a partir dos dados de submissão, que estão no caminho ```Dados/subm/Subm3Classes.csv```, com o seguinte formato:\n",
    "\n",
    "\n",
    "|id|sentiment_predict\n",
    "|-|-|\n",
    "|12123232|0\n",
    "|323212|1\n",
    "|342235|2\n",
    "\n",
    "Salve essa tabela como um arquivo csv com o nome ```<nome>_<sobrenome>_nlp_degree.csv``` e submeta-o como parte da entrega final do projeto.  \n",
    "\n",
    "Para ajudar no desenvolvimento, é possível dividir o projeto em algumas fases:\n",
    "\n",
    "- **Análise de consistência dos dados**: analise se os dados estão fazendo sentido, se os campos estão completos e se há dados duplicados ou faltantes. Se julgar necessário, trate-os.    \n",
    "\n",
    "\n",
    "- **Análise exploratória**: analise a sua base como um todo, verifique o balanceamento entre as classes e foque, principalmente, na coluna ```tweet_text```.    \n",
    "\n",
    "\n",
    "- **Pré-processamento e transformações**: projetos de NLP exigem um considerável pré-processamento. Foque no tratamento da string do texto. Procure começar com tratamentos simples e adicione complexidade gradualmente. Nessa etapa você testará diferentes técnicas de transformações, como o Bag Of Words e o TF-IDF.    \n",
    "\n",
    "\n",
    "- **Treinamento do modelo**: depois das transformações, você poderá executar o treinamento do modelo classificador. Nessa etapa o problema se torna semelhante aos abordados na primeira parte do módulo. Você pode testar diversos classificadores como RandomForest, AdaBoost, entre outros. Otimize os hiperparâmetros do modelo com técnicas como a GridSearch e a RandomizedSearch.    \n",
    "\n",
    "\n",
    "- **Conclusões**: descreva, em texto, as conclusões sobre os seus estudos. O modelo é capaz de identificar o sentimento das publicações? É possível extrapolar o modelo para outros contextos, como a análise de sentimento de uma frase qualquer? Pense em questões pertinentes e relevantes que você tenha obtido durante o desenvolvimento do projeto!     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283638c9",
   "metadata": {},
   "source": [
    "## Critérios de avaliação\n",
    "\n",
    "Os seguintes itens serão avaliados:\n",
    "\n",
    "1. Desenvolvimento das etapas descritas acima;\n",
    "\n",
    "\n",
    "2. Reprodutibilidade do código: seu código será executado e precisa gerar os mesmos resultados apresentados por você;\n",
    "\n",
    "\n",
    "3. Clareza: seu código precisa ser claro e deve existir uma linha de raciocínio direta. Comente o código em pontos que julgar necessário para o entendimento total;\n",
    "\n",
    "\n",
    "4. Justificativa das conclusões obitdas: não existirá certo ou errado, mas as decisões e as conclusões precisam ser bem justificadas com base nos resultados obtidos.  \n",
    "\n",
    "O desempenho do modelo **não** será considerado como critério de avaliação.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6049a9c",
   "metadata": {},
   "source": [
    "## Informações gerais\n",
    "\n",
    "- O projeto deve ser desenvolvido individualmente;\n",
    "\n",
    "\n",
    "- Data de divulgação: 11/01/2022;\n",
    "\n",
    "\n",
    "- Aula de monitoria: 19/01/2022;\n",
    "\n",
    "\n",
    "- Data de entrega: 26/01/2022;\n",
    "\n",
    "\n",
    "- Entrega através do Class: Árvore de Decisão -> Exercícios -> Projeto 2\n",
    "\n",
    "\n",
    "Anexar, na entrega, o notebook de desenvolvimento e o arquivo .csv de submissão, da seguinte forma:  \n",
    "\n",
    "notebook: ```<nome>_<sobrenome>_<númeroTurma>_projeto_2.ipynb```   \n",
    "csv: ```<nome>_<sobrenome>_<númeroTurma>_projeto_2_submissao.csv```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb23437",
   "metadata": {},
   "source": [
    "## Dicas\n",
    "\n",
    "### Base de treino e submissão\n",
    "\n",
    "A base de submissão não possui a variável de saída, portanto ela será utilizada **apenas** para gerar o arquivo que acompanha a submissão do projeto.      \n",
    "\n",
    "### Tente encontrar possíveis vieses\n",
    "\n",
    "É muito comum que modelos de NLP possuam fortes vieses, como a tendência de relacionar palavras específicas com alguma classe de saída. Tente encontrar vieses no seu estudo, isso pode ajudar a tirar boas conclusões. o campo \"query_used\" pode ser útil para essa análise.  \n",
    "\n",
    "### O pré-processamento é a chave para um bom desempenho\n",
    "\n",
    "Essa é a etapa que mais vai contribuir para o desempenho do seu modelo. Seja criativo e desenvolva essa etapa de uma maneira que seja fácil de aplicar o mesmo processamento para uma nova base, você terá que fazer isso para gerar a base de submissão.\n",
    "\n",
    "### Um termômetro para o seu desenvolvimento\n",
    "\n",
    "Após a correção do seu projeto, o professor irá disponibilizar a sua acurácia obtida na base de submissão. Você pode interpretar esse resultado como a simulação do resultado do seu modelo em produção. Uma diferença entre o resultado do estudo e o resultado de submissão indica um grau de **overfitting** no seu modelo.\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96911dea",
   "metadata": {},
   "source": [
    "# Desenvolvimento do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d5233",
   "metadata": {},
   "source": [
    "## Análise de consistência dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f25c3d",
   "metadata": {},
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad89b883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bibliotecas\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import requests\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import squarify\n",
    "import plotly.offline as py\n",
    "#import plotly_express as px\n",
    "from plotly import graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, f1_score, r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score, StratifiedKFold, cross_validate\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC \n",
    "# Naive Bayes (Gaussian, Multinomial)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Stochastic Gradient Descent Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# KNN (k-nearest neighbor)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# XGBoost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "# LGBM Classifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# Ada Boosting Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Dummy Boosting Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from unidecode import unidecode\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from enelvo.normaliser import Normaliser\n",
    "\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "\n",
    "from spacy.util import compounding\n",
    "from spacy.util import minibatch\n",
    "\n",
    "import shap\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from IPython.core.display import HTML as Center\n",
    "from IPython.display import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1272b9b",
   "metadata": {},
   "source": [
    "### Padrões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51314fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=13)    # legend fontsize\n",
    "plt.rc('font', size=13)          # controls default text sizes\n",
    "\n",
    "colors = sns.color_palette(\"pastel\") # deep, pastel, Set1 Set2 Set3, icefire, tab10, muted, colorlind, coolwarm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e73245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Center(\"\"\" <style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style> \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c2874",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3054506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de avaliação dos valores de NaN no dataframe\n",
    "\n",
    "def missing_values_table(df):\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        mz_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mz_table = mz_table.rename(\n",
    "        columns = {0 : 'Valores faltantes', 1 : '% de Valores Totais'})\n",
    "        mz_table['Data Type'] = df.dtypes\n",
    "        mz_table = mz_table[\n",
    "            mz_table.iloc[:,1] != 0].sort_values(\n",
    "        '% de Valores Totais', ascending=False).round(1)\n",
    "        print (\"O dataframe tem \" + str(df.shape[1]) + \" colunas e \" + str(df.shape[0]) + \" linhas.\\n\"      \n",
    "            \"Existem \" + str(mz_table.shape[0]) +\n",
    "              \" colunas que têm valores faltantes.\")\n",
    "        mz_table.to_excel('missing_and_zero_values.xlsx', freeze_panes=(1,0), index = True)\n",
    "        return mz_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "237d61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de avaliação de modelos de aprendizagem de máquinas\n",
    "\n",
    "def test_models_plot_roc_auc_curve(model_list, col_model_name, col_model, X_train, X_test, y_train, y_test):\n",
    "    plt.figure(figsize=(15,7))\n",
    "    for mdl in model_list:\n",
    "        model = mdl[col_model]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        y_predproba = model.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predproba)\n",
    "        auc = metrics.roc_auc_score(y_test, y_predict)\n",
    "        plt.plot(fpr, tpr, label='%s ROC (AUC = %0.4f)' % (mdl[col_model_name], auc))\n",
    "        print(\"Model      : %s\" % mdl[col_model_name])\n",
    "        calc_predict(mdl[col_model_name], y_test, y_predict)\n",
    "        \n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC-AUC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61537f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de avaliação de modelos apresentação da matriz de confusão\n",
    "\n",
    "def test_models_plot_confusion_matrix(model_list, col_model_name, col_model, X_train, X_test, y_train, y_test):\n",
    "    for mdl in model_list:\n",
    "        model = mdl[col_model]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        \n",
    "        print(\"\")        \n",
    "        print(\"=\" * 55)        \n",
    "        print(\"Model      : %s\" % mdl[col_model_name])\n",
    "        calc_predict(mdl[col_model_name], y_test, y_predict)\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_predict)\n",
    "        cm_matrix = pd.DataFrame(data=cm, columns=['Atual Positivo:1', 'Atual Negativo:0'], \n",
    "                                         index=['Pred. Positivo:1', 'Pred. Negativo:0'])\n",
    "\n",
    "        print('Matriz Confusão\\n\\n', cm)\n",
    "        print('\\nV. Positivos(VP) = ', cm[0,0])\n",
    "        print('V. Negativos(VN) = ', cm[1,1])\n",
    "        print('F. Positivos(FP) = ', cm[0,1])\n",
    "        print('F. Negativos(FN) = ', cm[1,0])\n",
    "\n",
    "        sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a3ea476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para cálcular as métricas \n",
    "\n",
    "def calc_predict(col_model_name, y_test, y_predict):\n",
    "    print(\"ROC - AUC  : %0.4f \" % metrics.roc_auc_score(y_test, y_predict))\n",
    "    print(\"Accuracy   : %0.4f \" %  accuracy_score(y_test, y_predict))\n",
    "    print(\"Precision  : %0.4f \" % precision_score(y_test, y_predict, average='weighted'))\n",
    "    print(\"Recall     : %0.4f \" % recall_score(y_test, y_predict, average='weighted'))\n",
    "    print(\"F1 - Score : %0.4f \" % f1_score(y_test, y_predict, average='weighted'))\n",
    "    print(\"MAE        : %0.4f \" % mean_absolute_error(y_test, y_predict))\n",
    "    print(\"RMSE       : %0.4f \" % np.sqrt(mean_squared_error(y_test, y_predict)))\n",
    "    print(\"R2         : %0.4f \" % r2_score(y_test, y_predict))\n",
    "    print(\"\")\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    print(\"=\" * 55)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f11adbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a importância da variável no modelo\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "def modelfit(alg, dtrain, predictors, target, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    # Adequando as classes para treino\n",
    "    alg.fit(dtrain[predictors], dtrain[target])\n",
    "        \n",
    "    # Previsão de saída para o conjunto de dados de teste\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    # Utilizando o Cross Validation\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, dtrain[predictors], dtrain[target], cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Exibindo relatório:\n",
    "    print (f\"\\nRelatório do Modelo {alg}\")\n",
    "    print (\"\\nAcuracia : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "    #print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predictions))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "        \n",
    "    #Exibindo gráfico da importancia das variáveis\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Importância das variáveis', color=colors)\n",
    "        plt.ylabel('Pontuação')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52180e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_colours(number_of_colors):\n",
    "    '''\n",
    "    Simple function for random colours generation.\n",
    "    Input:\n",
    "        number_of_colors - integer value indicating the number of colours which are going to be generated.\n",
    "    Output:\n",
    "        Color in the following format: ['#E86DA4'] .\n",
    "    '''\n",
    "    colors = []\n",
    "    for i in range(number_of_colors):\n",
    "        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922f869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\johnny.horita\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Esta celula precisa ser executada apenas 1 vez caso não tenha a biblioteca em portugues instalada\n",
    "# Abaixo seguem 2 formas para a instalação: via conda ou pip\n",
    "\n",
    "# Instalação utilizando conda\n",
    "#!conda install -c conda-forge spacy\n",
    "\n",
    "# Instalação utilizando Pip\n",
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "\n",
    "# Bilbioteca em portugues\n",
    "# Efficiency\n",
    "#!python -m spacy download pt_core_news_sm\n",
    "\n",
    "# Accuracy\n",
    "#!python -m spacy download pt_core_news_lg \n",
    "\n",
    "spc_pt = spacy.load('pt_core_news_sm')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "977cea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para tratamento da variável de texto para definir melhores valores para classificação da modelagem\n",
    "\n",
    "# instanciando\n",
    "normalizador = Normaliser(tokenizer='readable') #,capitalize_inis=True,capitalize_pns=True,capitalize_acs=True,sanitize=True)\n",
    "\n",
    "def nlp_normalizar_texto(texto):\n",
    "    texto_norm = normalizador.normalise(texto)\n",
    "   \n",
    "    return texto_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad860da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para tratamento da variável de texto para definir melhores valores para classificação da modelagem\n",
    "\n",
    "def nlp_tratar_texto(texto):\n",
    "    #Removendo endereços de sites\n",
    "    texto_sem_url = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', texto)\n",
    "        \n",
    "    #Removendo e-mail\n",
    "    texto_sem_email = re.sub(r'[A-Za-z0-9]*@[A-Za-z]*\\.?[A-Za-z0-9]*\\.?[A-Za-z0-9]*', '', texto_sem_url)\n",
    "\n",
    "    #Removendo users\n",
    "    texto_sem_user = re.sub(r'@[A-Za-z0-9]*', '', texto_sem_email)\n",
    "    \n",
    "    #Remover caracteres que não são letras e tokenização\n",
    "    letras =  re.findall(r'\\b[A-zÀ-úü]+\\b', texto_sem_user.lower())\n",
    "\n",
    "    #Remover stopwords\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    #Adicionando stopwords que não estão na lista do nltk \n",
    "    stopwords.append(\"'\")\n",
    "    stopwords.append(\"pra\")\n",
    "    stopwords.append(\"tá\")\n",
    "    stopwords.append(\"tão\")\n",
    "    #stop = set(stopwords)\n",
    "\n",
    "    palavras = [w for w in letras if w not in stopwords]\n",
    "    palavras_string = \" \".join(palavras)\n",
    "\n",
    "    #Instanciando o objeto spacy\n",
    "    spc_letras =  spc_pt(palavras_string)\n",
    "\n",
    "    #Lemmização \n",
    "    tokens = [token.lemma_ if token.pos_ == 'VERB' else str(token) for token in spc_letras]\n",
    "\n",
    "    #problemas com verbo ir\n",
    "    ir = ['vou', 'vais', 'vai', 'vamos', 'ides', 'vão']\n",
    "    tokens = ['ir' if token in ir else str(token) for token in tokens]\n",
    "    \n",
    "    return tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e738a2b7",
   "metadata": {},
   "source": [
    "### Inicializando Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39c224f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando arquivo\n",
    "\n",
    "df = pd.read_csv('./dados/train/Train3Classes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efd96274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de linhas...........: 95000\n",
      "Quantidade de linhas duplicadas: 0\n",
      "Quantidade de colunas..........: 5\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "\n",
    "qtl, qtc = df.shape\n",
    "\n",
    "# Quantidade de linhas duplicadas\n",
    "\n",
    "qtd, _ = df[df.duplicated(keep=False)].shape\n",
    "\n",
    "print(f'Quantidade de linhas...........: {qtl}')\n",
    "print(f'Quantidade de linhas duplicadas: {qtd}')\n",
    "print(f'Quantidade de colunas..........: {qtc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daf0b35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95000 entries, 0 to 94999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          95000 non-null  int64 \n",
      " 1   tweet_text  95000 non-null  object\n",
      " 2   tweet_date  95000 non-null  object\n",
      " 3   sentiment   95000 non-null  int64 \n",
      " 4   query_used  95000 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95aba7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataframe tem 5 colunas e 95000 linhas.\n",
      "Existem 0 colunas que têm valores faltantes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores faltantes</th>\n",
       "      <th>% de Valores Totais</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Valores faltantes, % de Valores Totais, Data Type]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando os valores nulos do dataframe\n",
    "\n",
    "missing_values_table(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abf0cc",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Conclusões:** \n",
    "\n",
    "O dataframe é composto por 05 colunas e 95.000 registros.\n",
    "\n",
    "A tabela acima NÃO apresenta valores NÃO preenchidos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc5d77c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tweet_text', 'tweet_date', 'sentiment', 'query_used'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de colunas do dataframe\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c9ae92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1049721159292346368</td>\n",
       "      <td>Rio elege maior bancada policial de sua histór...</td>\n",
       "      <td>Tue Oct 09 18:00:01 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>folha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046251157025423360</td>\n",
       "      <td>fiquei tão triste quando eu vi o preço da câme...</td>\n",
       "      <td>Sun Sep 30 04:11:28 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041744620206653440</td>\n",
       "      <td>Para Theresa May, seu plano para o Brexit é a ...</td>\n",
       "      <td>Mon Sep 17 17:44:06 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>exame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046937084727107589</td>\n",
       "      <td>caralho eu quero proteger a danielly em um pot...</td>\n",
       "      <td>Tue Oct 02 01:37:06 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1047326854229778432</td>\n",
       "      <td>@SiCaetano_ viva o caos :)</td>\n",
       "      <td>Wed Oct 03 03:25:55 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         tweet_text  \\\n",
       "0  1049721159292346368  Rio elege maior bancada policial de sua histór...   \n",
       "1  1046251157025423360  fiquei tão triste quando eu vi o preço da câme...   \n",
       "2  1041744620206653440  Para Theresa May, seu plano para o Brexit é a ...   \n",
       "3  1046937084727107589  caralho eu quero proteger a danielly em um pot...   \n",
       "4  1047326854229778432                         @SiCaetano_ viva o caos :)   \n",
       "\n",
       "                       tweet_date  sentiment query_used  \n",
       "0  Tue Oct 09 18:00:01 +0000 2018          2      folha  \n",
       "1  Sun Sep 30 04:11:28 +0000 2018          0         :(  \n",
       "2  Mon Sep 17 17:44:06 +0000 2018          2      exame  \n",
       "3  Tue Oct 02 01:37:06 +0000 2018          0         :(  \n",
       "4  Wed Oct 03 03:25:55 +0000 2018          1         :)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listagem das primeiras linhas do dataframe\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a59eb",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Tratamento de variáveis**\n",
    "\n",
    "- Criação de uma nova variável **filtered_words**, onde o texto original (tweet_text) será submetido a tratamentos para definir as palavras chaves de sentimento para melhorar a classificação do modelo;<br>\n",
    "\n",
    "\n",
    "- Exclusão de variáveis que entendemos não ser relevante para o modelo<br>\n",
    "    **id**: ID único para o tweet<br>\n",
    "    **tweet_date**: Data da publicação no Twitter<br>\n",
    "    **query_used**: Filtro utilizado para buscar a publicação<br>\n",
    "\n",
    "\n",
    "- Exclusão de variáveis tratadas<br>\n",
    "    **tweet_text**: Texto da publicação no Twitter<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc315228",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#O tratamendo dos tweets leva em média 8 min, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "#Cria uma nova variável utilizando funções para tratamento das palavras do texto\n",
    "df[\"tweet_text_normalise\"] = df['tweet_text'].apply(lambda w: nlp_normalizar_texto(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f385b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#O tratamendo dos tweets leva em média 8 min, em uma máquina i7 com 12 cores e 32 ram \n",
    "\n",
    "#Cria uma nova variável utilizando funções para tratamento das palavras do texto\n",
    "df[\"filtered_words\"] = df['tweet_text'].apply(lambda w: nlp_tratar_texto(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f22507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma nova variável concatenando os tokens gerados pelo tratamento das palavras gerando um novo texto reduzido\n",
    "df['join_f_words'] = df['filtered_words'].apply(lambda w: ' '.join(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e54ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma nova variável concatenando os tokens gerados pelo tratamento das palavras gerando um novo texto reduzido\n",
    "df['join_n_words'] = df['normalized_words'].apply(lambda w: ' '.join(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d283c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grava um novo CSV com as novas colunas para avaliação\n",
    "\n",
    "# Definindo o nome do arquivo\n",
    "file_name = './dados/train/Train3Classes_with_Tokens.csv'\n",
    "  \n",
    "# Salvando o CSV\n",
    "df.to_csv(file_name)\n",
    "print('DataFrame gravado com successo.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "\n",
    "#df[['tweet_text']]\n",
    "df[['tweet_text', 'filtered_words', 'join_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c279bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7682d5be",
   "metadata": {},
   "source": [
    "## Análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4baeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações do dataframe\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b3e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cffc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b796df",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\n",
    "temp.style.background_gradient(cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567c31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511c607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78261da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db10b250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df6c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apresentação de Wordcloud\n",
    "\n",
    "text = \" \".join(palavras_artista)\n",
    "wordcloud = WordCloud(background_color=\"white\",width=2000, height=800, collocations = False).generate(text)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "fig.savefig('baco_exu_blues.png', dpi=fig.dpi)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5811661",
   "metadata": {},
   "source": [
    "## Pré-processamento e transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082c8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72070112",
   "metadata": {},
   "source": [
    "## Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5edcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9646d853",
   "metadata": {},
   "source": [
    "## Conclusões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c7950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6114f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
